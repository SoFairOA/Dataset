<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T12:48+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>In this review article, the latest applications of machine learning (ML) in additive manufacturing (AM) field are reviewed. These applications, such as parameter optimization and anomaly detection, are classified into different types of ML tasks, including regression, classification, and clustering. The performance of various ML algorithms in these types of AM tasks are compared and evaluated. Finally, several future research directions are suggested.</p>
        <p>Machine learning (ML), a subset of artificial intelligence (AI), has increasingly become popular in additive manufacturing (AM) research. Additive manufacturing, also known as 3D printing or rapid prototyping (RP), is defined as a group of layer-upon-layer fabrication processes controlled by a computer-aided design (CAD) model [1,2]. Machine learning is defined as computer programming to optimize a performance criterion using example data or past experience [3]. For machine learning in additive manufacturing, besides the typical application of making predictions through data fitting, the research community is exploring new and innovative approaches to integrate ML and AI methods into AM. ML algorithms, applications, and platforms are helping AM practitioners improve product quality, optimize manufacturing process, and reduce costs.</p>
        <p>A major challenge in current AM field is the inconsistency of the quality of the printed products, which are highly dependent on numerous processing parameters, such as printing speed and layer thickness. These process-structure-property (PSP) relationships have been discussed in many review articles [4][5][6]. One method to address this challenge is conducting experiments or highfidelity simulations [7,8] to obtain reliable data and help optimize the processing parameters, but both of them are either time-consuming or expensive, and sometimes both. Another method to ensure part quality and process reliability is the application of in situ monitoring systems [9], but an efficient way for defect detection using the in situ data such as images is needed. In both methods, there is a critical need of an effective and efficient tool for data analysis and data mining. This need is being addressed by a subset of artificial intelligence (AI) known as ML.</p>
        <p>With a reliable training dataset, the ML models learn knowledge from the training set and make inference based on the knowledge. On one hand, the trained machine learning models can make predictions and determine the optimal processing parameters in an efficient way. On the other hand, it can also deal with in situ data for defect detection in real time. Some other ML applications, such as geometric deviation control, cost estimation, and quality assessment, are also reported in recent literature. In general, the ML applications can be regarded as the art of data manipulation. This capability makes ML a key aspect of Industry 4.0 [10].</p>
        <p>Machine learning tasks can be divided into three main categories: supervised learning, unsupervised learning, and reinforcement learning [3]. Figure 1 displays the taxonomy of ML with the corresponding applications in AM field. In supervised learning, each input datum is labeled with an output ğ‘Œğ‘Œ, and the training set consists of many input-output pairs. Each input is a vector contains all involved features, ğ‘‹ğ‘‹ 1 , ğ‘‹ğ‘‹ 2 , â€¦ , ğ‘‹ğ‘‹ ğ‘›ğ‘› , that may affect its output. Each output can be a target classification such as quality assessment (good or bad) and the corresponding ML category is classification, or a target parameter such as porosity and tensile strength and the corresponding ML category is regression. In unsupervised learning, each input datum doesn't come with an output, and the model will study the relationship among input data. A typical application of unsupervised learning is clustering, in which all data are clustered into groups based on their similarity. Reinforcement learning, on the other hand, is learning how to map situations to actions so as to maximize a numerical reward signal [11], the applications of which include self-driving car and chess. Figure 1 illustrates some example applications in AM field with their corresponding ML categories. In AM field, most of the ML applications fall into the supervised learning category.</p>
        <p>Data pre-processing</p>
        <p>Closed-loop control The objective of this review article is to present the latest applications of machine learning in AM field, and thus provide a starting point for AM practitioners and researchers who are interested in applying ML. Very recently, there are a few related review articles [12] and reports [13] available. While Ref. [12] focuses on the applications and challenges of only neural network (NN), and Ref. [13] focuses more on the data acquisition in AM field, this work focuses on providing guidance on how to generate ideas in applying ML in AM field, distinguish the type of ML tasks, and make selection of different ML models. The whole paper is organized as follows:</p>
        <p>The latest applications of ML in AM field are first reviewed from the perspective of AM in Section 2, and then classified into different categories of machine learning tasks, including supervised learning (Section 3) and unsupervised learning (Section 4). The performance of various machine learning algorithms applied in recent literature are compared and evaluated in Section 3 and Section 4. Finally, in Section 5, the work is summarized, and several future research directions are suggested.</p>
        <p>ML is a data manipulation tool. Figure 2 demonstrates various types of data available to be analyzed and utilized in the PSP relation chain. The "process" term in the widely used PSP relationships is partitioned into two terms, "processing parameter" and "processing resultant data", in order to distinguish data available before the process and during the process. There are many relationships between these data, including but not limited to: (1) the processing parameters, such as extruder temperature in ME, laser power in laser powder bed fusion (L-PBF), printing speed, and layer thickness, significantly affect the structure of the printed parts, and thus dominate their quality and performance; (2) the designed shape play a crucial role in the printing cost and the geometric deviation of the printed products; (3) the in situ images and acoustic emission (AE) acquired by the monitoring systems are available to detect the occurrence of defect and its type in real time. Therefore, if a dataset, which consists of at least two types of related data in the PSP relation chain, is used to train ML models, the ML models will be able to make inference based on these data. This is the general procedure to apply ML models.</p>
        <p>Figure 2. The process-structure-property relationship chain in additive manufacturing. Texts in the boxes represent the available data that can be used in machine learning. Bold texts represent some existing machine learning applications in additive manufacturing field. The origin and the end of each arrow represent the input and output data, respectively.</p>
        <p>For designers, the quality of a part using a certain combination of processing parameters will remain uncertain until it is finally printed. Therefore, a series of efforts, such as printing some samples and testing their performance, have to be made to ensure the part quality, which makes the design process expensive, time-consuming and dynamic. In this regard, a direct relationship between the processing parameters and part quality is strongly desirable. To this end, experiments and simulations are useful methods to help construct such a relationship, but it's impractical to obtain optimal processing parameters using the two methods when a large amount of input features is involved. ML models, on the other hand, can be applied as surrogate models to assist process optimization.</p>
        <p>Given a series of reliable training data of the property of interest (output) at some combinations of processing parameters (input), a process map can be generated by these discrete data points using ML regression models. Figure 3</p>
        <p>Closed-loop control and defect detection Process â€¦â€¦ (output) in terms of laser power and scan speed (input) of 316L strainless steel in L-PBF process [14]. The applications of the process map is twofold: (1) it can make predictions to the output at any combinations of input features as a surrogate model and therefore reduce the demand of experimental and computational study, and (2) it can provide the relevance of each input feature to the output so as to obtain optimal input combination. Figure 3(b) plots the uncertainty and the discrete data points used to generate the process map. The uncertainty from the ML model is part of epistemic uncertainties in uncertainty quantification (UQ) [15]. Recently, Meng and Zhang adopted the approach to develop the process design maps of two metals, 316L and 17-4 PH stainless steels [16]. Their studies show that the keyhole mode criteria need to be revised based on the specific metal composition and powder layer thickness. The process map enables designers to achieve property prediction and process optimization efficiently. Since the process map is a typical production of ML regression models, the recent applications from literature in this topic are reviewed in Section 3.1.</p>
        <p>The development of the in situ monitoring systems enables the acquisition of real time data that can be used for defect detection and closed-loop control for AM [9]. These real time data, including spectra, images, AE and computed tomography (CT), can be utilized by ML models in several ways: (1) label these data with defect (possibly with defect types) or not by experimental results or human knowledge, and then use the labelled data to train supervised learning models for defect detection and quality prediction in real time, which is a typical application of ML classification models and will be discussed in Section 3.2; (2) conduct cluster analysis using unsupervised learning models to cluster the abnormal data so as to achieve defect detection without the labelling process, which will be discussed in Section 4.1; (3) train the ML regression models along with the data of some real-time controllable processing parameters, in order to tune these processing parameters in real time. An example of the third way is the voltage level control in MJ process by Wang et al. [17]. Their process control framework consists of three main parts, as demonstrated in Figure 4. First, a charge-coupled device (CCD) camera is used to capture the dynamic images for the droplet. Second, four properties (satellite, ligament, volume, and speed) of the droplet are extracted from the images to train a neural network (NN) ML model along with the current voltage. Third, the trained ML model is then used to determine the optimized voltage level and send it to the voltage adjustment system to control the droplet jetting behavior.</p>
        <p>Low geometric accuracy and poor surface integrity are common defects of AM parts [18]. These geometric defects impede the applications of AM in several industries, such as aerospace and medical [19]. In this regard, ML models are capable of identifying the occurrence of geometric defect, quantifying the geometric deviation, and providing guidance of geometric error compensation. For instance, Francis et al. [20] developed a geometric error compensation framework for L-PBF process using convolutional neural network (CNN) ML model, shown in Figure 5. Using thermal history and some processing parameters as input and distortion as output, the trained ML model is capable of predicting distortion which is then imported reversely to the CAD model to achieve error compensation. By this means, the geometric accuracy of parts fabricated by the compensated CAD model will be significantly improved.</p>
        <p>The printing cost and time are significant components of information shared between the manufacturers, clients and other stakeholders within the supply chain. Although they can be roughly estimated by the volume of the designed shape, there is still a need of a more accurate and efficient tool for cost estimation. Recently, an application of cost estimation by Chan et al.</p>
        <p>[21] is reported. Figure 6 demonstrates the cost estimation framework they proposed: (1) a client submits a manufacturing job with a 3D model; (2) features are generated from the 3D model and form the input vector, which is then imported to the trained ML models for cost prediction based on similar jobs using clustering analysis; (3) if client prefers or the training dataset size for ML models is small, the 3D model will be forwarded to simulation models to predict the cost, which will also become training data for ML models; (4) the final predicted cost is estimated by combining the ML and simulation predictions; (5) the final prediction is forwarded to the client.</p>
        <p>So far, the latest applications of ML in AM have been reviewed in Section 2 from the perspective of AM. From now on, these applications are classified into different categories of ML tasks in Figure 1. This is important to make selection of ML models for some reasons: (1) even with same applications, the ML models applied may be different with different data type, such as defect detection which can be achieved by both supervised learning and unsupervised learning models; (2) ML models tend to possess similar performance in the same categories of ML tasks using similar data type and dataset size. In this regard, Section 3 and Section 4 aim at providing guidance of making selection of data type and corresponding ML models.</p>
        <p>An indispensable factor in applying ML in AM field is the data acquisition. A ML model requires sufficient data to make accurate predictions. The required number of training data also increases exponentially with the increasing number of input features. However, in many applications, the acquisition and labelling of data requires high experimental, computational, and/or laboring costs. Therefore, before a ML model is applied, the dimension of a ML task should be determined carefully considering the number of available data and the cost to obtain them. Section 3 and Section 4 also list many examples of ML applications in literature that can help determine the task dimension.</p>
        <p>In supervised learning, all input data are labeled with an output. The output can be either the parameters or the corresponding ML task is regression, or classes and the corresponding ML task is classification. Since most of the ML applications in AM aim at predicting a target parameter or class, supervised learning is the major type of ML applications in AM field.</p>
        <p>In regression tasks, the output of each input is parameters, such as porosity of the printed products, efficiency, melt pool depth, mechanical property, etc. The AM algorithm learns the relevance between the input and output parameters from the training dataset, and then makes inference from a new input to its output using the relevance it learns.</p>
        <p>The major functionality of ML regression models in AM field is the generation of process map, which has been discussed in Section 2.1. Therefore, processing parameters optimization and property prediction will be the two major applications of ML regression models. In addition, since the targets in geometric deviation control and cost estimation are all parameters, they may also be the applications of ML regression models.</p>
        <p>Table 1 shows the recent regression applications along with the ML models in AM field.</p>
        <p>According to Table 1, the two major ML models for regression tasks applied in AM field in recent literature are neural network (NN) and Gaussian process (GP). Table 1. ML regression applications in AM.</p>
        <p>Inputs Outputs Models Geometric deviations control [22] Shape parameters</p>
        <p>Gaussian process (GP) Processing parameters optimization [14] Laser power and scan speed Melt pool depth GP Processing parameters optimization [23] Laser power and scan speed Porosity GP Processing parameters optimization [24] Laser power and scan speed Melt pool depth Regression tree (RT), GP Processing parameters optimization [16] Laser power and scan speed Melt pool depth and width depth ratio GP Trace geometry prediction [25] Laser power and scan speed, and powder feeding rate of massively parallel interconnected networks of simple (usually adaptive) elements and their hierarchical organizations [32]. All the "neural network" or "NN" in this paper refer to artificial neural networks, instead of biological neural systems. A typical neural network contains an input layer, one or more hidden layers and one or more output layers. Each layer is made of numerous neurons. The information of each neuron is propagated to the next layer based on it's weight. A NN will be categorized to recurrent NN when the propagation of its neurons forms cycles, and feedforward NN otherwise. During training, the weight of each neuron is optimized by the learning rule as soon as a new observation is imported into the NN. The most popular learning rule for NN is the backpropagation (BP) algorithm [33], which adjusts the weights based on the gradient descent. However, due to the strong learning ability of BP algorithm, NN usually suffers from overfitting issue (More discussions in Section 3.3), which can be alleviated by either early stopping method or regularization [34,35]. For more knowledge about NN, refer to Ref. [36].</p>
        <p>Caiazzo et al. [25] applied BP-NN for trace geometry prediction with RMSE of around 5% using 30 tranining data. Rong-Ji et al. [26] tested the performance of BP-NN with 5 to 10 hidden neurons and their results exposed the trend that more hidden neurons tend to make better predictions. Zhang et al. [27] used recurrent NN in ME process to predict the tensile strength of the printed products and the RMSE was around 2%. A Gaussian process is defined as a collection of random variables, any finite number of which has a joint Gaussian distribution [37]. Similar to the mean value and variance in Gaussian distribution, a GP is completely specified by a mean function ğ‘šğ‘š(ğ‘¿ğ‘¿) and a covariance function ğ¶ğ¶(ğ‘¿ğ‘¿, ğ‘¿ğ‘¿ * ), where X is the input vector containing all input features. The covariance function is defined by a single or a combination of kernel functions and is critical to the performance of GP as it captures the spatial dependence between two different locations, ğ‘¿ğ‘¿ and ğ‘¿ğ‘¿ * . The selection of kernel functions should be based on practical applications and has been discussed in Ref. [37].</p>
        <p>Tapia et al. [14,23] applied GP to make predictions of porosity and melt pool depth in L-PBF process. The process map of melt pool depth in terms of laser power and scan speed with the corresponding uncentainty are plotted in Figure 3. GP shows excellent regression performance in noisy environment and with limited number of training data. The GP can be used calibrate a convinient criterion [14] to aviod porous formation due to keyhole mode [38] in L-PBF process.</p>
        <p>An exmaple of this calibration is demonstrated in Ref. [16], where the process maps of 316L and 17-4 PH stainless steels are generated by GP model using experimental dataset and used to compare anaginst and calibrate the normalized enthalpy criterion [14]. Zhu et al. [22] applied GP to make predictions on shape deviation and the RMSE is around 3% using 75% of the whole dataset as the training set. Overall, GP is efficient and effective in regression tasks with a few input features and a small dataset. GP may lose its efficiency when the number of involved input features is large or the size of the training dataset is too large, due to the high computational costs in performing matrix inversion.</p>
        <p>In general, both GP and NN are capable of handling regression tasks in AM field. NN is more complicated than GP and requires more knowledge to tune the hyperparameters. The selection of ML models should be based on the complexity of the training dataset (i.e. the number of training data points and input features). For low complexity tasks, GP is recommended. For high complexity tasks, NN is recommended. The application of an ensemble of multiple algorithms [28] (including NN) are also reported, which predict more accurately than NN and can be regarded as an alternative.</p>
        <p>In classification tasks, the output of each input is a class or a category, such as different defect types or quality assessment grade. Similar to regression tasks, the ML models learn how to make classification from the training set, and then use the knowledge to classify new input.</p>
        <p>In AM field, there are various classes with different criteria that can be used to distinguish part quality, such as defect and non-defect, quality is good or bad, quality grade assessment on a scale of 1 to 10 to quantify the quality, etc. If a ML model is trained by some classification examples at different input settings, it will be able to make classification to new input henceforth.</p>
        <p>Therefore, ML classification models can be used in AM field in three main aspects: (1) it can use in situ data, such as images and AE, to make predictions of defects so as to help defect detection in real time, (2) it can predict the part quality at different processing parameters, and (3) it can assist quality assessment using the geometric information of printed parts. As the geometric deviation can be described by several types, such as translation and rotation, ML classification models can also achieve geometric deviation control.</p>
        <p>An assessment method is necessary to quantify the performance of a classification model.</p>
        <p>Classification tasks can be further divided into two subgroups: (1) binary problems, in which only two categories are involved, and (2) multiclass problems, in which at least three categories are involved. The performance of ML algorithms in classification tasks is usually assessed by precision, recall, or F1 score in binary problems, and accuracy in multiclass problems.</p>
        <p>Table 2 displays the confusion matrix of binary classification problems. Precision is defined as ğ‘‡ğ‘‡ğ‘‡ğ‘‡ ğ‘‡ğ‘‡ğ‘‡ğ‘‡+ğ¹ğ¹ğ‘‡ğ‘‡ and represents the ability of a model to identify only the relevant instances, whereas recall is defined as ğ‘‡ğ‘‡ğ‘‡ğ‘‡ ğ‘‡ğ‘‡ğ‘‡ğ‘‡+ğ¹ğ¹ğ¹ğ¹ and represents the ability of a model to find all the relevant instances. As there is usually a trade-off between precision and recall, F1 score is defined as 2 Ã— ğ‘‡ğ‘‡ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘›ğ‘›Ã—ğ‘…ğ‘…ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘… ğ‘‡ğ‘‡ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘›ğ‘›+ğ‘…ğ‘…ğ‘ƒğ‘ƒğ‘ƒğ‘ƒğ‘…ğ‘…ğ‘…ğ‘…ğ‘…ğ‘… and represents the overall performance of a model. The range of F1 score is from 0 to 1, and the larger the F1 score, the better the performance. Accuracy is defined as the total number of correct predictions over all predictions, or ğ‘‡ğ‘‡ğ‘‡ğ‘‡+ğ‘‡ğ‘‡ğ¹ğ¹ ğ‘‡ğ‘‡ğ‘‡ğ‘‡+ğ‘‡ğ‘‡ğ¹ğ¹+ğ¹ğ¹ğ‘‡ğ‘‡+ğ¹ğ¹ğ¹ğ¹ in binary problems, but it may not be appropriate in binary problems when the number of positive and negative samples is imbalanced.</p>
        <p>Table 3 shows recent classification applications along with the ML models in AM field. Typical ML algorithms for classification tasks are decision trees (DT), support vector machines (SVM), and convolutional neural networks (CNN).</p>
        <p>Decision trees [53] are a type of common ML algorithm for classification tasks. Compared with NN, decision trees are more interpretable. Khanzadeh et al. [44] and Tootooni et al. [45] applied multiple ML models including DT for defect detection and quality assessment, respectively. In both articles, DT shows medium performance among many classifiers. Overall, DT is a relatively simple method and is capable of dealing with classification tasks in AM field. Though it may not perform the best, it is recommended as a contrast when applying other models to better show the performance of other models. Support vector machine is designed to deal with binary classification problems [54], but it can also be generalized to multiclass problems [55]. In binary problems, as each input-output pair in training set consists of a high dimensional input vector containing all input features and a target category as output, SVM uses a hyperplane in the high dimensional space to partition the two groups. According to Table 3, SVM is a very popular classifier in AM applications. In the comparison of multiple classifiers [44,45], SVM shows comparable performance with other algorithms.</p>
        <p>While SVM is good at handling inputs consist of only parameters or classes, it can also be applied in image-based problems. Figure 8 [44] demonstrates a procedure using images as input for defect detection of Ti-6Al-4V in L-PBF process. For each thermal image labeled with either porous or not porous, some geometric features are extracted from the image and used to train the ML models. Zhang et al. [40] applied SVM for defect detection using in situ images as input. In their article, though CNN performs better (92.8% accuracy), SVM shows 90.1% accuracy in this three-group classification task. Ye et al. [47] applied SVM for defect detection using AE as input, which also requires a feature extraction procedure like images. In this binary classification problem, SVM (98.01% accuracy) outperformed the deep belief network (95.87%). Gobert et al. [50] applied SVM for defect detection using CT image layers as input, and the F1 score (refer to Section 2.2.2) of their optimized SVM model is 0.62. Overall, SVM is a great alternative in classification problems. 20 Figure 8. The procedure from thermal images (input) to porosity predictions (output) of Ti-6Al-4V in L-PBF process. Some geometric features are extracted from the thermal images to train the ML models, which can then classify whether the printed product is porous (abnormal) or not (normal). Reprinted with permission from reference [44].</p>
        <p>Neural network tends to be the most popular algorithm in classification problems. While normal NN is usually applied in problems with input consists of only parameters and classes, a special type of NN, known as convolutional neural network (CNN), is designed to handle problems with images and AE [56]. Scime et al. [41,42] applied mutli-scale CNN for defect detection using in situ images and the overall, anomaly detection, and anomaly differentiation accuracies are 97%, 85%, and 93%, respectively. The multi-scale CNN they implemented is demonstrated in Figure 21 9. The information of images is propagated in the NN using convolution. Shen et al. [48] applied CNN for geometric error compensation using voxel grid as geometric input feature and got an overall F1 score (refer to Section 2.2.1) of 0.95. Overall, NN is a complex but strong model among the existing algorithms for classification tasks in AM field. NN is applicable in most classification tasks.</p>
        <p>ML models learn knowledge from training data, and then use the knowledge to make predictions.</p>
        <p>Therefore, if the training data is used for testing the performance of ML models, the models tend to make perfect predictions in these training data, which seems good but may trap in the overfitting issue. Figure 10 demonstrates an example of this situation in melt pool depth predictions using GP in L-PBF process. It reflects the fact that validation should never be done with the training dataset. Another example of this situation is the 100% F1 score of NN in Ref. [45]. Overfitting is a phenomenon that the model adjusts itself to fit the training dataset too exactly. In other words, with decreasing training error, the prediction error for future observations tends to increase. This is a common issue in supervised learning and should be avoided by some means.</p>
        <p>Three popular methods to help detect and avoid the overfitting issue in AM field are the hold-out method, the k-fold cross-validation method, and the regularization method.</p>
        <p>The hold-out method, also known as data splitting, is a simple method to monitor overfitting. It partitions the whole dataset into two subsets, training set and testing set. The training set is used to train the model and the testing set is used to test the performance of the model. By this means, data in the testing set will not be used to train the model and is useful to test the performance of the model and whether overfitting occurs. An appropriate size of the training set is usually around 70% of the whole dataset. However, this method has a main drawback: it will further reduce the size of the training dataset when initially the number of data points is limited, which is the common situation in additive manufacturing as the cost, consumed time, and human labor to obtain each data point is usually high. This method is commonly applied in most of the applications mentioned above.</p>
        <p>The k-fold cross-validation (CV) method is an iterative procedure which can monitor the overfitting issue and enhance the utilization of data. It partitions the whole dataset into k subsets of roughly same size. In each iteration, one subset is left out as the testing set and all other subsets are used to train the model. The iteration is repeated until all subsets have been left out once. A special case of this method is ğ‘˜ğ‘˜ = ğ‘›ğ‘›, ğ‘›ğ‘› being the number of data points, which is also called n-fold cross-validation method or leave-one-out cross-validation (LOOCV). Compared with the simple hold-out method, the CV method alleviates the common issue of the limited size of dataset in AM field.</p>
        <p>The regularization method is a process which discourages the ML model to become too complex by adding information during training [57,58]. In general, the goal of a ML model is to minimize the loss function:</p>
        <p>where ğ¸ğ¸ is the accumulative error, ğ‘šğ‘š is the number of training data points, and ğ¸ğ¸ ğ‘˜ğ‘˜ is the error at each training data point. However, if noise exists in the training data, the ML model will also learn the noise using Eq. ( 1) and tend to overfit. To avoid this situation, the regularization method adds a term to the loss function, to penalize the complexity of the model. A commonly used regularization method is called ğ¿ğ¿ 2 regularization [59], which encourages the sum of the squares of the parameters to be small. For example, the loss function using ğ¿ğ¿ 2 regularization for neural network is:</p>
        <p>where ğœ†ğœ† ğœ–ğœ– (0, 1) is the tuning parameter that determines how much penalty is added to the model complexity, and ğ‘¤ğ‘¤ ğ‘ƒğ‘ƒ is the weight of each neuron. The tuning parameter should be carefully selected and is usually estimated by cross-validation [57,58].</p>
        <p>Many algorithms, due to their learning mechanisms or strong learning ability, tend to overfit the training data. For instance, a characteristic of GP is that it will pass through all training points in regression tasks (Figure 10). For another instance, Hornik et al. [60] has shown that multilayer feedforward NN can approximate any function to any desired degree of accuracy, provided sufficiently many hidden units are available. Such strong learning ability of NN makes it likely overfit. To counter overfitting, many applications using above methods are reported in literature, such as the 10-fold [14] and n-fold cross-validation method for GP [16,24,61], and L2 regularization for NN [35]. Some algorithms also have their own methods against overfitting, such as the dropout method [62] for NN. Overall, the applications of one or more methods to monitor and avoid overfitting issue is necessary to make the ML model robust.</p>
        <p>In unsupervised learning, all data are not labeled with an output. The most common task in unsupervised learning is clustering analysis, in which the data are separated into groups based on their similarity. Another main type of unsupervised learning is principal component analysis (PCA), which converts a dataset with possibly correlated variables into a set of values of linearly uncorrelated variables called principal components by orthogonal transformation.</p>
        <p>In clustering analysis, all data are separated into groups based on their similarity. In general, a clustering analysis usually requires a large dataset size. However, the dataset size in AM field is usually limited, which impedes the application of clustering analysis. Therefore, only a few applications of clustering analysis in AM are reported recently.</p>
        <p>In the cost estimation framework proposed by Chan et al., the ML models applied are the least absolute selection and shrinkage operator (LASSO) and elastic net (EN) models. Another typical ML model for clustering analysis is the self-organizing map (SOM), which is a type of NN for unsupervised learning. Recently, an application for geometric accuracy analysis using 
            <rs type="software">SOM</rs> by Khanzadeh et al. [63] is reported. Using 
            <rs type="software">SOM</rs>, millions of data of geometric deviation are separated into clusters, and the overall geometric accuracy of the part fabricated using each combination of processing parameters can then be assessed: the more clusters that appear, the more types of deviations in terms of direction and magnitude it has. It should be noted that the same dataset in Ref. [63] is also used in Ref. [45] for quality assessment using supervised learning. This reveals that one dataset can have multiple applications in machine learning.
        </p>
        <p>Sometimes the number of features in a dataset is very large, especially when the input data type is image. In this case, to avoid the problem being too complicated, PCA is usually applied as a data pre-processing tool in AM to reduce the number of features so as to simplify the data.</p>
        <p>Khanzadeh et al. [44] applied PCA to simplify the features from melt pool characteristics and finally obtained nine principal components that account for almost 99.52% of variation in the data. Yang et al. [66] also demonstrates how to extract geometric features for energy consumption estimation in mask image projection stereolithography using PCA. In an application using in situ images as input data [40], the PCA increases the accuracy of SVM from 89.6% to 90.1% using 33 input features extracted from the image. However, in their 17-feature case, PCA is reported to weaken the performance of SVM, which indicate that PCA may also have negative effects on the performance of the coupled model, since too many features are eliminated and too much information is lost. Overall, when dealing with image-based problems, PCA is a great alternative to simplify the data.</p>
        <p>In this review article, the latest applications of ML in AM field are reviewed in terms of the type of learning tasks: supervised learning and unsupervised learning. For each specific types of tasks, including regression, classification, clustering and PCA, the corresponding applications and some popular algorithms are discussed, and the performance of some popular algorithms are assessed. The following is the recommended future research directions:</p>
        <p>â€¢ While ML has been developing for several decades, the applications of ML in AM field have only been discovered for several years. These applications span processing parameters optimization, property prediction, defect detection, geometric deviation control, quality prediction and assessment, etc. Firstly, ML models can learn the relevance between the processing parameters and property using existing data, so as to provide guidance of optimizing these processing parameters. Secondly, ML models can predict the geometric deviation based on the designed geometry after training and provide guidance of geometric error compensation. Thirdly, ML models are good at dealing with in situ images and acoustic emission during printing and detecting defect formation in real time. However, the available data that can be extracted from the processing parameter-process-microstructure-property map have not been fully utilized. In this regard, exploiting more data acquisition methods, exploring more ML applications and developing better algorithms will be the main research directions in this infancy research field.</p>
        <p>â€¢ A missing but useful functionality in supervised learning in recent literature is active learning. In AM field, labelling the output of each input data point is usually expensive in terms of the consumed time, cost and human labor, because it requires conducting an experiment or a simulation at each input setting to make this observation. Active learning is a method that can alleviate this issue. In recent literature, the common procedure in ML models is acquiring enough input-output pairs first and then using them to train ML models without further query of labelling new data. On the contrary, the procedure in active learning is that the ML models can make query interactively for labelling new data during training so as to maximize its performance. By this means, the ML models may use fewer data points to achieve better performance. Therefore, active learning is strongly recommended in the case that a dataset to be used to train the ML model has not been acquired.</p>
        <p>â€¢ Another potential research field is the uncertainty quantification (UQ), which is critical for a robust design. The uncertainty in AM field has been reviewed in Ref. [15]. In regression tasks, ML models like GP provide not only the mean value at a certain input as the prediction of its output, but also standard deviation which represents the uncertainty at that point. Also, in classification tasks, ML models will also provide confidence when they make a classification. These uncertainties are part of the epistemic uncertainty and have not been utilized in recent literature. In addition, a typical UQ procedure [67] may require hundreds of data points, which is impractical to obtain from experiments or simulations. In this regard, a ML-based surrogate model is very helpful in obtaining the required data and increasing the efficiency of the UQ procedure. Overall, UQ in ML applications in AM field is a good research direction that has not been investigated in depth.</p>
        <p>The work is conducted under CCDC Army Research Laboratory Cooperative Research and Development Agreement 19-013-001. This work is partially supported by "Human Resources Program in Energy Technology (No. 20194030202450)", "Power Generation &amp; Electricity Delivery grant (No. 20193310100030)" of the Korea Institute of Energy Technology Evaluation and Planning (KETEP), Republic of Korea.</p>
    </text>
</tei>
