<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:38+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>High impedance faults caused by vegetation are difficult to detect when covered conductors in medium voltage overhead power lines are used. Long-term contact of XLPE insulation with vegetation causes partial discharges (PDs) which damage the insulation. Although a cheap and easy to install, contactless detection method was developed using an antenna, there is a lack of classification algorithms for this method. Only two custom machine learning algorithms have been tested so far, and both rendered unsatisfactory results for the real application. This work investigates the use of neural network algorithms for this problem and the application of heterogeneous stacking ensembles using neural networks. We used real data collected from a number of detection stations in the Czech Republic. Also, we limited ourselves to supporting edge computing using devices such as Edge TPU. We propose the application of a heterogeneous stacking ensemble neural network to classify PDs obtained by the contactless method. The algorithm we propose is based on a stacking ensemble with a novel combination of base learners, and the Wide and Deep neural network is used as a meta-learner. We compared the results of our algorithm with other algorithms designated for time series classification. Also, an ablation study of the ensemble was conducted, and satisfactory results were obtained using the proposed algorithm. The ensemble outperformed all algorithms tested and is usable on the edge using AI HW accelerator as the ensemble is only feedforward and contains only well-used and known layers. This research improves our understanding of the classification of PDs using the contactless PD detection method and also introduces a stacking ensemble of convolutional neural network and autoencoders for a time series classification for the first time.</p>
        <p>Worldwide, medium voltage overhead power lines have been used without external insulation and equipped with aluminum-conductor steel reinforced cables (ACSR), but these cannot withstand contact with grounded objects. Covered conductors (CCs) are designed to withstand contact with grounded objects, for example, a fallen tree on the line, without immediate power supply interruption (Pakonen, 2007). CCs have an aluminum core covered with a thin layer of cross-linked polyethylene (XLPE) insulation material for high reliability (Dabbak, Illias, Chin, &amp; Tunio, 2015). However, even covered conductors cannot prevent all faults, and high impedance faults are common in medium voltage overhead power lines (22 kV) (Voldhaug &amp; Robertson, 1995).</p>
        <p>In forested areas, where clearance areas cannot be maintained, such as natural parks or mountain ranges, faults occur as a result of contact with surrounding vegetation (Leskinen, 2004). These faults grid operators in the Czech Republic and Slovakia (Mis√°k, Fulnecek, Vantuch, Buri√°nek, &amp; Jezowicz, 2017). Misak, Fulnecek, Jezowicz, Vantuch, and Burianek (2017) proposed an alternative contactless method with data acquisition using an antenna. The acquired antenna signal is very noisy and lacks information on phases and low-frequency component, which has been the cornerstone of one of the best-performing classification algorithms for the galvanic contact method by Kratky et al. (2018). Using an antenna, the price is significantly lower and can be installed without shutting down the power line. The types of discharges commonly found on high voltage distribution lines were tested. These were surface PDs on the conductor (surface discharge), corona discharge, other types of discharges on other distribution line equipment (e.g. recloser-gap discharge).</p>
        <p>PD's activity creates a typical pattern in the electromagnetic field surrounding the CCs and the antenna should capture all PDs such as inner, outer or surface ones (Misak, Kratky, &amp; Prokop, 2016). This pattern can be measured with an antenna, as was done in previous works of Misak et al. (2017) and Martinovic and Fulnecek (2021). The disadvantages of the contactless method are a shorter detection range and a much greater ratio of noise to information.</p>
        <p>Only two classification algorithms were published (Fulnecek &amp; Misak, 2021;Martinovic &amp; Fulnecek, 2021) for this contactless method, and their results are not satisfactory enough to justify the use of the contactless method in the real environment. To be specific, Fulnecek and Misak (2021) proposed a simple classification algorithm based on handcrafted features, which is far from perfect. The second classification algorithm was based on machine learning with gradient boosting and detection of outliers with 87.52% precision (Martinovic &amp; Fulnecek, 2021). However, it used a very reduced dataset as many data points had been excluded because they contained too much noise.</p>
        <p>Although the ENET Centre has deployed the contactless method in the real environment for experimental purposes, the method cannot be used globally in the real environment until the precision and detection performance are satisfactory. We believe that deep learning algorithms could improve detection performance and robustness using the contactless antenna PDs detection method, but none of these algorithms have been tested so far.</p>
        <p>This work investigates the application of modern deep learning algorithms and compares them with various machine learning algorithms. In addition, this study explores for the first time the application of stacking a heterogeneous ensemble neural network on PDs classification for detection using antenna in overhead power lines. We examine whether the weak learning ensemble consisting of autoencoders and 1D-CNN networks has its benefits. Ensemble with a novel combination of convolution neural networks based on one-dimensional convolution layers and autoencoders was proposed. This work describes the design of that ensemble, as we limit ourselves to feedforward neural networks without any unusual changes to support edge neural network accelerators such as Edge TPU, NVIDIA Jetson Nano, or Intel Neural Compute Stick 2. This research could enable a better and cheaper classification of PDs in CCs.</p>
        <p>The whole proposed novel algorithm is designed to run on edge hardware neural network accelerators, as detection stations are usually in forested or mountainous areas and without good connectivity (Martinovic &amp; Fulnecek, 2021). Another benefit of using neural network accelerators is power efficiency, because it is better to be battery powered, as connecting to the power line means shutting down the power line. Also, connecting to a medium voltage power line means that high voltage power supply components for the power supply would be needed in the final design of the detection device, which increases the system costs.</p>
        <p>Additionally, we propose data augmentation for datasets with downsampling using max-pooling and a custom application of a method for denoising data with low computing cost. The tuning of hyperparameters is used for parts of the final design of the proposed architecture. We tested the final architecture on two datasets. The smaller dataset was already used in previous work by Martinovic and Fulnecek (2021), which excluded noisy data, artificially increasing the sensitivity of the algorithms in their results. In this study, we include noisy data. The second dataset is ten times larger and obtains data from more detection stations than the first. We compare the results of our proposed algorithm with the previous algorithm for the classification of the study by Martinovic and Fulnecek (2021) and with various machine learning algorithms. We also investigated whether pre-training on a larger dataset and fine tuning on a smaller dataset yielded interesting results. Next, we performed an ablation study of the proposed stacking ensemble to separately analyze the contribution of each part of the ensemble and influence of inputs or choice of meta-learner.</p>
        <p>The main contributions of this paper are as follows:</p>
        <p>‚Ä¢ We investigate deep learning and machine learning application to detect PDs in signals acquired using a PDs detection contactless method ‚Ä¢ We show that stacking ensemble is a viable option, which outperforms other algorithms on a new dataset from the real environment gathered from several different locations ‚Ä¢ The stacking heterogeneous ensemble has a unique and novel combination of autoencoders and 1D-CNN, and the ablation study indicates its usefulness ‚Ä¢ The designed algorithm is compatible with edge devices like Edge TPU. This could enable cheaper and more accessible monitoring of CCs in medium-voltage overhead power lines.</p>
        <p>The comprehensive review by Lu, Chai, Sahoo, and Phung (2020) reports a number of classifications based on neural networks (NN) and deep learning with great precision and good robustness if trained properly on a suitable dataset. For example, Gao, Zhu, Cai, and Zhang (2020) demonstrated that one-dimensional convolution neural networks (1D-CNN) are successful with UHF sensors and the classification was robust. A study by Che, Wen, Li, Peng, and Chen (2019) applied 2D CNN to images using optical fiber. Furthermore, LSTM-based neural network was used to classify overhead power lines using the galvanic contact method (Dong &amp; Sun, 2020). In a study by Woon, Aung, and El-Hag (2018), a one-dimensional convolutional neural network was used to monitor the insulation of a transformer. Autoencoders were used for partial discharge recognition in several studies, such as Ganjun et al. (2018), Tang, Jin, Zeng, Zhang, andHuang (2017), Zemouri et al. (2020).</p>
        <p>An interpretable model was proposed in the work of Michau, Hsu, and Fink (2021), where a temporal 1D-CNN was used on the contact galvanic method for overhead power lines. As for more recent studies on PDs, one focuses on federated learning (Wang, Yan, Jing, Wang, &amp; Geng, 2022), and another proposes a noise-invariant partial discharge classification based on a convolutional neural network (Raymond, Xin, Kin, &amp; Illias, 2021). There is also work on the 1D CNN-LSTM model (Liu, Yan, Wang, Xu, &amp; Zhao, 2021).</p>
        <p>The approach using an ensemble of classical machine learning algorithms has already been studied (Stefenon et al., 2021;Wang &amp; Han, 2020;Wang, Wu, Sim, &amp; Hwangbo, 2017). The benefit of this approach is that deep learning algorithms should perform better when learning from a large amount of data (Figueroa, Zeng-Treitler, Kandula, &amp; Ngo, 2012;Hestness et al., 2017). None of these algorithms has been applied to the contactless antenna detection method.</p>
        <p>There are many successful machine learning algorithms that are not based on neural networks (Supervised Time Series Forest (Cabello, Naghizade, Qi, &amp; Kulik, 2020), Random Interval Spectral Ensemble (Lines, Taylor, &amp; Bagnall, 2018)). The best example is the algorithm 
            <rs type="software">HIVE-COTE</rs> 2.
            <rs type="version">0</rs> of Middlehurst et al. (2021) used for the classification of time series. Their algorithm ensembles multiple best performing machine learning algorithms such as Temporal Dictionary Ensemble and others, and so far it has been the best-performing time series classifier. The great disadvantage of that algorithm is the training time which is enormous, and it is not parallelizable on GPUs.
        </p>
        <p>Homogeneous stacking ensemble neural networks were tested with successful results in various disciplines from medicine (Alzheimer's disease research (Ahmed, Kim, Lee, Jung, &amp; for the Alzheimer's Disease Neuroimaging Initiative, 2020;Giovannetti et al., 2021;Logan et al., 2021)), machine translation (Shazeer et al., 2017), finance (Yu, Lai, &amp; Wang, 2008) to others (Li, Yao et al., 2018;Poloni &amp; Ferrari, 2022). For anomaly detection, another ensemble of multiple types of autoencoders was proposed by Liao, Teo, Pratim Kundu, and Truong-Huu (2021). Most of the cited papers use voting or non-neural network-based machine learning algorithms such as SVM or random forest.</p>
        <p>The use of multiple CNNs ensemble is commonly used in many studies (Asif &amp; Trivedi, 2020;Sikakollu &amp; Dash, 2021;Zhao, Liu, Yin, &amp; Wang, 2022). In addition, a heterogeneous combination of deep learning in the ensemble is used in many recent articles (Dey, Bhattacharya, Malakar, Schwenker, &amp; Sarkar, 2022;Mishra, Naik, Dash, &amp; Nayak, 2021;Zicari, Folino, Guarascio, &amp; Pontieri, 2022) although most of them did not use a neural network as a meta-learner. In the article from Zian, Kareem, and Varathan (2021) it is shown that the ensemble is suitable for imbalanced datasets. The heterogeneous ensemble RGVF-HeteroESM-Net was proposed, which combines three pretrained CNN networks (VGG-19, GoogleLeNet and Resnet) with a random forest as base learner.</p>
        <p>Our proposed method contains a novel combination of an autoencoder and a 1D-CNN, which was not done before to our knowledge and was not included in the recent review of Dong, Yu, Cao, Shi, and Ma (2019), Ganaie, Hu, Malik, Tanveer, and Suganthan (2021). An algorithm proposed by Cao et al. (2021) used only autoencoders or an algorithm by Williams and Li (2018) used only CNNs for image classification.</p>
        <p>The meta-learner of the ensemble network is based on Google's Wide and Deep neural network (Cheng et al., 2016), which is also unusual for ensemble networks, but we show that this network has its benefits compared to other machine learning algorithms. The architecture of the convolution neural network is based on a ResNet-like (He, Zhang, Ren, &amp; Sun, 2016) architecture with convolution, pooling, skip connection, and batch normalization layers followed by two fully connected layers.</p>
        <p>Data for both datasets were acquired from detection stations in the real environment, in forested or difficult terrain. The detection stations were designed primarily for the detection of partial discharges using the galvanic contact method (Misak &amp; Pokorny, 2015). These detection stations monitor various overhead medium voltage power lines with covered conductors in Czechia and Slovakia. Subsequently, the contactless method was also deployed at the detection stations, thanks to an additional input for the DAQ card (a case and a device can be seen in Fig. 1).</p>
        <p>An active omnidirectional BONI whip antenna (manufactured by the Bonito Dennis Walter company) was added to these stations to support the contactless detection of PDs, as can be seen in Fig. 2. BONI whip antenna has a frequency range of 20 kHz to 300 MHz, but the data are sampled only up to 20 MHz. The antenna is 17 cm long and its gain is 3 dB. The antenna voltage supply is 14V-15V, IP3 is +32.5 dBm, and IP2 is +55 dBm.</p>
        <p>The galvanic method was used to label the results of the contactless method, since they share the same stations, and in theory, both methods should be able to detect the same PDs, although the contactless method has a smaller detection range.</p>
        <p>The sensitivity of the antenna varies in real environments because the value depends on the parameters of the power line and there is no possibility of performing an on-site calibration. This is because the operators of the distribution grid would not allow the entire power grid to be shut down, which is necessary for calibration or sensitivity estimation.</p>
        <p>The wireless antenna method captures not only the electromagnetic signal from the covered conductors, but also a large amount of noise artifacts, mostly from the AM radio and other discrete spectral resistance (Fulnecek &amp; Misak, 2021). Noise usually hides a substantial part of the signal from covered conductors as the highest frequency received is captured, creating a very noisy series. Also, the body of a signal changes its properties over time, for example, its magnitude. Due to this, we cannot set a single hard threshold for noise and partial discharges. A signal was measured by the 8-bit analog-to-digital converter (ADC), which returns values in the range from -128 to 127.</p>
        <p>The first dataset, dataset A, was relatively small, as it contains only 1,926 acquired signals and the dataset was highly imbalanced. It had 189 series containing PDs and 1,737 series are without PDs. One series consisted of 800,000 observations, which presents one full period (20 ms as the system frequency is 50 Hz). An observation is represented by a signed byte. All signals from dataset A were validated by an expert. Experts validated the series by comparing the PDs detected by the contact galvanic method and confirmed that PDs are also recognizable in the acquired data from the contactless method. The dataset A contains measurements from 4 different stations in the Czech Republic (two in mountains and two in a national park in Czechia, and each of them is on a different power line).</p>
        <p>The second dataset, dataset B is newer and is ten times larger. It contains data from 18 stations in the Czech Republic. They are located in various national parks and mountain ranges, and no station is in a short distance from another. The dataset B is similarly imbalanced as the first dataset A. The larger dataset B contains only 3,992 series with partial discharge and 13,767 series without partial discharge. The difference from the previous dataset A is that no manual validation was performed by an expert in the field and the labels were taken directly from the galvanic contact method.</p>
        <p>Both datasets contain a large amount of noise, as they contain a series with other types of discharge, such as corona discharge or rime on covered conductors. Noise also depends on the sunset and dawn or weather conditions (Misak et al., 2017).</p>
        <p>We were not successful in applying a single 1D-CNN network or autoencoder. The sensitivity of the autoencoders was too low, unable to recognize enough anomalies (PD patterns). However, 1D-CNN networks did not have sufficient precision, and the false positive rate was too high. Because of that, we propose an algorithm based on an ensemble stacking neural network using deep learning with an ensemble of 1D-CNN and autoencoders, which combines high precision autoencoders with low sensitivity and low precision 1D-CNN with high sensitivity.</p>
        <p>The algorithm training pipeline consists of four phases, as can be seen in Fig. 3 preprocessing data, data augmentation, application of standalone neural networks, and finally use of meta-learner.</p>
        <p>All series were reinterpreted as signed bytes, because the data was originally kept as unsigned bytes. Data preprocessing started with duplication of each series. From one duplicate of a series, a mean of the absolute value of observations of a given series was subtracted or added to each observation depending on the positivity of that single observation point (for positive mean, it was subtracted, and for negative mean, it was added). Subtracting means was done as a simple way to remove constant noise, as can be seen in Fig. 4 and to create different features for one part of the ensemble. The second series was kept as is.</p>
        <p>The next step was custom denoising based on the uniqueness of the observations. All signals contained a large amount of noise. Some of the noise was white noise, which has a normal distribution. We mainly looked for peaks in the signal that are anomalies or extremes that could indicate PDs. The idea of this denoising filter was that most of the signal is Gaussian noise and partial discharges are characterized by peaks in the signal (Misak et al., 2017).</p>
        <p>We reduced that noise in such a way that we first substantially decreased observations in a given series based on the incidence of value in the series. This step was done because partial discharges should be an anomaly in the data series. We used Eq. ( 1) for each observation point.</p>
        <p>Where ùë• is a single observation multiplied by the count of given observation value in a given series divided by the length of the series raised to the power of constant ùëß. ùëô is a count in the largest observation group. The constant ùëß was a factor of decrease for non-unique observations. An example of a denoised signal is shown in Fig. 5. We had empirically validated this approach by comparing galvanic contact data with processed data from the contactless antenna method, where we focused on highlighting peaks in the signal.</p>
        <p>As one series consists of 800,000 observations, which takes a large amount of memory (we had to keep the sampling rate as reducing the sample rate would also reduce the amplitude of PD peaks, making them harder to detect), max-pooling was applied. Our proposed max-pooling takes the biggest absolute value of observations in a given window. This step also allowed us to submit data to an HW accelerator, such as Edge TPU (Google, 2022), and significantly reduced training time.</p>
        <p>After data pre-processing, two small denoised series were created from one raw series. The preprocessed data was then passed on to neural networks. All operations proposed in the preprocessing stage were designed to be low computational complexity (the computational complexity is ùëÇ(ùëõ)) and should be easily optimizable.</p>
        <p>From our observation factor, the constant ùëß was chosen as 500. The max-pooling window was chosen to be 512 observations as the denoised signal is relatively sparse and from testing no important peaks or clusters were lost in pooling. Also, the difference in results for testing when using pooling of 32 observations and 512 was nonexistent, but the speed of training increased substantially and the size of input is also important for HW NN accelerators.</p>
        <p>Both datasets were imbalanced, and the first was relatively small. Thus, data augmentation was applied, as it should improve training (Wen et al., 2021). As the signal from the series does not have a precise start, we can augment the data by rolling (elements that roll beyond the last position are reintroduced at the first) the series by a random amount. Rolled series are still valid data series that contain a single signal. With this augmentation, we can expand the training set to reduce positional dependence in training data with series that have partial discharges. Furthermore, this step could serve as an oversampling of positive cases (with PDs), which could help detect the minority class (Hernandez, Carrasco-Ochoa, &amp; Mart√≠nez-Trinidad, 2013).</p>
        <p>Data augmentation using rolling the sample was used for dataset A as a way to oversample positive cases (series with PDs), because dataset A was relatively small and contained a limited number of positive cases. This data augmentation was performed once per single series containing PDs (a positive case) in the training set, and each positive case was rolled by a random amount and added to the training set.</p>
        <p>In particular, we chose to support Edge TPU, which uses only unidirectional layers (no bidirectional LSTM, or recurrent layers) and does not support deconvolution natively (Kist, 2021). On the other hand, Edge TPU was available at the time of the study and is energy efficient with a computational power of 4 TOPS (Yazdanbakhsh, Akin, &amp; Seshadri, 2021). Edge TPU is an HW NN accelerator, where components of each processing engine are a single or multiple core(s), each with multiple compute lanes to perform operations in a SIMD manner. That is ideal for CNNs as they can be easily mapped to the processing engine (Yazdanbakhsh et al., 2021).</p>
        <p>Ensemble learning uses multiple learning algorithms to obtain better results than any constituent alone could provide. The stacking ensemble neural networks is a learning technique that combines predictions from other learning algorithms and trains on those predictions a learning algorithm (also called a meta-learner). The idea in combining 1D-CNN and autoencoders is that autoencoders detect anomalies different from the usual signal and that 1D-CNN could be able to recognize PDs patterns.</p>
        <p>The proposed ensemble stacking neural network consisted of two autoencoders and two 1D-CNN. Each CNN takes a different input to diversify the input features. Both CNNs and autoencoders had preprocessed signal input. In CNN, the output of these networks was for CNN a binary probability of containing PDs in the given signal. For autoencoders it was reconstruction loss (difference between input signal and reconstructed signal). These scalar values were input of the Wide and Deep network.</p>
        <p>One CNN takes the signal, which had subtracted a mean (very computationally cheap operation), and the second one was without subtracted mean. The same inputs were for autoencoders. One autoencoder had an input signal without a subtracted mean and the other had one with a subtracted mean. The result was then calculated by a Wide and Deep neural network.</p>
        <p>The entire network was implemented in the Keras framework (Chollet et al., 2015) using the functional style.</p>
        <p>Properly chosen hyperparameters are important for the successful application of machine learning algorithms (Song, Du, &amp; Jackson, 2019). Hyperparameter tuning is an automated search for the proper hyperparameters (Bergstra, Bardenet, Bengio, &amp; K√©gl, 2011). The neural network was then hyperparameters tuned to minimize validation loss using the Keras tuner (O'Malley et al., 2019). The algorithm used to find parameters was Hyperband, which was a bandit-based approach to hyperparameter optimization published by Li, Jamieson, DeSalvo, Rostamizadeh, and Talwalkar (2018). Hyperparameter tuning was performed on a smaller validated dataset A.</p>
        <p>Part of the proposed ensemble neural network was a 1D convolution neural network consisting of 1D convolution layers. The proposed part was visualized in Fig. 6. 1D convolution layer creates a convolution kernel that was convolved with the layer input over a single temporal dimension to produce a tensor of outputs. An inspiration for CNN's design was the ResNet architecture (He et al., 2016). That leads to the idea of using skip connections to jump over some layers. A reason for using this design is to try to avoid vanishing gradients and mitigate the Degradation problem (Roy, Ghosh, Bhattacharya, &amp; Pal, 2018).</p>
        <p>The architecture consists of ResNet blocks (in Fig. 7), which contains 1D convolution followed by batch normalization and leaky ReLU activation function, which is repeated and the results of the first leaky ReLU and the second are added together. After two ResNet blocks, there are two 1D convolution layers (16 and 24 filter sizes) with a dropout layer (dropout rate 0.15%) in between. After that, the average global pooling is applied and then two fully connected layers are applied. The tuner chose leaky ReLU as well as other parameters like kernel size (chosen was 3), batch normalization, including dropout (0.15) at last layers, or filter size. The output of this network was the probability of category. This probability was passed to meta-learner.</p>
        <p>Another part of the proposed ensemble neural network is an autoencoder. Autoencoders are a type of neural network that is used to learn efficient encoding and decoding of unlabeled data (Bank, Koenigstein, &amp; Giryes, 2020). Encoding is validated and refined by recreating the input from the encoding (decoding). Autoencoder learns a representation for a series, in this case, normal data (without PDs) representation for anomaly detection (Raman, Dong, &amp; Mathur, 2020). Autoencoder can contain the constriction produced by the small layer that represents the relevant information in a low-dimensional space. Bottleneck features are used in autoencoders which can learn the two-way mapping relationships between high-dimensional space and low-dimensional space. The optimization objective of autoencoder is to minimize the reconstruction error of input samples.</p>
        <p>The proposed autoencoders, as can be seen in Fig. 8, consisted of two layers of 1D convolutions on the side of an encoder, and on the side of a decoder 1D deconvolution (transposed convolution) was used. 1D convolutions had filters size of 16 and kernel size 7 with stride 4. Between 1D convolution was dropout (alpha dropout of 1%) to force generalization in data reconstruction and as part of the autoencoder bottleneck. The output of these autoencoders was the mean squared difference between the reconstructed and the original input. As the autoencoder should not learn anomaly features (PDs) (Morawski, Bejger, Cuoco, &amp; Petre, 2021), only the signal without PDs should be reconstructed and the difference between the reconstructed and original signal could mean that the signal contains PDs (Sato et al., 2018). The mean difference between the reconstructed and original signal for each series was then passed to the meta-learner. 1D deconvolution can also be implemented as a transposed convolution or as a split deconvolution (Xu et al., 2019), which can be run on Edge TPU.</p>
        <p>The purpose of meta-learner was to classify whether the series contains PDs or not, depending on inputs from base learners. The metalearner takes scalar values from the base-learners as an input. The input of CNNs was a probability of positive case (containing PDs), and the autoencoders provided as input a difference between a reconstructed and an original signal. The meta-learner was chosen to be designed as a Wide and Deep neural network proposed by Cheng et al. (2016). Wide and Deep neural network combines a deep neural network (for generalization) and a wide linear network (for memorization) to solve generic large-scale regression and classification problems (Cheng et al., 2016) (see Fig. 9).</p>
        <p>For training the ensemble, a binary cross-entropy loss is used in CNNs and Wide and Deep network. For autoencoder, a loss is the mean of squares of errors between labels and predictions. Adam optimizer is used for all neural networks with an initial learning rate of 0.001 for autoencoders and CNN and for Wide and Deep network is 0.01.</p>
        <p>We set an unlimited number of epochs for CNNs and Wide and Deep network as we utilize early stopping. We choose the best model based on validation loss, as we monitor validation loss and used model checkpoint callback from the Keras framework. This callback saves the best model with the monitored metric. Autoencoders were trained for 140 epochs.</p>
        <p>We also reduced the learning rate on the plateau (monitoring value loss) with factor 0.5 and 10 epoch patience and trained each base learner in isolation. Next, results from the base learners are gathered as a training and test set for the meta-learner. We train our ensemble on 4 GPUs NVIDIA 
            <rs type="software">GeForce</rs> GTX 1070.
        </p>
        <p>We also tried to pre-train base learners on the larger unvalidated dataset B and then fine-tune on the smaller dataset A. We ensured that no sample was included in both datasets. In other words, we reuse the weights learned in dataset B and then fine-tune them in dataset A.</p>
        <p>This should improve the performance, as dataset B contains much more different data and also many samples of PDs. Because the pretraining phase provided ample knowledge, the fine-tuning phase allowed models to properly process target tasks in small samples due to the fine-tuning phase. The goal of this pre-training is to show if a larger dataset would help the algorithm perform better and be more stable. This was done in the work of Gao, Kotevska, Sorokine, and Christian (2021), where they pre-train on a very large general biomedical NER corpus and then fine-tune the model on a more specific target. In addition, this is usually done in the biomedical field, as the data is sparse (Han et al., 2021;Zeng et al., 2021).</p>
        <p>For the smaller dataset A, we trained the algorithm on 1540 series, 386 series were used for testing purposes (20%). From the training set, 20% of training data was set aside for validation (Table 1). The results were taken from a randomly initialized cross-validation that was performed 100 times. Cross-validation was performed to test the stability of the model and to simulate unseen observations in the testing. We also evenly stratified (preserved class ratio) series with PDs between sets to eliminate cases where series with PDs would be overrepresented or missing in some sets.</p>
        <p>For a larger invalidated dataset B, random initialization crossvalidation was performed 100 times, as in the case of a smaller expert-validated dataset A. Due to the extensive dataset B, we were able to make the test set larger. The test set contained 6216 series (35%) and training 11543 series with 20% of them were designated as the validation set (2309 series, as can be seen in Table 1). We also stratified the series with PDs evenly between sets.</p>
        <p>Only two previously published algorithms (Fulnecek &amp; Misak, 2021;Martinovic &amp; Fulnecek, 2021) exist for this kind of data and were evaluated only on the smaller validated dataset A. To compare the performance of our proposed algorithm with existing solutions, we classified the larger unvalidated dataset B using three types of algorithms. These were general machine learning classifiers, time series-focused machine learning classifiers, and deep learning-based classifiers. All of these classifiers were evaluated on the same splits as our proposed algorithm, and cross-validation was performed the same times as our proposed algorithm. Most algorithms were unable to learn or even run on raw data. Thus, the data for these classifiers were denoised by our proposed denoise method, as no algorithm gave reasonable results for unprocessed data. If not said otherwise, algorithms were used in the default settings of a given package or library.</p>
        <p>As for general machine learning classifiers, we choose algorithms from package 
            <rs type="software">scikit-learn</rs> (Pedregosa et al., 2011) and libraries 
            <rs type="software">Light-GBM</rs> (Ke et al., 2017) and 
            <rs type="software">XGBoost</rs> (Chen &amp; Guestrin, 2016). From package 
            <rs type="software">scikit-learn</rs> we applied C-Support Vector Classification (SVC), Decision Tree Classifier (DTC), Gradient Boosting Classifier (GBC), and Random Forest Classifier (RFC). 
            <rs type="software">LightGBM</rs> is a gradient boosting framework that uses tree-based learning algorithms. 
            <rs type="software">XGBoost</rs> library implements parallel machine learning algorithms under the Gradient Boosting framework.
        </p>
        <p>For time series-focused classifiers, we used algorithms from library 
            <rs type="software">sktime</rs> (L√∂ning et al., 2022). We use a dictionary-based algorithm MUSE (MUltivariate Symbolic Extension), interval-based Time Series Forest classifier (TSF) (Deng, Runger, Tuv, &amp; Vladimir, 2013), Supervised Time Series Forest Classifier (STC) (Cabello et al., 2020), Random Interval Spectral Ensemble (RISE) Lines et al. (2018), Arsenal proposed by Middlehurst et al. (2021). Also, we used library 
            <rs type="software">tsfresh</rs> (fresh stands for FeatuRe Extraction based on Scalable Hypothesis tests), which automatically calculates a large number of time series features, then we applied the Random Forest Classifier (RFC) from package 
            <rs type="software">sklearn</rs>. We tried two variants of 
            <rs type="software">tsfresh</rs>. The first was with full extraction of features, which is relatively slow. The second variant is with parameter EfficientFCParameters. That restricts features to only features which are computation efficient, as full variant computes, for example, sample entropy and approximate entropy.
        </p>
        <p>One of the latest algorithms for time series classification was 
            <rs type="software">MiniRocket</rs> (Dempster, Schmidt, &amp; Webb, 2021) from library tsai (Oguiza, 2020). MiniRocket algorithm and Arsenal are similar, as both use ensembles of 
            <rs type="software">ROCKET</rs> and their advantage is fast training speed. 
            <rs type="software">MiniRocket</rs> can also be trained on GPUs. We also tried distancebased algorithms from the 
            <rs type="software">sktime</rs> library, but without any success, the algorithms were unable to learn or classify when they were tried, and their training time was too high to consider them further. The same applies to the hybrid HIVECOTEV2 algorithm, which was too costly to evaluate and its training time too long. Also, using 
            <rs type="software">HIVECOTEV</rs>2 would be impossible on edge devices.
        </p>
        <p>Deep learning algorithms were taken from the library 
            <rs type="software">tsai</rs> (Oguiza, 2020). The 
            <rs type="software">library</rs> is an open-source deep learning package focused on the state-of-the-art techniques for time-series tasks like classification, regression, forecasting, etc. We choose models from multiple categories to cover most of today's architectures. We started with the simplest Multi-layer Perceptron (MLP). From 1D-CNNs we ran ResNet (He et al., 2016) and newer models such as TCN (Bai, Kolter, &amp; Koltun, 2018), Inception Time (Ismail Fawaz et al., 2020) and Xception Time (Rahimian, Zabihi, Atashzar, Asif, &amp; Mohammadi, 2019). We also tested two recurrent neural networks using 1D convolutions. They were RNN FCN based on recurrent neural network and LSTM FCN based on Long short-term memory. The last deep learning algorithm we tested was multilevel Wavelet Decomposition Network (mWDN) published Wang, Wang, Li, and Wu (2018).
        </p>
        <p>To present and compare the results, we used both datasets. The first dataset A was smaller and was validated by an expert. Using that dataset, A we could compare our results to the previous work of Martinovic and Fulnecek (2021). The second one was a newer and much larger dataset B, as it contained more observations and the observations are taken from more stations. A disadvantage of the second dataset B was that no human validation had been performed. In this way, the dataset B might have been corrupted for various reasons. The results of the second larger dataset B were compared with various time series classification algorithms to compare the performance with existing available solutions.</p>
        <p>To interpret the results, accuracy is not that interesting metric, as the dataset was highly imbalanced. Precision and sensitivity are more interesting, as they show how many series with partial discharges can be detected and how many of them are false positives.</p>
        <p>The interesting metric is the Mathew correlation coefficient (MCC, also known as the phi coefficient) which was used in the Kaggle competition for the galvanic detection of PDs as a score (Kaggle, 2019) and has also been shown to be a statistical rate much more reliable than accuracy or ùêπ 1 (Luque, Carrasco, Mart√≠n, &amp; de las Heras, 2019). The MCC value range is from -1 to 1. Interpretation of MCC is similar to Pearson Correlation Coefficient as MCC is a special case of Pearson Correlation Coefficient. The result of -1 is a total disagreement between prediction and observation. The result of 0 should be for the prediction no better than random, and for the prediction of 1, the results are in perfect agreement with the observations. MCC is defined in Eq. ( 2).</p>
        <p>(2)</p>
        <p>L. Klein et al.</p>
        <p>In Table 2 we present mean cross-validated results for the entire ensemble neural network on the smaller validated dataset A and for each part of the ensemble, which was 1D-CNN and autoencoder.</p>
        <p>Parts of the ensemble network were not sufficient to give reasonable results, as can be seen in Table 2. 1D-CNN had precision only 33.3% and sensitivity 17.5%. The autoencoder had perfect precision, but an abysmal sensitivity of 0.7%. When they were combined to a single ensemble network with a meta-learner on top of them, the results for the ensemble network were substantially better. The mean MCC had increased from 0.150 for 1D-CNN and 0.197 for the autoencoder to a combined 0.584. In addition, the sensitivity was greatly improved.</p>
        <p>As can be seen in Table 3 the best cross-validated ensemble model had MCC 0.645. The worst result from cross-validation was MCC 0.569. The best precision was 72.7% with a sensitivity of 63.2%. The relatively high difference in best and worst results is probably caused by a small dataset A, and some of the series are very noisy.</p>
        <p>In Table 3 it can be shown that even under performing algorithm in terms of precision and sensitivity, it has great accuracy. This is because of the highly imbalanced dataset. Our proposed algorithm performed better on metrics that are suitable for these types of imbalanced dataset, such as F1 or MCC.</p>
        <p>The best algorithm published for contactless classification of partial discharges by Martinovic and Fulnecek (2021) can be seen in Table 3 and had the best MCC 0.642 and the worst 0.488, including excluded data points in the appropriate proportion for the division of the test and training set (inferred from two tables). It is not possible to directly compare the mean results of Martinovic's algorithm, as in his work some of the series were excluded for containing too much noise, and the results are calculated without these excluded series.</p>
        <p>The algorithm of Martinovic and Fulnecek (2021) had better precision than our algorithm presented. For the worst case, it was 66.6% for Martinovic's algorithm and 45.6% for our proposed algorithm, and for the best case, it was 100.0% compared to 72.2% for proposed algorithm. However, our proposed algorithm had better sensitivity and, most importantly, overall MCC for the best and worst results. Precision could be improved by increasing the threshold for binary cross-entropy when predicting on a test set, as binary cross-entropy is a probabilistic loss metric and it is possible to set a threshold for more precise results.</p>
        <p>Martinovic's algorithm is designed for low computation costs. Our proposed algorithm is computationally demanding, but could be easily overcome using HW accelerators. Preprocessing is very similar in computational cost, but predicting using a neural network is costly. This could be easily alleviated using HW accelerators such as Edge TPU, which can process 4 TOPS/s and their consumption is much lower than conventional CPU. All parts of the proposed neural network can run on these kinds of HW accelerators because CNN networks, multi-layer perceptrons and autoencoders are supported.</p>
        <p>We performed the test, where we pretrained the base learners on the larger dataset B and then the algorithm was fine-tuned and trained on the smaller dataset A. The meta-learner was trained only on the smaller dataset A.</p>
        <p>The performance of the ensemble increased noticeably (Table 4), but the sensitivity was slightly lower. This shows that pre-training whenever possible could bring performance improvements. Also, we could train neural networks on a larger dataset and then fine-tune or train online on a given specific detection station. This highlights the importance of enough data for training neural networks and could indicate that when we acquire more data, the ensemble would perform much better.</p>
        <p>Results for the larger dataset B were only slightly worse (mean MCC 0.523) than the results for the dataset A (mean MCC 0.584), when we consider that the dataset B was not validated. This confirmed that the proposed model could be robust and could learn from more data accurately even when it contains more data from various locations with variable noise background and power line parameters.</p>
        <p>As the larger dataset B had more series with PDs, the accuracy was lower, as can be seen in Table 5. The precision increased with comparison to the results for the smaller dataset A. However, the sensitivity decreased noticeably (from 68.4% to 52.3%). The MCC also decreased slightly from a mean value of 0.584 to 0.523. In addition, the stability of the algorithm is much better, which could confirm that our algorithm performs quite well on larger datasets.</p>
        <p>The suspected reason for the drop in sensitivity and subsequently in MCC is that there is no validation from an expert and only labels inferred from contact galvanic methods (using state of the art algorithm used in a production environment) is used. As such, the galvanic contact method has a wider detection range and can classify PDs, which are not even captured in the signal acquired by the contactless method. Additionally, some of the data from the contactless method could be corrupted as no supervision on them was performed.</p>
        <p>Another possible reason for the drop in MCC and sensitivity is that because the data are from various stations and much more diverse, the proposed network cannot handle all variants. Furthermore, the percentage difference in the size of the split of the dataset (the larger L. Klein et al. dataset B has the size of the test split 35% of the dataset B and the smaller one A only 20%) could explain some of the differences in the results. As 1D-CNN were hyper-parameter tuned for smaller datasets A, it is very likely that when tuning for the larger dataset B would be done, then sensitivity and MCC should increase accordingly. However, our results indicate that our proposed model is capable of learning from a much more diverse and larger dataset.</p>
        <p>As can be seen in Table 6, conventional machine learning algorithms were not very successful in the classification of partial discharges using the contactless method. The best performing algorithm from this group was the XGB from the library 
            <rs type="software">XGBoost</rs>, which was very dependent on a number of estimators. With the number of estimators set to 1,000, the classifier had a resulting MCC of 0.308. That was significantly lower than our proposed algorithms. All metrics were lower than our proposed algorithms. The worst classifier was Gradient Boosting Classifier, which was not much better than random. Also, the XGB classifier with only 10 estimators was useless.
        </p>
        <p>The multi-layer perceptron and mWDN were not successful in learning, as can be seen in Table 7. Reasonable results gave a recurrent neural network with 1D convolutions. When RNN was replaced by LSTM, the results were better. The use of the ResNet model gave better sensitivity than the LSTM FCN. TCN and InceptionTime algorithms were similar in their performance. The best performing deep learning algorithm was 
            <rs type="software">XceptionTime</rs>, which had MCC 0.497. Our proposed solution was better in all metrics. In general, most deep learning algorithms, with the exception of MLP and mWDN outperformed machine learning algorithms such as XBG or LGBM. We were surprised with poor results from the mWDN network, as it should be optimal in theory for this kind of data.
        </p>
        <p>MUSE algorithm, which is a dictionary-based algorithm, was the worst in the group of time series-focused algorithms (Table 8). The algorithms that performed better were interval-based algorithms such as STC, TSC, or RISE. From the interval-based algorithms, the TSC in the default settings was the best with an MCC of 0.350. The TSC outperformed the MiniRocket, which had an MCC of 0.416. Arsenal had a similar sensitivity, but Arsenal had better precision, and the MCC was 0.451. The best performing combination of algorithms was feature extraction using the library 
            <rs type="software">tsfresh</rs> with RFC as classifier. This combination was very close to our proposed solution with an MCC of 0.511. This combination was more precise, but the sensitivity was lower. The disadvantage of using tsfresh with RFC is a very high computation cost as it computes a very large number of features and tsfresh decreased that number of features using statistical methods to 205 features. Also, this combination would not be as easily run on edge devices using the hardware neural networks accelerator-based solution. And probably the power consumption would be much higher.
        </p>
        <p>For a larger unvalidated dataset B, our proposed algorithm had the highest mean MCC (0.523). The second was tsfresh with RFC, which is a time-series-focused approach. The third was deep learning algorithm 
            <rs type="software">XceptionTime</rs>, and the fourth was Arsenal. Our deep learning algorithm outperformed all algorithms tested and should be more power efficient than tsfresh with RFC. Tsfresh with RFC computes 205 features, and most of them are computationally expensive. The variant of Tsfresh with RFC restricted only to computation efficient features (Efficient-FCParameters) was slightly less performant, although selected features are still too computationally expensive to compute on edge device.
        </p>
        <p>We performed a two-tailed unpaired t-test to test the hypothesis that our proposed algorithms had better MCC than others. A higher ùë°-value means a greater difference between classes. The result of a lower ùëù-value below 0.05 rejects the null hypothesis, which is that the performance of the algorithm is the same (measured by MCC). First, we ensured that the differences between the two groups were of normal distribution. Then we run the t-test. The results can be seen in Table 9 and were statistically significant, indicating that our proposed algorithm was better than XceptionTime and tsfresh with RFC, as these were the two algorithms that performed the best after our proposed ensemble.</p>
        <p>In this part we analyze the contribution of each part of the ensemble and influence of inputs or choice of meta-learner and base learners. This is done to justify or confirm our choices for the design of the ensemble.</p>
        <p>In the first part of this ablation study, we investigate the influence of meta-learner choice. We compare classical machine learning algorithms and gradient boosting algorithms with multi-layer perceptron (MLP) and our chosen Wide and Deep neural network. The comparison was made in the same terms as the rest of the results and was performed on a smaller validated dataset A (100x cross-validated).</p>
        <p>In Table 10 the results can be seen for various meta-learners. Our proposed Wide and Deep were the best in terms of MCC and the F1 metric, but the results were too similar to the second and third algorithms. We performed a two-tailed unpaired t-test to test the hypothesis that our proposed algorithms had better MCC than others. For RFC and MLP the ùëù-value was greater than 0.05 as can be seen in Table 11. Therefore, we do not reject the null hypothesis of equal population means. We found that the difference in means was not statistically significant. Although our proposed Wide and Deep network is not statistically significantly more performant than RFC and MLP it has certain advantages as is smaller than MLP and can be easily run edge devices such as on Edge TPU, which could be a problem for RFC with 1000 estimators.</p>
        <p>In second part of the ablation study, we focused on base learners. In the first part, we tried 5 different settings from our proposed algorithm. To confirm or reject the idea that the combination of autoencoders and CNNs is useful, we tested two ensembles with only autoencoders and two with only CNNs networks. The last setting was the same ensemble as our proposed, but with twice as many base learners as the proposed one.</p>
        <p>The algorithms with only autoencoders were substantially worse, but had high precision. When we removed the autoencoders from the ensemble, the MCC decreased from 0.584 to 0.541. This indicates that the primary part of the ensemble was CNNs, and autoencoders only help to increase performance.</p>
        <p>Interestingly, the ensemble with four CNNs was highly performant, but slightly worse than ours (see Table 12). As can be seen in Table 14, the difference in the mean MCC is statistically significant. CNNs ensembles are used in multiple works (Asif &amp; Trivedi, 2020;Sikakollu &amp; Dash, 2021;Zhao et al., 2022) and it could be interesting if any CNNs ensemble configuration can outperform the proposed combination of autoencoders and CNNs and if the addition of autoencoders for anomaly detection would increase the performance.</p>
        <p>However, the auto-encoders were roughly half the size CNN networks (see Table 13), so they have a better cost value than using only CNNs. The last configuration was a combination of the previous two models and yielded the best performance in terms of MCC. This configuration should still fit neural network accelerators, and it is possible to add base learners to yield additional performance. Although the gain in performance is rather small, the difference in average MCC is statistically significant using a two-tailed unpaired t-test (Table 14).</p>
        <p>After the influence of the base learners on the ensemble, we tested the influence of inputs on the performance of the ensemble. We tested the ensemble with only denoised input and the ensemble with denoised input and subtracted mean. The results can be seen in Table 15, where the most efficient variation was with a combination of two different inputs.</p>
        <p>The second was the ensemble with the denoised input and the subtracted mean with a statistically significant difference in the mean MCC (see Table 14) from the combination of inputs. Interestingly, the ensemble with input, which was only denoised, was the worst. We think that constant noise could confuse autoencoders or CNNs, or our denoising method could perform better on an input with subtracted mean. However, a combination of these two inputs yields better results with a statistical significance.</p>
        <p>We presented a customized method for contactless detection of PDs on CCs based on a deep learning algorithm using an ensemble stacking neural network using primarily convolution neural networks.</p>
        <p>The algorithm had better results than the proposed Martinovic algorithm (Martinovic &amp; Fulnecek, 2021) and worked on a more noisy dataset, with the potential to perform better as more data are available, as deep learning algorithms should predict more accurately when learning from a large amount of data (Figueroa et al., 2012;Hestness et al., 2017). Furthermore, our proposed algorithm outperformed all algorithms with various mechanisms of work (dictionary-based, deep learning, . . . ) tested on larger dataset. We have shown the influence of the choice of meta-learner and base learners for the ensemble. We verified that deep learning is a viable option for detecting PDs in a signal from the contactless antenna method.</p>
        <p>Our proposed approach is suitable for use with hardware accelerators of neural networks. Using hardware accelerators such as Edge TPU or Jetson Nano, it should be possible to design a low-power and efficient detection system. Hardware accelerators are relatively inexpensive and commercially available. This kind of detection system could then run directly on a detection device that collects data. Some of the preprocessing could also be run on these accelerators with some clever tricks; for example, max-pooling or subtracting a mean should be possible on HW accelerators.</p>
        <p>The detection system with an antenna is cheaper and with the proposed method it should be easier to cover large areas of the distribution power grid. Nevertheless, the proposed method is not yet as precise as the contact galvanic method, but potential benefits should overcome its shortcomings. We tested the method on a larger dataset than previously worked with, but it is still possible that the method will not be able to generalize well in different noise backgrounds or environments.</p>
        <p>The open question is if any different ensemble of deep learning algorithms or newly designed algorithms could bring better results. Our proposed ensemble could be improved with more variable CNNs, as indicated in our ablation study. Also, as the data are very noisy, a better denoising method could bring about a more substantial increase in performance. Furthermore, methods that consider more physical properties of PDs than signal peaks could outperform the proposed solution.</p>
        <p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
        <p>The research was supported by the doctoral grant competition VSB-Technical University of Ostrava, reg. no. CZ.02.2.69/0.0/0.0/ 19_073/0016945 within the Operational Programme Research, Development and Education and under project DGS/TEAM/2020-015 ''Partial Discharge Detection in Insulation Systems''. We would like to thank Alena Kasparkova, Ph. D. for her feedback.</p>
        <p>Data will be made available on request.</p>
    </text>
</tei>
