<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T06:42+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>The size and the complexity of photovoltaic solar power plants are increasing, and it requires an advanced and robust condition monitoring systems for ensuring their reliability. This paper proposes a novel method for faults detection in photovoltaic panels employing a thermographic camera embedded in an unmanned aerial vehicle. The large amount of data generated by these systems must be processed and analyzed. This paper presents a novel approach to identify panels to detect hot spots, and to set their locations. Two novels region-based convolutional neural networks are unified to generate a robust detection structure. The main contribution is the combination of thermography and telemetry data to provide a response of the panel condition monitoring. The data are acquired and then automatically processed, allowing fault detection during the inspection. A detailed description of the methodology is presented, including the different stages to build the neural networks, i.e. the training process, the acquisition and processing of data and the outcomes generation. A thermographic inspection of a real photovoltaic solar plant is done to validate the proposed methodology. The accuracy, the efficiency and the performance of the approach under different real scenarios are evaluated statistically obtaining satisfactory results.The size and the complexity of photovoltaic solar power plants are increasing, and it requires an advanced and robust condition monitoring systems for ensuring their reliability. This paper proposes a novel method for faults detection in photovoltaic panels employing a thermographic camera embedded in an unmanned aerial vehicle. The large amount of data generated by these systems must be processed and analyzed. This paper presents a novel approach to identify panels to detect hot spots, and to set their locations. Two novels region-based convolutional neural networks are unified to generate a robust detection structure. The main contribution is the combination of thermography and telemetry data to provide a response of the panel condition monitoring. The data are acquired and then automatically processed, allowing fault detection during the inspection. A detailed description of the methodology is presented, including the different stages to build the neural networks, i.e. the training process, the acquisition and processing of data and the outcomes generation. A thermographic inspection of a real photovoltaic solar plant is done to validate the proposed methodology. The accuracy, the efficiency and the performance of the approach under different real scenarios are evaluated statistically obtaining satisfactory results.</p>
        <p>Photovoltaic (PV) energy generation has been growing exponentially during the last decade. The global installed capacity has increased from 14 GWp in 2008 to more than 385 GWp in 2017 [1], i.e. a mean annual increase of 28% during the last ten years.Photovoltaic (PV) energy generation has been growing exponentially during the last decade. The global installed capacity has increased from 14 GWp in 2008 to more than 385 GWp in 2017 [1], i.e. a mean annual increase of 28% during the last ten years.</p>
        <p>The installed capacity increased due to two main reasons: the extent of modern PV solar power plants is larger than before [2], covering areas with thousands of square meters, and; modern PV solar panels are more efficient, increasing the energy production [3,4]. For example, in 2008, the world largest PV solar plant was "Olmedilla PV Park" (Spain), with a capacity of 60 MW spread over 285 ha [5], whereas in 2017, it is "Shakti Sthala" (India), 2,000 MWp spread over 5,261 ha [6]. The difference of installed capacity between both plants is more than 1,940 MWp, being the extension of the newer plant more than 18 times greater. Consequently, sophisticated systems require complex maintenance and operation (O&amp;M) tasks [7,8], e.g. panel cleaning, lubrication, repairs and general inspections [9]. The O&amp;M annually costs are estimated to be about 11.27 ‚Ç¨/kWp in a ground installation [10], being the costs associated to planned inspection and monitoring around 1.47 ‚Ç¨/kWp. Efficient methodologies and tools are needed to reduce the O&amp;M costs and to improve the availability of the PV solar plants [11][12][13]. These approaches can facilitate both corrective and preventive maintenance [14][15][16][17].The installed capacity increased due to two main reasons: the extent of modern PV solar power plants is larger than before [2], covering areas with thousands of square meters, and; modern PV solar panels are more efficient, increasing the energy production [3,4]. For example, in 2008, the world largest PV solar plant was "Olmedilla PV Park" (Spain), with a capacity of 60 MW spread over 285 ha [5], whereas in 2017, it is "Shakti Sthala" (India), 2,000 MWp spread over 5,261 ha [6]. The difference of installed capacity between both plants is more than 1,940 MWp, being the extension of the newer plant more than 18 times greater. Consequently, sophisticated systems require complex maintenance and operation (O&amp;M) tasks [7,8], e.g. panel cleaning, lubrication, repairs and general inspections [9]. The O&amp;M annually costs are estimated to be about 11.27 ‚Ç¨/kWp in a ground installation [10], being the costs associated to planned inspection and monitoring around 1.47 ‚Ç¨/kWp. Efficient methodologies and tools are needed to reduce the O&amp;M costs and to improve the availability of the PV solar plants [11][12][13]. These approaches can facilitate both corrective and preventive maintenance [14][15][16][17].</p>
        <p>This paper presents a method to process the data provided by an unmanned aerial vehicle (UAV) [18,19] fitted with a thermographic camera [20,21]. An 97% average increasing in inspection efficiency between aerial and to manual inspection time was found in reference [22] comparing, i.e. 1.07 ‚Ç¨/kWp reduction.This paper presents a method to process the data provided by an unmanned aerial vehicle (UAV) [18,19] fitted with a thermographic camera [20,21]. An 97% average increasing in inspection efficiency between aerial and to manual inspection time was found in reference [22] comparing, i.e. 1.07 ‚Ç¨/kWp reduction.</p>
        <p>The thermographic camera captures the infrared energy emitted by the objects [11]. The UAV allows thermal data to be acquired from better locations [23,24]. Hereinafter, the system composed of the UAV and the IR camera will be named as IR-UAV system. This system provides two different types of data: the IR images captured by a thermographic camera are collected in a matrix that assigns a temperature value to each pixel; telemetry data are provided continuously by the UAV, e.g. Global Positioning System (GPS), coordinates, altitude, orientation, etc. The system can record large amount of data in few minutes, e.g. around 2 Gigabytes in ten minutes. This paper proposes an advanced method to analyse automatically these data. Figure 1 shows a basic scheme of the complete data acquisition system. Figure 1. Data acquisition and image composition: An UAV equipped with thermographic camera obtains images from solar modules; A temperature matrix is generated, and a processing algorithm is used to detect relative hot spots; The telemetry is added for hot spots localization.The thermographic camera captures the infrared energy emitted by the objects [11]. The UAV allows thermal data to be acquired from better locations [23,24]. Hereinafter, the system composed of the UAV and the IR camera will be named as IR-UAV system. This system provides two different types of data: the IR images captured by a thermographic camera are collected in a matrix that assigns a temperature value to each pixel; telemetry data are provided continuously by the UAV, e.g. Global Positioning System (GPS), coordinates, altitude, orientation, etc. The system can record large amount of data in few minutes, e.g. around 2 Gigabytes in ten minutes. This paper proposes an advanced method to analyse automatically these data. Figure 1 shows a basic scheme of the complete data acquisition system. Figure 1. Data acquisition and image composition: An UAV equipped with thermographic camera obtains images from solar modules; A temperature matrix is generated, and a processing algorithm is used to detect relative hot spots; The telemetry is added for hot spots localization.</p>
        <p>The thermal images can be employed to detect relative hot regions, associated to some failures, e.g. damaged cells, short circuits and fire hazards, etc. [25]. The telemetry data can be used to locate these hot spots. An artificial neural network (ANN) based methodology is developed to recognize panels and detect faults. The results of the image processing together with the GPS position are presented in a final report. This information facilitates the maintenance management, since the hot spots and failures in the PV solar power plant can be mapped.The thermal images can be employed to detect relative hot regions, associated to some failures, e.g. damaged cells, short circuits and fire hazards, etc. [25]. The telemetry data can be used to locate these hot spots. An artificial neural network (ANN) based methodology is developed to recognize panels and detect faults. The results of the image processing together with the GPS position are presented in a final report. This information facilitates the maintenance management, since the hot spots and failures in the PV solar power plant can be mapped.</p>
        <p>The main contributions of this paper are:The main contributions of this paper are:</p>
        <p>-The paper proposes a combination of thermography, GPS positioning and convolutional neural networks (CNN) for fault detection in PV solar panels. Several authors have employed some of these techniques but not all techniques together. For example, Acciani et al. proposed a generic analysis of PVs using thermography [26,27], concluding that dirt can be identified as dark regions in thermal images. J. Mu√±oz et al. studied the risk of hot spots, that can cause irreversible damage in modules, appearing in PV solar cells and also in resistive solder bonds [28]. M. Aghaei et al. studied the applications of UAVs in PV solar plants maintenance [29]. They performed two experiments: the UAV flew for 5 minutes and monitored some panels in a roof; the second flight was in a PV solar plant. This inspection method had some limitations due to is was a visual method and image processing was not included. However, they confirm that UAVs result an efficient, cheap and reliable inspection tool. Kim et al. developed a method for detecting failures automatically in PV modules. They employed an UAV equipped with thermographic camera [30]. They obtained the panel area with their own algorithm and created an intensity histogram for each panel [31]. The automatic detection method was a pattern recognition based on histograms and statistical characteristics between good and defective panels. Unlike the method presented in this paper, they did not employ telemetry or GPS data to determine the location of the faults. -The method allows to detect and located faults automatically. Literature shows similar techniques to locate faults. For example, Tsanakas et al. elaborated an advanced inspection system based in UAVs and thermal images [32]. They developed a technique with true orthophoto mapping, based on aerial triangulation and also GPS techniques. They concluded that GPS was more effective than aerial triangulation, especially in large areas. However, this method is not an automatic detection process. -This work employs artificial intelligence to detect faults in PV panels. Similar works can be found in the literature [33], however, they do not combine the region-based convolutional neural networks (R-CNN) and telemetry data. Thermography in PV solar panels has been developed on laboratories to study or identify hot spots, or cracked silicon wafers [28,34]. ANN based methods, in particular R-CNN, are often used to the object detection and classification in images [35], even real-time object detection [36]. Some authors use pretrained networks suitable to current object detection, e.g. AlexNet or GoogleNet [37]. However, they cannot detect relative hot regions since they are not a common object. This tool is also employed in the automotive sector to detect signals [38], vehicles or pedestrian [39]; in medicine to detect tumours [40] or face detection [41]; and in manufacturing industry for process automation [42]. Regarding the positioning system, a similar technique can be found in reference [43], where the positioning of the UAV is improved by integrating a GPS/INS/Vision sensors (INS: inertial navigation systems). However, this positioning system is not integrated in a R-CNN. -The method is validated and applied in real PV solar plants. Most of the works about thermography inspection of PV solar panels focus on the analysis of individual panels. In those works, different methods were applied to demonstrate the capabilities of thermography, for example, studying the efficiency of the panel [26], detecting relative hot regions in panels [44] or identifying general faults in PV modules [45]. However, the proposed method is employed in a real PV solar plant, where many panels can be analyzed together.-The paper proposes a combination of thermography, GPS positioning and convolutional neural networks (CNN) for fault detection in PV solar panels. Several authors have employed some of these techniques but not all techniques together. For example, Acciani et al. proposed a generic analysis of PVs using thermography [26,27], concluding that dirt can be identified as dark regions in thermal images. J. Mu√±oz et al. studied the risk of hot spots, that can cause irreversible damage in modules, appearing in PV solar cells and also in resistive solder bonds [28]. M. Aghaei et al. studied the applications of UAVs in PV solar plants maintenance [29]. They performed two experiments: the UAV flew for 5 minutes and monitored some panels in a roof; the second flight was in a PV solar plant. This inspection method had some limitations due to is was a visual method and image processing was not included. However, they confirm that UAVs result an efficient, cheap and reliable inspection tool. Kim et al. developed a method for detecting failures automatically in PV modules. They employed an UAV equipped with thermographic camera [30]. They obtained the panel area with their own algorithm and created an intensity histogram for each panel [31]. The automatic detection method was a pattern recognition based on histograms and statistical characteristics between good and defective panels. Unlike the method presented in this paper, they did not employ telemetry or GPS data to determine the location of the faults. -The method allows to detect and located faults automatically. Literature shows similar techniques to locate faults. For example, Tsanakas et al. elaborated an advanced inspection system based in UAVs and thermal images [32]. They developed a technique with true orthophoto mapping, based on aerial triangulation and also GPS techniques. They concluded that GPS was more effective than aerial triangulation, especially in large areas. However, this method is not an automatic detection process. -This work employs artificial intelligence to detect faults in PV panels. Similar works can be found in the literature [33], however, they do not combine the region-based convolutional neural networks (R-CNN) and telemetry data. Thermography in PV solar panels has been developed on laboratories to study or identify hot spots, or cracked silicon wafers [28,34]. ANN based methods, in particular R-CNN, are often used to the object detection and classification in images [35], even real-time object detection [36]. Some authors use pretrained networks suitable to current object detection, e.g. AlexNet or GoogleNet [37]. However, they cannot detect relative hot regions since they are not a common object. This tool is also employed in the automotive sector to detect signals [38], vehicles or pedestrian [39]; in medicine to detect tumours [40] or face detection [41]; and in manufacturing industry for process automation [42]. Regarding the positioning system, a similar technique can be found in reference [43], where the positioning of the UAV is improved by integrating a GPS/INS/Vision sensors (INS: inertial navigation systems). However, this positioning system is not integrated in a R-CNN. -The method is validated and applied in real PV solar plants. Most of the works about thermography inspection of PV solar panels focus on the analysis of individual panels. In those works, different methods were applied to demonstrate the capabilities of thermography, for example, studying the efficiency of the panel [26], detecting relative hot regions in panels [44] or identifying general faults in PV modules [45]. However, the proposed method is employed in a real PV solar plant, where many panels can be analyzed together.</p>
        <p>Therefore, the main contribution of this paper with respect to the literature is the development of an intelligent algorithm that detects and allocates automatically relative hot areas of solar panels. The algorithm is tested in a real PV solar farm.Therefore, the main contribution of this paper with respect to the literature is the development of an intelligent algorithm that detects and allocates automatically relative hot areas of solar panels. The algorithm is tested in a real PV solar farm.</p>
        <p>The paper is structured as follows: Section 2 describes the IR-UAV based data acquisition system. Section 3 explains the CNN and the R-CNN structure. Section 4 shows the method together with the training, data acquisition and processing stages. Section 5 validates the method in a real PV solar plant by comparing the outcomes of the method with the real dataset.The paper is structured as follows: Section 2 describes the IR-UAV based data acquisition system. Section 3 explains the CNN and the R-CNN structure. Section 4 shows the method together with the training, data acquisition and processing stages. Section 5 validates the method in a real PV solar plant by comparing the outcomes of the method with the real dataset.</p>
        <p>Thermography is a non-destructive evaluation (NDE) technique [20,[46][47][48]. Therefore, it allows to inspect components and materials without modifying their structural or physical integrity. It is based on the infrared radiation (IR) that objects emit [49].Thermography is a non-destructive evaluation (NDE) technique [20,[46][47][48]. Therefore, it allows to inspect components and materials without modifying their structural or physical integrity. It is based on the infrared radiation (IR) that objects emit [49].</p>
        <p>Thermographic inspections can provide the operating status of the PV panels using a thermographic pattern identification of relative hot areas. Further details about these patterns can be found in references [50] and [51]. This information can be used for detecting faults or abnormal performances.Thermographic inspections can provide the operating status of the PV panels using a thermographic pattern identification of relative hot areas. Further details about these patterns can be found in references [50] and [51]. This information can be used for detecting faults or abnormal performances.</p>
        <p>There are two types of IR thermography techniques: active techniques, which employ an external source that adds extra energy to the object, generating an internal heat flow and increasing the temperature, and; passive techniques, that measure the radiation from the matter without using any external heat source.There are two types of IR thermography techniques: active techniques, which employ an external source that adds extra energy to the object, generating an internal heat flow and increasing the temperature, and; passive techniques, that measure the radiation from the matter without using any external heat source.</p>
        <p>The approach proposed in this paper employs radiation data collected by passive thermographic methods, i.e. the acquisition system only needs a camera without any power heat systems. The suitability IR-UAV system depends on the following aspects:The approach proposed in this paper employs radiation data collected by passive thermographic methods, i.e. the acquisition system only needs a camera without any power heat systems. The suitability IR-UAV system depends on the following aspects:</p>
        <p>UAV specifications: the UAV must be safe and stable. The most determining parameters are:UAV specifications: the UAV must be safe and stable. The most determining parameters are:</p>
        <p>-Power is the capacity in watts of the UAV. The power will determine variables such as the total admissible weight, the battery consumption and the power of DC motors. -Autonomy is the estimated flight time of the aircraft. It depends of, for example, the weight or the wind speed. -Weight depends on the type of UAV and the on-board equipment, e.g. camera, sensor or video transmitters. -Gimbal is the device that controls the movement of the camera. It usually has pan, tilt and roll movements. It is essential for controlling the camera.-Power is the capacity in watts of the UAV. The power will determine variables such as the total admissible weight, the battery consumption and the power of DC motors. -Autonomy is the estimated flight time of the aircraft. It depends of, for example, the weight or the wind speed. -Weight depends on the type of UAV and the on-board equipment, e.g. camera, sensor or video transmitters. -Gimbal is the device that controls the movement of the camera. It usually has pan, tilt and roll movements. It is essential for controlling the camera.</p>
        <p>IR camera features: it must be able to take thermal and visual images and to provide telemetry and GPS data. The most important parameters of the camera are [52]:IR camera features: it must be able to take thermal and visual images and to provide telemetry and GPS data. The most important parameters of the camera are [52]:</p>
        <p>-Resolution corresponds to the density of pixels of the images. High-resolution cameras allow usually smaller areas to be scanned without losing the quality of the image. The available information depends on the resolution of the detector. -Focal length is de distance between the convergence point and the imaging sensor. It determines the angle of view and, therefore, the area recorded [53]. -Temperature range is the difference between the maximum and the minimum temperatures that can be recorded by the IR camera.-Resolution corresponds to the density of pixels of the images. High-resolution cameras allow usually smaller areas to be scanned without losing the quality of the image. The available information depends on the resolution of the detector. -Focal length is de distance between the convergence point and the imaging sensor. It determines the angle of view and, therefore, the area recorded [53]. -Temperature range is the difference between the maximum and the minimum temperatures that can be recorded by the IR camera.</p>
        <p>-Emissivity is related to the energy that matter radiates to the exterior. The emissivity is adjusted in the camera depending on the object to analyse. Emissivity values could vary with the surface condition of the measured object, and also with temperature variation and wavelength. A variation in emissivity values will cause an alteration in the measure [51].-Emissivity is related to the energy that matter radiates to the exterior. The emissivity is adjusted in the camera depending on the object to analyse. Emissivity values could vary with the surface condition of the measured object, and also with temperature variation and wavelength. A variation in emissivity values will cause an alteration in the measure [51].</p>
        <p>The hour of the day and the date are key variables for the experiments. The acquisition system has been designed considering that each PV solar plant has a different shape or design, either related to the configuration of panels or the conditions of the terrain in that are installed. Orientation of the UAV and the IR camera. The images should be taken in perpendicular to the PV panel, where panels have square or rectangular contours in the image. The time and the date of the flight require to be considered to avoid reflections because they could cause confusions with relative hot region or other faults [54]. The altitude of the UAV determines the number of panels inspected, where duplicated information would appear in several frames.The hour of the day and the date are key variables for the experiments. The acquisition system has been designed considering that each PV solar plant has a different shape or design, either related to the configuration of panels or the conditions of the terrain in that are installed. Orientation of the UAV and the IR camera. The images should be taken in perpendicular to the PV panel, where panels have square or rectangular contours in the image. The time and the date of the flight require to be considered to avoid reflections because they could cause confusions with relative hot region or other faults [54]. The altitude of the UAV determines the number of panels inspected, where duplicated information would appear in several frames.</p>
        <p>Reflections are a common problem in thermography inspections. It affects to the image resolution and the precision. Accurate measurements only will be possible when the image signal presents a high noise equivalent temperature-difference (NETD) [54]. In case of reflections, the approach could detect brightness instead of relative hot regions.Reflections are a common problem in thermography inspections. It affects to the image resolution and the precision. Accurate measurements only will be possible when the image signal presents a high noise equivalent temperature-difference (NETD) [54]. In case of reflections, the approach could detect brightness instead of relative hot regions.</p>
        <p>A panel or a set of panels may appear several times in different frames since several images are inputted into the approach. An algorithm to manage these duplications is needed before the results.A panel or a set of panels may appear several times in different frames since several images are inputted into the approach. An algorithm to manage these duplications is needed before the results.</p>
        <p>An adequate combination of these factors allows high-quality thermographic inspections to be carried out.An adequate combination of these factors allows high-quality thermographic inspections to be carried out.</p>
        <p>ANN is an advanced and robust method based on biological neural networks. They are usually composed of the following elements:ANN is an advanced and robust method based on biological neural networks. They are usually composed of the following elements:</p>
        <p>-Neurons are the processing units. There are three types of neurons grouped in layers: input neurons, output neurons and hidden neurons. The input layer receives the data, the hidden layers link the inputs and the outputs, and the output layer provides the outcomes of the ANN.-Neurons are the processing units. There are three types of neurons grouped in layers: input neurons, output neurons and hidden neurons. The input layer receives the data, the hidden layers link the inputs and the outputs, and the output layer provides the outcomes of the ANN.</p>
        <p>-Activation function defines the output of each neuron according to its inputs. The activation value can be continuous or discrete. -Connection between neurons is a certain value adjusted during the training stage and reflects the knowledge acquired by the net.-Activation function defines the output of each neuron according to its inputs. The activation value can be continuous or discrete. -Connection between neurons is a certain value adjusted during the training stage and reflects the knowledge acquired by the net.</p>
        <p>ANNs learn to interpret the data by a training process. Then, the data can be classified according to the learned patterns [33]. However, the ANNs require a large computational cost for processing images. These images need a high number of connections between neurons and require large processing periods. This problem can be addressed by using CNNs.ANNs learn to interpret the data by a training process. Then, the data can be classified according to the learned patterns [33]. However, the ANNs require a large computational cost for processing images. These images need a high number of connections between neurons and require large processing periods. This problem can be addressed by using CNNs.</p>
        <p>CNNs belong to the family of Deep Neural Networks, whose main characteristic is the use of multiple convolution layers [55]. Their structures are different from conventional ANNs such as perceptron [56]. CNNs have some layers only connected to a subset of neurons in the next layer, reaching a high processing speed. Figure 3 shows a comparison between ANN (left) and CNN (right). The structures of these networks are based on the following layers:CNNs belong to the family of Deep Neural Networks, whose main characteristic is the use of multiple convolution layers [55]. Their structures are different from conventional ANNs such as perceptron [56]. CNNs have some layers only connected to a subset of neurons in the next layer, reaching a high processing speed. Figure 3 shows a comparison between ANN (left) and CNN (right). The structures of these networks are based on the following layers:</p>
        <p>Convolutional layers are sets of filters capable of learning by a training stage [61]. These filters are convoluted along the input image. The number of neurons (ùëÅ) is given by equation ( 1):Convolutional layers are sets of filters capable of learning by a training stage [61]. These filters are convoluted along the input image. The number of neurons (ùëÅ) is given by equation ( 1):</p>
        <p>where:where:</p>
        <p>-ùëä is the input volume.-ùëä is the input volume.</p>
        <p>-ùêπ is the spatial extent.-ùêπ is the spatial extent.</p>
        <p>-ùëÜ is the stride of the convolution.-ùëÜ is the stride of the convolution.</p>
        <p>-ùëÉ is the zero padding on the border.-ùëÉ is the zero padding on the border.</p>
        <p>A zero-padding is used to ensure that the input and the output have the same size. A zero-padding is a process that pad the input volume with zeros around the border. To control the output volume, the zero-padding is used and the stride (ùëÜ) is set at 1. Then, the zero padding (ùëÉ) is defined by equation ( 2):A zero-padding is used to ensure that the input and the output have the same size. A zero-padding is a process that pad the input volume with zeros around the border. To control the output volume, the zero-padding is used and the stride (ùëÜ) is set at 1. Then, the zero padding (ùëÉ) is defined by equation ( 2):</p>
        <p>An input size of ùëä 1 ùë• ùêª 1 ùë• ùê∑ 1 will generate an output size of ùëä 2 ùë• ùêª 2 ùë• ùê∑ 2 . These parameters are defined by equation ( 3):An input size of ùëä 1 ùë• ùêª 1 ùë• ùê∑ 1 will generate an output size of ùëä 2 ùë• ùêª 2 ùë• ùê∑ 2 . These parameters are defined by equation ( 3):</p>
        <p>where ùêæ is the number of filters of the convolutional layer.where ùêæ is the number of filters of the convolutional layer.</p>
        <p>Pooling layer: is commonly inserted between different convolution layers. This layer is used for a progressive reduction of the spatial size of the representation. The number of parameters and the computational cost will be reduced. The pooling layer has a size of ùëä 2 ùë• ùêª 2 ùë• ùê∑ 2 . The output will be a volume of dimensions ùëä 3 ùë• ùêª 3 ùë• ùê∑ 3 , where:Pooling layer: is commonly inserted between different convolution layers. This layer is used for a progressive reduction of the spatial size of the representation. The number of parameters and the computational cost will be reduced. The pooling layer has a size of ùëä 2 ùë• ùêª 2 ùë• ùê∑ 2 . The output will be a volume of dimensions ùëä 3 ùë• ùêª 3 ùë• ùê∑ 3 , where:</p>
        <p>Rectified Linear Unit (ReLU) layer: it is a complementary step to the convolution operation. Some authors consider that it is a part of the convolutional layer. In this paper, it is considered as a separated layer because of the programming language employed [62]. This layer employs an activation function [63,64]. This function can be defined by equation (5).Rectified Linear Unit (ReLU) layer: it is a complementary step to the convolution operation. Some authors consider that it is a part of the convolutional layer. In this paper, it is considered as a separated layer because of the programming language employed [62]. This layer employs an activation function [63,64]. This function can be defined by equation (5).</p>
        <p>Fully-connected layer: the neurons are connected with all the activation functions of the previous layer. The input is pondered by a weight matrix and a bias vector is added. The objective of this layer is to classify the input image through the features obtained previously. This layer is usually followed by a SoftMax Layer.Fully-connected layer: the neurons are connected with all the activation functions of the previous layer. The input is pondered by a weight matrix and a bias vector is added. The objective of this layer is to classify the input image through the features obtained previously. This layer is usually followed by a SoftMax Layer.</p>
        <p>SoftMax layer [65]: It is used as a classifier. The probabilities of each class are calculated with a confidence level. The SoftMax model is often considered as a part of the fully connected layer. The advantage of using SoftMax is that the sum of the output vector is 1 and there are not negative values, therefore, each component can be considered the probability of each class. The same vector could be also obtained by employing the Sigmoid function when the number of output classes is 2. The SoftMax model is a generalization of the sigmoid function for multiclass prediction. The use of SoftMax would allow to the ANN to be improved in case that more classes, such as specific faults, need to be predicted. Each node of this layer receives the information from all the nodes of the previous layer. The total input of the SoftMax layer (ùëé ùëñ ) is given by equation (6).SoftMax layer [65]: It is used as a classifier. The probabilities of each class are calculated with a confidence level. The SoftMax model is often considered as a part of the fully connected layer. The advantage of using SoftMax is that the sum of the output vector is 1 and there are not negative values, therefore, each component can be considered the probability of each class. The same vector could be also obtained by employing the Sigmoid function when the number of output classes is 2. The SoftMax model is a generalization of the sigmoid function for multiclass prediction. The use of SoftMax would allow to the ANN to be improved in case that more classes, such as specific faults, need to be predicted. Each node of this layer receives the information from all the nodes of the previous layer. The total input of the SoftMax layer (ùëé ùëñ ) is given by equation (6).</p>
        <p>being:being:</p>
        <p>‚Ñé is the activation function of the previous layer nodes.‚Ñé is the activation function of the previous layer nodes.</p>
        <p>-ùëÄ is the weight connecting the previous layer to the SoftMax layer.-ùëÄ is the weight connecting the previous layer to the SoftMax layer.</p>
        <p>For ùëã number of classes, this layer contains a total of ùëã nodes denoted as pi [66], where pi is a discrete probability function, so that ‚àë ùëù ùëñ = 1.For ùëã number of classes, this layer contains a total of ùëã nodes denoted as pi [66], where pi is a discrete probability function, so that ‚àë ùëù ùëñ = 1.</p>
        <p>The probability value assigned to each class is:The probability value assigned to each class is:</p>
        <p>, where ùëñ = 1, ‚Ä¶ , ùëã, where ùëñ = 1, ‚Ä¶ , ùëã</p>
        <p>Finally, since ùëù ùëñ is dependent on ùëé ùëñ , then the predicted class ùëñÃÇ is given by:Finally, since ùëù ùëñ is dependent on ùëé ùëñ , then the predicted class ùëñÃÇ is given by:</p>
        <p>Figure 4 shows the operations carried out by each different layer of the R-CNN. The class prediction is the basis for the detection system. Figure 5 shows the scheme of the detection system proposed in this paper [36]. An image is selected and the regions of interest (ROI) are marked (Figure 5.2). This step is accurately developed by experts using specific labelling software, e.g. see reference [67], obtaining a database with the images ant the location of panels and relative hot regions in the image. Then, the images are computed by the R-CNN (Figure 5.Figure 4 shows the operations carried out by each different layer of the R-CNN. The class prediction is the basis for the detection system. Figure 5 shows the scheme of the detection system proposed in this paper [36]. An image is selected and the regions of interest (ROI) are marked (Figure 5.2). This step is accurately developed by experts using specific labelling software, e.g. see reference [67], obtaining a database with the images ant the location of panels and relative hot regions in the image. Then, the images are computed by the R-CNN (Figure 5.</p>
        <p>3) that provides a final classification (Figure 5.4)).3) that provides a final classification (Figure 5.4)).</p>
        <p>The cross entropy loss of the input is evaluated. This layers allows to analice the probabilities and finally choose an output class. The success of the R-CNN depends on several variables, e.g. the applicability of the input database, the volume and the representativity.The cross entropy loss of the input is evaluated. This layers allows to analice the probabilities and finally choose an output class. The success of the R-CNN depends on several variables, e.g. the applicability of the input database, the volume and the representativity.</p>
        <p>This section describes novel methodology for detecting and locating relative hot regions. The algorithm is divided into three main stages: a R-CNN based structure is created and trained by using real image of solar panels; the R-CNN is employed for processing new data from the IR-UAV system, and; the results are summarized in a report, considering both telemetric and thermal information. Figure 6 shows the flowchart of the method. -Learn rate drop period: is applied to the learn rate schedule and defines the period of epochs to apply previous factor. -Max epochs: 15 epochs have been found as the optimal. The number of epochs determines the number of times that the training algorithm is applied to the whole training dataset. The time required by the training process depends on this parameter. -Mini batch size: adjusts the batch size. With a batch size of 16, optimal results have been obtained. This batch is a subset of the training image set. The SGD algorithm uses the parameter mini batch size as a parameter to evaluate the gradient at each iteration. A gradient clipping stabilizes the higher training learning rates in case of exponential increasing of the gradient.This section describes novel methodology for detecting and locating relative hot regions. The algorithm is divided into three main stages: a R-CNN based structure is created and trained by using real image of solar panels; the R-CNN is employed for processing new data from the IR-UAV system, and; the results are summarized in a report, considering both telemetric and thermal information. Figure 6 shows the flowchart of the method. -Learn rate drop period: is applied to the learn rate schedule and defines the period of epochs to apply previous factor. -Max epochs: 15 epochs have been found as the optimal. The number of epochs determines the number of times that the training algorithm is applied to the whole training dataset. The time required by the training process depends on this parameter. -Mini batch size: adjusts the batch size. With a batch size of 16, optimal results have been obtained. This batch is a subset of the training image set. The SGD algorithm uses the parameter mini batch size as a parameter to evaluate the gradient at each iteration. A gradient clipping stabilizes the higher training learning rates in case of exponential increasing of the gradient.</p>
        <p>The selection of both the batch size and the max epochs has been done by iterating the algorithm with different values. Figure 8 shows that a higher max epochs number reduces the error, however the computational time increase. Similar results can be found in reference [70]. It can be observed that the error become stable from 15 epoch. Figure 9 shows the computational time required by the algorithm to complete the image processing for different batch sizes and 15 max. epochs. In this case study, the computational cost decreases for higher batch sizes. Therefore, a batch size of 16 is selected instead of 8. These parameter selection leads to reduce the computational cost without an excessive loss of accuracy. Table I shows a resume of the training options and structural parameters considered for the proposed R-CNN. The convolutional layers are created after the training options. The method employs a R-CNN with 15 different layers including input, convolution, ReLU, pooling and output layers. Figure 10 shows the architecture of the developed R-CNN, that is based on the architectures given in references [71], [72] and [73].The selection of both the batch size and the max epochs has been done by iterating the algorithm with different values. Figure 8 shows that a higher max epochs number reduces the error, however the computational time increase. Similar results can be found in reference [70]. It can be observed that the error become stable from 15 epoch. Figure 9 shows the computational time required by the algorithm to complete the image processing for different batch sizes and 15 max. epochs. In this case study, the computational cost decreases for higher batch sizes. Therefore, a batch size of 16 is selected instead of 8. These parameter selection leads to reduce the computational cost without an excessive loss of accuracy. Table I shows a resume of the training options and structural parameters considered for the proposed R-CNN. The convolutional layers are created after the training options. The method employs a R-CNN with 15 different layers including input, convolution, ReLU, pooling and output layers. Figure 10 shows the architecture of the developed R-CNN, that is based on the architectures given in references [71], [72] and [73].</p>
        <p>Size: [32 32 3] Convolution 2D layer The training process is a complex task that could take several hours, even days, depending on the number of images, boundary boxes and labels, and on the GPU or CPU characteristics. The training algorithm is according to reference [74]: a Region Proposal Network is pre-trained to generate a set of proposals; a new detection network is trained by using the proposals generated; the detector network is employed to initialize the RPN training, and; the convolutional layers shared by both networks are fixed and the fully connected layers are tuned. Consequently, the networks share the convolutional layers to create a unified structure. Once the R-CNN has been trained, it is ready to receive real images from the data acquisition system.Size: [32 32 3] Convolution 2D layer The training process is a complex task that could take several hours, even days, depending on the number of images, boundary boxes and labels, and on the GPU or CPU characteristics. The training algorithm is according to reference [74]: a Region Proposal Network is pre-trained to generate a set of proposals; a new detection network is trained by using the proposals generated; the detector network is employed to initialize the RPN training, and; the convolutional layers shared by both networks are fixed and the fully connected layers are tuned. Consequently, the networks share the convolutional layers to create a unified structure. Once the R-CNN has been trained, it is ready to receive real images from the data acquisition system.</p>
        <p>The telemetry data provided by the IR-UAV system contain the altitude, orientation, GPS position, camera angle and vision angle. The data will be added to the final report if a relative hot region is detected.The telemetry data provided by the IR-UAV system contain the altitude, orientation, GPS position, camera angle and vision angle. The data will be added to the final report if a relative hot region is detected.</p>
        <p>The R-CNN provides better results if the edges of the PV solar panels are perpendicular to the edges of the images because of the ROIs are square. Therefore, it is convenient to orientate the image to improve the detection task. For this purpose, a code has been developed using an edge detection algorithm. It is based on derivative approximation method [75], developed through the Sobel model. The bounds are considered to be the points where the gradient is maximum. The edges of the images are detected using this information, and the algorithm is able to find the predominant directions to rotate the image. Figure 11 shows, from left to right, the different steps of the image rotation process. The detection algorithm is developed to assign a score to each boundary box and a confidence scores to each detected object. Only those results with a high confidence (more than 0.9) will be considered in this paper. The final stage of the approach is to associate the telemetry data and the outcomes in case that any relative hot region has been detected.The R-CNN provides better results if the edges of the PV solar panels are perpendicular to the edges of the images because of the ROIs are square. Therefore, it is convenient to orientate the image to improve the detection task. For this purpose, a code has been developed using an edge detection algorithm. It is based on derivative approximation method [75], developed through the Sobel model. The bounds are considered to be the points where the gradient is maximum. The edges of the images are detected using this information, and the algorithm is able to find the predominant directions to rotate the image. Figure 11 shows, from left to right, the different steps of the image rotation process. The detection algorithm is developed to assign a score to each boundary box and a confidence scores to each detected object. Only those results with a high confidence (more than 0.9) will be considered in this paper. The final stage of the approach is to associate the telemetry data and the outcomes in case that any relative hot region has been detected.</p>
        <p>The approach outcomes and the telemetry data are joined to generate a final report. The GPS position is combined with the altitude, the UAV orientation, the camera angle and the focus angle.The approach outcomes and the telemetry data are joined to generate a final report. The GPS position is combined with the altitude, the UAV orientation, the camera angle and the focus angle.</p>
        <p>Figure 13 shows a basic scheme the area of interest together with the variables. The area of interest is the real portion of ground taken by IR camera in a specific frame. On the other side, the ROI is the region inside the area of interest that will be analyzed. The following parameters are considered for calculating the position of the damaged PV module (see Figure 14):Figure 13 shows a basic scheme the area of interest together with the variables. The area of interest is the real portion of ground taken by IR camera in a specific frame. On the other side, the ROI is the region inside the area of interest that will be analyzed. The following parameters are considered for calculating the position of the damaged PV module (see Figure 14):</p>
        <p>-Altitude (z), Zenithal angle (ùúÉ ùëçùê∑ ) and Azimuthal angle (ùõπ ùëçùê∑ ), provided by the telemetry system. -The field of view angle (œí) of the thermographic camera.-Altitude (z), Zenithal angle (ùúÉ ùëçùê∑ ) and Azimuthal angle (ùõπ ùëçùê∑ ), provided by the telemetry system. -The field of view angle (œí) of the thermographic camera.</p>
        <p>-Location of the relative hot region within the IR image (ùëã ‚Ñé , ùëå ‚Ñé ).-Location of the relative hot region within the IR image (ùëã ‚Ñé , ùëå ‚Ñé ).</p>
        <p>-Coordinates of the drone (ùë• ùê∑ , ùë¶ ùê∑ ), provided by the GPS. This information is processed through trigonometric. The area of interest coordinates (ùë• ùëì1 , ùë• ùëì2 , ùë¶ ùëì1 , ùë¶ ùëì2 ) and the coordinates of the damaged panel (ùë• ùëÉ , ùë¶ ùëÉ ) are obtained. Figure 14 shows two perspectives to visualize the information provided by the GPS and the telemetry system together with the coordinates above mentioned. The following expressions are employed to obtain the coordinates in the ground according to Figure 14:-Coordinates of the drone (ùë• ùê∑ , ùë¶ ùê∑ ), provided by the GPS. This information is processed through trigonometric. The area of interest coordinates (ùë• ùëì1 , ùë• ùëì2 , ùë¶ ùëì1 , ùë¶ ùëì2 ) and the coordinates of the damaged panel (ùë• ùëÉ , ùë¶ ùëÉ ) are obtained. Figure 14 shows two perspectives to visualize the information provided by the GPS and the telemetry system together with the coordinates above mentioned. The following expressions are employed to obtain the coordinates in the ground according to Figure 14:</p>
        <p>Therefore, the relative hot region location is given by: ùë• ùëÉ = ùë• ùëì1 + ùëã ‚Ñé ùë¶ ùëÉ = ùë¶ ùëì1 + ùëå ‚Ñé ùë• ùëÉ and ùë¶ ùëÉ are set into GPS coordinates to show to the operators the allocation of the faults. Nowadays, any fault is usually manually checked by operators before starting any task. The GPS and the telemetry systems are subject to errors that depend of the system.Therefore, the relative hot region location is given by: ùë• ùëÉ = ùë• ùëì1 + ùëã ‚Ñé ùë¶ ùëÉ = ùë¶ ùëì1 + ùëå ‚Ñé ùë• ùëÉ and ùë¶ ùëÉ are set into GPS coordinates to show to the operators the allocation of the faults. Nowadays, any fault is usually manually checked by operators before starting any task. The GPS and the telemetry systems are subject to errors that depend of the system.</p>
        <p>The final report presents a table with two columns. The rows correspond to each fault detected. The first column contains the GPS coordinates of the area of interest. The second column defines the position of ROI. The results vary if the telemetry data are not accurate enough [76]. Figure 15 shows an example of a final report. The four points (ùëã ‚Ñé , ùëå ‚Ñé , ùêª, ùëä) define in which position of the image the relative hot region are detected, (ùëã ‚Ñé , ùëå ‚Ñé ) are the start point of the relative hot region, and (H, ùëä) are the size in pixels of the boundary box. It is combined with the GPS telemetry specified in each frame to determine the final position.The final report presents a table with two columns. The rows correspond to each fault detected. The first column contains the GPS coordinates of the area of interest. The second column defines the position of ROI. The results vary if the telemetry data are not accurate enough [76]. Figure 15 shows an example of a final report. The four points (ùëã ‚Ñé , ùëå ‚Ñé , ùêª, ùëä) define in which position of the image the relative hot region are detected, (ùëã ‚Ñé , ùëå ‚Ñé ) are the start point of the relative hot region, and (H, ùëä) are the size in pixels of the boundary box. It is combined with the GPS telemetry specified in each frame to determine the final position.</p>
        <p>The approach has been implemented and used for inspecting a real PV solar plant of 100 kWp.The approach has been implemented and used for inspecting a real PV solar plant of 100 kWp.</p>
        <p>Figure 16 shows the main image processing and hotspot detection steps for one example thermal image of the solar park. The R-CNN works with square ROIs. The ROI presents an error that depends of the training images, the orientation of the panels, the temperature of the edges, etc. They are trapezoidal because of the perspective of the images deforms panels. Therefore, the contour of the panels cannot be exactly marked by the panel ROIs. The relative hot area is always located inside a panel ROI, therefore, it is not considered an external hot element as anomaly in the panels.Figure 16 shows the main image processing and hotspot detection steps for one example thermal image of the solar park. The R-CNN works with square ROIs. The ROI presents an error that depends of the training images, the orientation of the panels, the temperature of the edges, etc. They are trapezoidal because of the perspective of the images deforms panels. Therefore, the contour of the panels cannot be exactly marked by the panel ROIs. The relative hot area is always located inside a panel ROI, therefore, it is not considered an external hot element as anomaly in the panels.</p>
        <p>The locations of the relative hot regions are obtained by the telemetry data given by the camera into the image files. This information is detailed in Table II. A method has been developed to compare the results with the final report table to avoid the repetition of located relative hot regions. Only one is considered if there are several points with the same coordinates within a margin. PV panels that appears partially are not detected and, therefore, relative hot regions are not considered in these areas. An example of the panel detection is shown at the bottom of Figure 16(d), where several panels are partially included in the image but not detected.The locations of the relative hot regions are obtained by the telemetry data given by the camera into the image files. This information is detailed in Table II. A method has been developed to compare the results with the final report table to avoid the repetition of located relative hot regions. Only one is considered if there are several points with the same coordinates within a margin. PV panels that appears partially are not detected and, therefore, relative hot regions are not considered in these areas. An example of the panel detection is shown at the bottom of Figure 16(d), where several panels are partially included in the image but not detected.</p>
        <p>A set of 100 thermographic images of the PV solar plant has been analyzed into the approach to validate the proposed methodology. Figure 17 shows an example of different images of the set. The validation will be done according to the detection of PV solar panels and the faults by two confusion matrices. The images are divided into four types of areas, showed in Figure 18, regarding to the concordance between the estimation of the approach and the real case.A set of 100 thermographic images of the PV solar plant has been analyzed into the approach to validate the proposed methodology. Figure 17 shows an example of different images of the set. The validation will be done according to the detection of PV solar panels and the faults by two confusion matrices. The images are divided into four types of areas, showed in Figure 18, regarding to the concordance between the estimation of the approach and the real case.</p>
        <p>Those panels that do not contain any relative hot regions are considered as good panels, otherwise, will be considered as conspicuous panels. Figure 18 shows the possible scenarios for the detection of relative hot regions. The images in Figure 17 are employed to validate the method, and the outcomes are analyzed according to the scenarios given in Figure 18. The statistical characterization of the approach is presented in ¬°Error! No se encuentra el origen de la referencia.. Some standard terms are considered to quantify the performance of both the panel and the relative hot region detectors: accuracy (AC); the true positive rate (TP); false positive rate (FP); true negative rate (TN); the false negative rate (FN), and; precision (P). The accuracy of the panel detector, i.e. the ratio of success in the outcomes, is more than 92.25%. The worst characteristic of the panel detector is the FN, in other words, there is an average of 11% of the panels that cannot be detected in a specific image. These misdetections are due to some panels do not appear completely in the image. However, the complete panels are detected with a higher accuracy. It must be highlighted that the approach has a precision of 94.52%.Those panels that do not contain any relative hot regions are considered as good panels, otherwise, will be considered as conspicuous panels. Figure 18 shows the possible scenarios for the detection of relative hot regions. The images in Figure 17 are employed to validate the method, and the outcomes are analyzed according to the scenarios given in Figure 18. The statistical characterization of the approach is presented in ¬°Error! No se encuentra el origen de la referencia.. Some standard terms are considered to quantify the performance of both the panel and the relative hot region detectors: accuracy (AC); the true positive rate (TP); false positive rate (FP); true negative rate (TN); the false negative rate (FN), and; precision (P). The accuracy of the panel detector, i.e. the ratio of success in the outcomes, is more than 92.25%. The worst characteristic of the panel detector is the FN, in other words, there is an average of 11% of the panels that cannot be detected in a specific image. These misdetections are due to some panels do not appear completely in the image. However, the complete panels are detected with a higher accuracy. It must be highlighted that the approach has a precision of 94.52%.</p>
        <p>Regarding the relative hot region detector, the accuracy is more that 99%. Since the panel detector has a high false negative rate, this error is extended to the relative hot region detector, being the precision more than 91%.Regarding the relative hot region detector, the accuracy is more that 99%. Since the panel detector has a high false negative rate, this error is extended to the relative hot region detector, being the precision more than 91%.</p>
        <p>The equipment employed in the inspection are:The equipment employed in the inspection are:</p>
        <p>-Drone DJI S900 -IR Camera: WIRIS WORKSWELL -Flight controller: DJI A2 -Gimbal system: Gremsy, T1-Drone DJI S900 -IR Camera: WIRIS WORKSWELL -Flight controller: DJI A2 -Gimbal system: Gremsy, T1</p>
        <p>The specifications show that the GPS in the flight controller has ¬±0.5 m vertical error and ¬±1.5 m horizontal error [77]. According to the gimbal specifications, the zenithal and azimuthal angles can have an error margin of 0.005¬∫ [78]. Considering a maximum altitude of 50 m, and a minimum zenithal angle of 30¬∫, the maximum error introduced in the location is estimated to 1.8 m. The validation of the localization method has been done by using a thermal IR camera with a GPS. The validation process consisted in the manual checking of all the relative hot spots locations that were predicted by the proposed algorithm. This process is divided in three steps for each predicted hot spot: first, the location predicted by the algorithm is found using the manual GPS; second, the location of the nearest hotspot is registered, and; third, the distance between both locations is evaluated. The absolute distances obtained are shown in Figure 19. In this case study, an average error of 0.86 m has been achieved and all the errors were below to the estimated threshold of 1.8 m (minimal distance to classify a solar tracker). The solar trackers are longer than this threshold, and there is also space between them, therefore, the localization is done correctly. Due to the positioning error, this methodology does not guarantee the correct localization of the faulty PV panel, but the corresponding solar tracker is identified. This error is not a significative drawback, since all the detected anomalies must be checked manually before doing any repairment or replacement. Therefore, the coordinates of the affected PV trackers are enough to help the operators search for faulty panels.The specifications show that the GPS in the flight controller has ¬±0.5 m vertical error and ¬±1.5 m horizontal error [77]. According to the gimbal specifications, the zenithal and azimuthal angles can have an error margin of 0.005¬∫ [78]. Considering a maximum altitude of 50 m, and a minimum zenithal angle of 30¬∫, the maximum error introduced in the location is estimated to 1.8 m. The validation of the localization method has been done by using a thermal IR camera with a GPS. The validation process consisted in the manual checking of all the relative hot spots locations that were predicted by the proposed algorithm. This process is divided in three steps for each predicted hot spot: first, the location predicted by the algorithm is found using the manual GPS; second, the location of the nearest hotspot is registered, and; third, the distance between both locations is evaluated. The absolute distances obtained are shown in Figure 19. In this case study, an average error of 0.86 m has been achieved and all the errors were below to the estimated threshold of 1.8 m (minimal distance to classify a solar tracker). The solar trackers are longer than this threshold, and there is also space between them, therefore, the localization is done correctly. Due to the positioning error, this methodology does not guarantee the correct localization of the faulty PV panel, but the corresponding solar tracker is identified. This error is not a significative drawback, since all the detected anomalies must be checked manually before doing any repairment or replacement. Therefore, the coordinates of the affected PV trackers are enough to help the operators search for faulty panels.</p>
        <p>This paper has presented a methodology for the detection of faults in photovoltaic solar panels employing data from a thermography camera embedded in an unmanned aerial vehicle. An autonomous and automatic panel and relative hot region detection approach has been designed based on region-based convolutional neural networks. Inspections by unmanned aerial vehicles based usually provide heterogenous images due to the altitude, the orientation, the recording angle, etc. The approach has been demonstrated to be robust and it is validated. The results show that the methodology is adequate for the automatic detection and localization of solar trackers and relative hot regions with and accuracy more than 99.02% and a precision of 91.67%. The PV set and the relative hot spots are located correctly considering the errors found in the experiments. An average error of 0.86 m has been calculated for the localization of relative hot spots. Predicted hot spot locationsThis paper has presented a methodology for the detection of faults in photovoltaic solar panels employing data from a thermography camera embedded in an unmanned aerial vehicle. An autonomous and automatic panel and relative hot region detection approach has been designed based on region-based convolutional neural networks. Inspections by unmanned aerial vehicles based usually provide heterogenous images due to the altitude, the orientation, the recording angle, etc. The approach has been demonstrated to be robust and it is validated. The results show that the methodology is adequate for the automatic detection and localization of solar trackers and relative hot regions with and accuracy more than 99.02% and a precision of 91.67%. The PV set and the relative hot spots are located correctly considering the errors found in the experiments. An average error of 0.86 m has been calculated for the localization of relative hot spots. Predicted hot spot locations</p>
        <p>The work reported herewith has been financially supported by the Spanish Ministerio de Econom√≠a y Competitividad, under the Research Grant RTC-2016-5694-3. The authors are very grateful to the referees for their contribution to improve this paper.The work reported herewith has been financially supported by the Spanish Ministerio de Econom√≠a y Competitividad, under the Research Grant RTC-2016-5694-3. The authors are very grateful to the referees for their contribution to improve this paper.</p>
    </text>
</tei>
