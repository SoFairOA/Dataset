<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T16:07+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>It is well-known that Numerical Weather Prediction (NWP) models require considerable computer power to solve complex mathematical equations to obtain a forecast based on current weather conditions. In this article, we propose a novel lightweight data-driven weather forecasting model by exploring temporal modelling approaches of Long Short-Term Memory (LSTM) and Temporal Convolutional Networks (TCN) and compare its performance with the existing classical machine learning approaches, statistical forecasting approaches, and a dynamic ensemble method, as well as the well-established Weather Research and Forecasting (WRF) NWP model. More specifically Standard Regression (SR), Support Vector Regression (SVR), and Random Forest (RF) are implemented as the classical machine learning approaches, and Autoregressive Integrated Moving Average (ARIMA), Vector Auto Regression (VAR), and Vector Error Correction Model (VECM) are implemented as the statistical forecasting approaches. Furthermore, Arbitrage of Forecasting Expert (AFE) is implemented as the dynamic ensemble method in this article. Weather information is captured by time-series data and thus, we explore the state-of-art LSTM and TCN models, which is a specialised form of Recurrent Neural Network (RNN) for weather prediction. The proposed deep model consists of a number of layers that use surface weather parameters over a given period of time for weather forecasting. The proposed deep learning networks with LSTM and TCN layers are assessed in two different regressions, namely Multi-Input Multi-Output (MIMO) and Multi-Input Single-Output (MISO). Our experiment shows that the proposed lightweight model produces better results compared to the well-known and complex WRF model, demonstrating its potential for efficient and accurate weather forecasting up to 12 hours.It is well-known that Numerical Weather Prediction (NWP) models require considerable computer power to solve complex mathematical equations to obtain a forecast based on current weather conditions. In this article, we propose a novel lightweight data-driven weather forecasting model by exploring temporal modelling approaches of Long Short-Term Memory (LSTM) and Temporal Convolutional Networks (TCN) and compare its performance with the existing classical machine learning approaches, statistical forecasting approaches, and a dynamic ensemble method, as well as the well-established Weather Research and Forecasting (WRF) NWP model. More specifically Standard Regression (SR), Support Vector Regression (SVR), and Random Forest (RF) are implemented as the classical machine learning approaches, and Autoregressive Integrated Moving Average (ARIMA), Vector Auto Regression (VAR), and Vector Error Correction Model (VECM) are implemented as the statistical forecasting approaches. Furthermore, Arbitrage of Forecasting Expert (AFE) is implemented as the dynamic ensemble method in this article. Weather information is captured by time-series data and thus, we explore the state-of-art LSTM and TCN models, which is a specialised form of Recurrent Neural Network (RNN) for weather prediction. The proposed deep model consists of a number of layers that use surface weather parameters over a given period of time for weather forecasting. The proposed deep learning networks with LSTM and TCN layers are assessed in two different regressions, namely Multi-Input Multi-Output (MIMO) and Multi-Input Single-Output (MISO). Our experiment shows that the proposed lightweight model produces better results compared to the well-known and complex WRF model, demonstrating its potential for efficient and accurate weather forecasting up to 12 hours.</p>
        <p>Weather forecasting refers to the scientific process of predicting the state of the atmosphere based on specific time frames and locations [1]. Numerical Weather Prediction (NWP) utilises computer algorithms to provide a forecast based on current weather conditions by solving a large system of non-linear mathematical equations, which are based on specific mathematical models. More specifically, these models define a coordinate system, which divides the earth into a 3-dimensional grid. The weather parameters such as winds, solar radiation, the phase change of water, heat transfer, relative humidity, and surface hydrology are measured within each grid and their interaction with neighbouring grids to predict atmospheric properties for the future [2]. Meteorology adopted a more quantitative approach with the advancement of technology and computer science, and forecast models became more accessible to researchers, forecasters, and other stakeholders. Many NWP systems were developed in recent years, such as Weather Research and Forecasting (WRF) model, where increasing high-performance computing power has facilitated the enhancement and the introduction of regional or limited area models [3]. As a consequence, the WRF model became the world's most-used atmospheric NWP model due to its higher resolution rate, accuracy, open-source nature, community support, and a wide variety of usability within different domains [4], [5].Weather forecasting refers to the scientific process of predicting the state of the atmosphere based on specific time frames and locations [1]. Numerical Weather Prediction (NWP) utilises computer algorithms to provide a forecast based on current weather conditions by solving a large system of non-linear mathematical equations, which are based on specific mathematical models. More specifically, these models define a coordinate system, which divides the earth into a 3-dimensional grid. The weather parameters such as winds, solar radiation, the phase change of water, heat transfer, relative humidity, and surface hydrology are measured within each grid and their interaction with neighbouring grids to predict atmospheric properties for the future [2]. Meteorology adopted a more quantitative approach with the advancement of technology and computer science, and forecast models became more accessible to researchers, forecasters, and other stakeholders. Many NWP systems were developed in recent years, such as Weather Research and Forecasting (WRF) model, where increasing high-performance computing power has facilitated the enhancement and the introduction of regional or limited area models [3]. As a consequence, the WRF model became the world's most-used atmospheric NWP model due to its higher resolution rate, accuracy, open-source nature, community support, and a wide variety of usability within different domains [4], [5].</p>
        <p>According to [1], data-driven computer modelling systems can be utilised to reduce the computational power of NWPs. In particular, Artificial Neural Network (ANN) can be used for this purpose due to their adaptive nature and learning capabilities based on prior knowledge. This feature makes the ANN techniques very appealing in application domains for solving highly nonlinear phenomena. Deep models for multivariate time-series forecasting often use Recurrent Neural Networks (RNN) and Temporal Convolutional Networks (TCN). Recently, a variant of RNN called Long Short Term Memory (LSTM) has attached considerable attention due to its superior performance. Such models have attracted considerable attention due to their superior performance [6]- [8]. Deep networks often use stacked neural networks and include several layers as part of the overall composition known as nodes. The computation takes place at the node level since it allows the combination of data input through a set of coefficients. Subsequently, the activation function gets established on the basis of input-weight products while signal progresses through the network [9]. Regression technique is often employed to develop and evaluate Neural network models for accurate weather prediction as the weather information is captured by time-series data consisting of real numbers [10]. This article presents developing and evaluating a lightweight and novel weather forecasting system using modern neural networks. Figure 1 depicts a general overview of the research discussed in this article. More specifically, a suitable machine learning model is proposed by exploring temporal modelling approaches of LSTM and TCN, and compare its performance with classical machine learning approaches, statistical forecasting models, and a dynamic ensemble method. Secondly, we use the proposed model for short-term weather prediction and compare the model accuracy with the well-established WRF model. Finally, we reform the model for long-term weather forecasting, and analyse the model accuracy and compared the performance to the state-of-art WRF model.According to [1], data-driven computer modelling systems can be utilised to reduce the computational power of NWPs. In particular, Artificial Neural Network (ANN) can be used for this purpose due to their adaptive nature and learning capabilities based on prior knowledge. This feature makes the ANN techniques very appealing in application domains for solving highly nonlinear phenomena. Deep models for multivariate time-series forecasting often use Recurrent Neural Networks (RNN) and Temporal Convolutional Networks (TCN). Recently, a variant of RNN called Long Short Term Memory (LSTM) has attached considerable attention due to its superior performance. Such models have attracted considerable attention due to their superior performance [6]- [8]. Deep networks often use stacked neural networks and include several layers as part of the overall composition known as nodes. The computation takes place at the node level since it allows the combination of data input through a set of coefficients. Subsequently, the activation function gets established on the basis of input-weight products while signal progresses through the network [9]. Regression technique is often employed to develop and evaluate Neural network models for accurate weather prediction as the weather information is captured by time-series data consisting of real numbers [10]. This article presents developing and evaluating a lightweight and novel weather forecasting system using modern neural networks. Figure 1 depicts a general overview of the research discussed in this article. More specifically, a suitable machine learning model is proposed by exploring temporal modelling approaches of LSTM and TCN, and compare its performance with classical machine learning approaches, statistical forecasting models, and a dynamic ensemble method. Secondly, we use the proposed model for short-term weather prediction and compare the model accuracy with the well-established WRF model. Finally, we reform the model for long-term weather forecasting, and analyse the model accuracy and compared the performance to the state-of-art WRF model.</p>
        <p>In this study, we investigate LSTM and TCN over RNN since there is an inherent issue of the vanishing gradient problem with the RNN [6]. The LSTM and TCN can overcome this vanishing gradient issue, but it can easily use up the high capacity of memory [8], [11]. The rest of the article is organised as follows: Section 2 focuses on related work, and Section 3 discusses the research aims and objectives. In Section 4, we present the WRF model and its challenges, and Section 5 discusses the sequence modelling and prediction. In Sections 6 and Section 7, we discuss the methodology and results. Finally, Section 8 concludes the article.In this study, we investigate LSTM and TCN over RNN since there is an inherent issue of the vanishing gradient problem with the RNN [6]. The LSTM and TCN can overcome this vanishing gradient issue, but it can easily use up the high capacity of memory [8], [11]. The rest of the article is organised as follows: Section 2 focuses on related work, and Section 3 discusses the research aims and objectives. In Section 4, we present the WRF model and its challenges, and Section 5 discusses the sequence modelling and prediction. In Sections 6 and Section 7, we discuss the methodology and results. Finally, Section 8 concludes the article.</p>
        <p>Numerical Weather Prediction (NWP) concept was proposed by Lewis Fry Richardson in 1922, and practical use of NWP began in 1955 after the development of programmable computers [1]. Neural Networks based weather forecasting has been evolved significantly in the last three decades. Before the year 2000, the Model Output Statistics (MOS) was the most widely used approach to improve the numerical models' ability to forecast by relating model outputs to observational data [12]- [14]. A mixed statistical or dynamic technique for the weather forecasting was introduced by [15] in 1983. The work in [16] added a new perception to dynamic modelling in 1991. These approaches have limitations and challenges such as massive computational requirements, lack of design methodologies for selecting the model architecture and parameters, and time-consuming to prediction resulting less reliability as the difference between the current time and the forecast time increases [13], [16], [17].Numerical Weather Prediction (NWP) concept was proposed by Lewis Fry Richardson in 1922, and practical use of NWP began in 1955 after the development of programmable computers [1]. Neural Networks based weather forecasting has been evolved significantly in the last three decades. Before the year 2000, the Model Output Statistics (MOS) was the most widely used approach to improve the numerical models' ability to forecast by relating model outputs to observational data [12]- [14]. A mixed statistical or dynamic technique for the weather forecasting was introduced by [15] in 1983. The work in [16] added a new perception to dynamic modelling in 1991. These approaches have limitations and challenges such as massive computational requirements, lack of design methodologies for selecting the model architecture and parameters, and time-consuming to prediction resulting less reliability as the difference between the current time and the forecast time increases [13], [16], [17].</p>
        <p>Artificial Neural Network based minimum temperature prediction system was introduced in 1991 using the backpropagation algorithms [18], [19]. This concept considerably reduced the computational requirements of MOS directing an effective forecast [16]. A snowfall and rainfall forecasting model was introduced in 1995 from weather radar images with ANN [20]. The results show that the ANN is more effective than the traditional crosscorrelation method, and the persistence prediction method is producing a substantial reduction in prediction error. In 1998, Oishi et al. developed a severe rainfall prediction method using AI [21]. The development method was unique as it is introduced inference (i.e. Knowledge-based) rather than using numerical simulations. A Multi-Polynomial High Order Neural Network (M-PHONN) based rainfall prediction model was developed by Hui Qi and Ming Zhang in 2001 [22]. This new model has features such as increasing the speed, accuracy, and the robustness of the rainfall estimate. Therefore, this model could be used to complement the already established Auto-Estimator algorithms.Artificial Neural Network based minimum temperature prediction system was introduced in 1991 using the backpropagation algorithms [18], [19]. This concept considerably reduced the computational requirements of MOS directing an effective forecast [16]. A snowfall and rainfall forecasting model was introduced in 1995 from weather radar images with ANN [20]. The results show that the ANN is more effective than the traditional crosscorrelation method, and the persistence prediction method is producing a substantial reduction in prediction error. In 1998, Oishi et al. developed a severe rainfall prediction method using AI [21]. The development method was unique as it is introduced inference (i.e. Knowledge-based) rather than using numerical simulations. A Multi-Polynomial High Order Neural Network (M-PHONN) based rainfall prediction model was developed by Hui Qi and Ming Zhang in 2001 [22]. This new model has features such as increasing the speed, accuracy, and the robustness of the rainfall estimate. Therefore, this model could be used to complement the already established Auto-Estimator algorithms.</p>
        <p>A multilayer perceptron network was trained with the backpropagation algorithm with momentum for temperature forecasting in 2002 [23]. The results were very encouraging and clearly demonstrated the potential for future weather forecasting applications. In the same year, a comparative was carried out analysing different neural network models for daily maximum and minimum temperature, and wind speed [24]. The results show that the Radial Basis Function Network (RBFN) produced the most accurate forecast compared to the Elman Recurrent Neural Network (ELNN) and Multi-Layered Perceptron (MLP) networks. In 2005, a rough set of fuzzy neural network was introduced to forecast weather parameters; dew temperature, wind speed, temperature, and visibility [25]. This model has several fuzzy rules, and their initial weights were estimated with a deeper network for weather forecasting. Moreover, M. Hayati and Z. Mohebi proposed a successful model for temperature forecasting based on MLP.A multilayer perceptron network was trained with the backpropagation algorithm with momentum for temperature forecasting in 2002 [23]. The results were very encouraging and clearly demonstrated the potential for future weather forecasting applications. In the same year, a comparative was carried out analysing different neural network models for daily maximum and minimum temperature, and wind speed [24]. The results show that the Radial Basis Function Network (RBFN) produced the most accurate forecast compared to the Elman Recurrent Neural Network (ELNN) and Multi-Layered Perceptron (MLP) networks. In 2005, a rough set of fuzzy neural network was introduced to forecast weather parameters; dew temperature, wind speed, temperature, and visibility [25]. This model has several fuzzy rules, and their initial weights were estimated with a deeper network for weather forecasting. Moreover, M. Hayati and Z. Mohebi proposed a successful model for temperature forecasting based on MLP.</p>
        <p>A feature-based neural network model was introduced in 2008 to predict maximum temperature, minimum temperature, and relative humidity [26]. Neural Network features are extracted over different periods as well as from the time-series weather parameter itself. In particular, feedforward ANN is utilised in this approach with backpropagation for supervised learning. The prediction results have a high degree of accuracy, and this modelling is recommended as an alternative to traditional meteorological approaches by [27]- [29]. In 2012, a Backpropagations Neural Network (BPN) was implemented for temperature forecasting [30], [31]. This network has successfully identified the non-linear structural relationship between various input weather parameters. Furthermore, a new hybrid model was introduced in 2014 to forecast the temperature which is based on an Ensemble of Neural Networks (ENN) [32], and the results suggested that including image data would improve the prediction results. In the same year, a deep neural network based feature representation for weather perdition model was developed for the temperature and dew point prediction [33].A feature-based neural network model was introduced in 2008 to predict maximum temperature, minimum temperature, and relative humidity [26]. Neural Network features are extracted over different periods as well as from the time-series weather parameter itself. In particular, feedforward ANN is utilised in this approach with backpropagation for supervised learning. The prediction results have a high degree of accuracy, and this modelling is recommended as an alternative to traditional meteorological approaches by [27]- [29]. In 2012, a Backpropagations Neural Network (BPN) was implemented for temperature forecasting [30], [31]. This network has successfully identified the non-linear structural relationship between various input weather parameters. Furthermore, a new hybrid model was introduced in 2014 to forecast the temperature which is based on an Ensemble of Neural Networks (ENN) [32], and the results suggested that including image data would improve the prediction results. In the same year, a deep neural network based feature representation for weather perdition model was developed for the temperature and dew point prediction [33].</p>
        <p>In 2015, eight different novel regression tree structures were applied to short-term wind speed prediction [34]. The author also compared the best regression tree approach against other AI approaches such as Support Vector Regression (SVR), MLP, extreme learning machines, and multi-linear regression approach. The best regression tree yields the best results for wind speed prediction. In the same year, a deep neural network was introduced for ultra-short-term wind forecasting with success [35]. Deep learning with LSTM layers has been introduced to precipitation nowcasting by Shi et al. [11]. The experimental results show that the LSTM network has the ability to capture spatiotemporal correlations and can be used to precipitation nowcasting. In the same year, a model was developed to predict the temperate in Nevada using a deep neural network with stacked denoising auto-encoders with higher accuracy of 97.97% compared to traditional neural networks (94.92%) [36]. In 2016, the multi-stacked deep learning LSTM approach was utilised to forecasting weather parameters temperature, humidity, and wind speed [37]. The author suggested that the model could be used to predict other weather parameters based on the effectiveness and accuracy of the results.In 2015, eight different novel regression tree structures were applied to short-term wind speed prediction [34]. The author also compared the best regression tree approach against other AI approaches such as Support Vector Regression (SVR), MLP, extreme learning machines, and multi-linear regression approach. The best regression tree yields the best results for wind speed prediction. In the same year, a deep neural network was introduced for ultra-short-term wind forecasting with success [35]. Deep learning with LSTM layers has been introduced to precipitation nowcasting by Shi et al. [11]. The experimental results show that the LSTM network has the ability to capture spatiotemporal correlations and can be used to precipitation nowcasting. In the same year, a model was developed to predict the temperate in Nevada using a deep neural network with stacked denoising auto-encoders with higher accuracy of 97.97% compared to traditional neural networks (94.92%) [36]. In 2016, the multi-stacked deep learning LSTM approach was utilised to forecasting weather parameters temperature, humidity, and wind speed [37]. The author suggested that the model could be used to predict other weather parameters based on the effectiveness and accuracy of the results.</p>
        <p>Traditional machine learning methods were analysed for radiation forecasting in 2017 [38]. The author concluded that the SVR, regression trees, and forests have produced a promising outcome for radiation forecasting. In 2018, the Backpropagation Neural (BPN) network's performance compared with linear regression and regression tree for temperature forecasting [39]. As a result, a significant better temperature yields the BPN. In 2018, a short-term local rain and temperature forecasting model was developed using deep neural network [40]. The author concluded that the deep neural networks yield the highest accuracy for rain prediction among several machine learning methods. In the same year, the neural network approach is utilised to create models to predict sea surface temperature and soil moisture [41], [42].Traditional machine learning methods were analysed for radiation forecasting in 2017 [38]. The author concluded that the SVR, regression trees, and forests have produced a promising outcome for radiation forecasting. In 2018, the Backpropagation Neural (BPN) network's performance compared with linear regression and regression tree for temperature forecasting [39]. As a result, a significant better temperature yields the BPN. In 2018, a short-term local rain and temperature forecasting model was developed using deep neural network [40]. The author concluded that the deep neural networks yield the highest accuracy for rain prediction among several machine learning methods. In the same year, the neural network approach is utilised to create models to predict sea surface temperature and soil moisture [41], [42].</p>
        <p>The selected state-of-the-art deep learning approaches for weather forecasting and their contributions and differences with the previous approaches are discussed in Table 1.The selected state-of-the-art deep learning approaches for weather forecasting and their contributions and differences with the previous approaches are discussed in Table 1.</p>
        <p>Deep neural networks for ultra-shortterm wind forecasting [35] Results show that carefully selection of deep neural networks outperforms shallow ones. The model accepts a single input parameter and predicts a single parameter, and the model is limited to very short-term forecasting (less than an hour). Weather forecasting using deep learning techniques [43] Recurrent neural network is used for prediction of the rainfall with adequate accuracy level. The model uses a single input single output and is used for short-term forecasting. Short-term local weather forecast using dense weather station by deep neural network [40] Deep neural network is used to predict rain and temperature. The researches use four input parameters and predict one parameter at a given time. This model is able to predict data accurately up to an hour. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting [11] Formulated precipitation nowcasting as a spatiotemporal sequence forecasting problem. The proposed model is a Single-input singleoutput and able to produce a state-of-the-art performance for up to 6 hours. Forecasting the weather of Nevada: A deep learning approach [36] This model accepts four input parameters and predicts one output as temperature. Results indicated that stacked denoising auto-encoder deep learning model predicts accurate long-term temperature. Sequence to Sequence Weather Forecasting with Long Short-Term Memory Recurrent Neural Networks [37] Multi-stacked LSTMs are used to map sequences of weather values of the same length. This model uses three input parameters and it predicts one parameter at a time.Deep neural networks for ultra-shortterm wind forecasting [35] Results show that carefully selection of deep neural networks outperforms shallow ones. The model accepts a single input parameter and predicts a single parameter, and the model is limited to very short-term forecasting (less than an hour). Weather forecasting using deep learning techniques [43] Recurrent neural network is used for prediction of the rainfall with adequate accuracy level. The model uses a single input single output and is used for short-term forecasting. Short-term local weather forecast using dense weather station by deep neural network [40] Deep neural network is used to predict rain and temperature. The researches use four input parameters and predict one parameter at a given time. This model is able to predict data accurately up to an hour. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting [11] Formulated precipitation nowcasting as a spatiotemporal sequence forecasting problem. The proposed model is a Single-input singleoutput and able to produce a state-of-the-art performance for up to 6 hours. Forecasting the weather of Nevada: A deep learning approach [36] This model accepts four input parameters and predicts one output as temperature. Results indicated that stacked denoising auto-encoder deep learning model predicts accurate long-term temperature. Sequence to Sequence Weather Forecasting with Long Short-Term Memory Recurrent Neural Networks [37] Multi-stacked LSTMs are used to map sequences of weather values of the same length. This model uses three input parameters and it predicts one parameter at a time.</p>
        <p>A Deep Learning Methodology Based on Bidirectional Gated Recurrent Unit for Wind Power Prediction [44] Contributed the bidirectional gated recurrent network for wind power forecasting. The model used wind direction and wind speed as inputs and predicted the results more accurately up to 6 hours. Table 1: Existing deep learning approaches and their contributions The above existing weather forecasting models are able to predict up to maximum three weather parameters. Besides, weather forecasting is an entirely non-linear process, and each parameter often depends upon one more other parameters [13], [45], [46]. These larger numbers of interrelated parameters work together, aiming for an accurate weather forecast in a more reliable NWP such as met office and WRF models [4], [47]. A maximum of up to four input weather parameters is considered in the existing AI-based forecasting models.A Deep Learning Methodology Based on Bidirectional Gated Recurrent Unit for Wind Power Prediction [44] Contributed the bidirectional gated recurrent network for wind power forecasting. The model used wind direction and wind speed as inputs and predicted the results more accurately up to 6 hours. Table 1: Existing deep learning approaches and their contributions The above existing weather forecasting models are able to predict up to maximum three weather parameters. Besides, weather forecasting is an entirely non-linear process, and each parameter often depends upon one more other parameters [13], [45], [46]. These larger numbers of interrelated parameters work together, aiming for an accurate weather forecast in a more reliable NWP such as met office and WRF models [4], [47]. A maximum of up to four input weather parameters is considered in the existing AI-based forecasting models.</p>
        <p>Based on the related work, it is evident that:Based on the related work, it is evident that:</p>
        <p>â€¢ There is no identified attempt to compare an AI-based weather prediction with a well-established and existing weather forecasting model such as WRF; â€¢ There has been little or no attempt to compare traditional machine learning approaches with cuttingedge deep learning technologies for weather forecasting; â€¢ Most of the existing approaches use less than four interrelated input parameters for neural networkbased weather forecasting model;â€¢ There is no identified attempt to compare an AI-based weather prediction with a well-established and existing weather forecasting model such as WRF; â€¢ There has been little or no attempt to compare traditional machine learning approaches with cuttingedge deep learning technologies for weather forecasting; â€¢ Most of the existing approaches use less than four interrelated input parameters for neural networkbased weather forecasting model;</p>
        <p>â€¢ A complete AI-based weather forecasting model with up to 10 input/output weather parameters is yet to be explored.â€¢ A complete AI-based weather forecasting model with up to 10 input/output weather parameters is yet to be explored.</p>
        <p>The work presented in this article aimed to develop a weather forecasting model to address the above-mentioned drawbacks using state-of-the-art deep models by establishing the following objectives.The work presented in this article aimed to develop a weather forecasting model to address the above-mentioned drawbacks using state-of-the-art deep models by establishing the following objectives.</p>
        <p>1. To propose an efficient Neural Network-based weather forecasting model by exploring temporal modelling approaches of LSTM and TCN, and compare its performance with the existing approaches; 2. Use the proposed neural network model for short-term weather prediction and compare the results with WRF model prediction; 3. Fine-tune the proposed model for long-term weather forecasting; 4. Compare the model performances for long-term forecasting with the WRF model prediction.1. To propose an efficient Neural Network-based weather forecasting model by exploring temporal modelling approaches of LSTM and TCN, and compare its performance with the existing approaches; 2. Use the proposed neural network model for short-term weather prediction and compare the results with WRF model prediction; 3. Fine-tune the proposed model for long-term weather forecasting; 4. Compare the model performances for long-term forecasting with the WRF model prediction.</p>
        <p>Our approach is targeted to develop deep neural networks to solve the regression problem of weather forecasting. We propose two different regression models to assess proposed deep learning models, namely Multi-Input Multi-Output (MIMO) and Multi-Input Single-Output (MISO). In this article, we addressed the above objectives in detail in various sections. Objective 1, an effective neural network-based weather forecasting model is proposed and compared its performance with existing approaches in Section 7.1. Objective 2, the proposed model is used to short-term weather forecasting and compared its performance with the WRF model predictions in Section 7.2. For Objective 3 and Objective 4, the proposed model is fine-tuned for long-term forecasting and compared the results with the WRF model predictions in Section 7.3.Our approach is targeted to develop deep neural networks to solve the regression problem of weather forecasting. We propose two different regression models to assess proposed deep learning models, namely Multi-Input Multi-Output (MIMO) and Multi-Input Single-Output (MISO). In this article, we addressed the above objectives in detail in various sections. Objective 1, an effective neural network-based weather forecasting model is proposed and compared its performance with existing approaches in Section 7.1. Objective 2, the proposed model is used to short-term weather forecasting and compared its performance with the WRF model predictions in Section 7.2. For Objective 3 and Objective 4, the proposed model is fine-tuned for long-term forecasting and compared the results with the WRF model predictions in Section 7.3.</p>
        <p>The WRF model was developed by Norwegian physicist Vilhelm Bjerknes in the latter part of the 1990s as part of a collaborative partnership with many environmental and meteorology organisations. The model involves solving of various thermodynamic equations so that numerical weather-based predictions can be made mainly through different vertical levels [48], [49]. The primary role of the WRF is to carry out analysis focusing on climate time scale via linking physics data between land, atmosphere and ocean. The WRF model is currently the world's most-used atmospheric model since its initial public release in the year 2000 [5].The WRF model was developed by Norwegian physicist Vilhelm Bjerknes in the latter part of the 1990s as part of a collaborative partnership with many environmental and meteorology organisations. The model involves solving of various thermodynamic equations so that numerical weather-based predictions can be made mainly through different vertical levels [48], [49]. The primary role of the WRF is to carry out analysis focusing on climate time scale via linking physics data between land, atmosphere and ocean. The WRF model is currently the world's most-used atmospheric model since its initial public release in the year 2000 [5].</p>
        <p>In order to investigate the model for real cases, it is necessary to install and configure WPS (WRF Preprocessing System), WRF ARW (Advanced Research WRF model), and 
            <rs type="software">Post</rs> Processing software. The WRF post-processing is not described in this article, as the main objective is to collect historical weather data for prediction and analyses. Interested researchers can refer to [50] for further details. The WRF ARW and the WPS share common routines, like WRF I/O API. Therefore, the successful compilation of the WPS depends upon the successful compilation of the WRF ARW model [4].
        </p>
        <p>The WRF model needs to run in two different modes to extract time-series data. Firstly, historical weather data are collected and subsequently, predicted weather data is identified for evaluation purposes. For each instance, the model runs in a single domain mode and utilises different "namelist.wps" and "namelist.input" files to configure the WPS and WRF-ARW components [17]. GRIdded Binary or General Regularly-distributed Information in Binary, often use as GRIB data, which is a concise data format commonly used in meteorology to store historical and forecast weather data [17], [51]. According to [52], Global Forecast System (GFS) GRIB data provides 0.25 degrees resolution and available to download every three hours freely. Therefore, the GFS threehourly data are selected for this project, with a horizontal resolution set to 10km.The WRF model needs to run in two different modes to extract time-series data. Firstly, historical weather data are collected and subsequently, predicted weather data is identified for evaluation purposes. For each instance, the model runs in a single domain mode and utilises different "namelist.wps" and "namelist.input" files to configure the WPS and WRF-ARW components [17]. GRIdded Binary or General Regularly-distributed Information in Binary, often use as GRIB data, which is a concise data format commonly used in meteorology to store historical and forecast weather data [17], [51]. According to [52], Global Forecast System (GFS) GRIB data provides 0.25 degrees resolution and available to download every three hours freely. Therefore, the GFS threehourly data are selected for this project, with a horizontal resolution set to 10km.</p>
        <p>One of the primary challenges in the WRF is its requirement for massive computational power to solve the equations that describe the atmosphere. Furthermore, atmospheric processes are associated with highly chaotic dynamical systems, which causes a limited model's accuracy. As a consequence, the model forecast capabilities are less reliable as the difference between the current time and the forecast time increases [1], [53]. In addition, the WRF is a large and complex model with different versions and applications, which lead to the need for greater understanding of the model, its implementation and the different option associated with its execution [5]. The GFS 0.25 degrees dataset is the freely available highest resolution dataset for the WRF model. This allows the user to forecast weather data at a horizontal resolution about 27km [51], [52]. This implies that the user can predict data with increased accuracy up to 27km. The model calculates the lesser resolution data based on results obtained. Thus, the model obtains better results for long-range forecast and not for a selected geographical region, such as a farm, school, places of interest, and so on [5], [17], [54].One of the primary challenges in the WRF is its requirement for massive computational power to solve the equations that describe the atmosphere. Furthermore, atmospheric processes are associated with highly chaotic dynamical systems, which causes a limited model's accuracy. As a consequence, the model forecast capabilities are less reliable as the difference between the current time and the forecast time increases [1], [53]. In addition, the WRF is a large and complex model with different versions and applications, which lead to the need for greater understanding of the model, its implementation and the different option associated with its execution [5]. The GFS 0.25 degrees dataset is the freely available highest resolution dataset for the WRF model. This allows the user to forecast weather data at a horizontal resolution about 27km [51], [52]. This implies that the user can predict data with increased accuracy up to 27km. The model calculates the lesser resolution data based on results obtained. Thus, the model obtains better results for long-range forecast and not for a selected geographical region, such as a farm, school, places of interest, and so on [5], [17], [54].</p>
        <p>Based on the above discussion, we propose a novel lightweight weather prediction model that could run on a standalone PC for accurate weather prediction and could easily be deployed in a selected geographical region.Based on the above discussion, we propose a novel lightweight weather prediction model that could run on a standalone PC for accurate weather prediction and could easily be deployed in a selected geographical region.</p>
        <p>The modelling task has been highlighted before defining a network structure which involves time-series weather data sequence ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘‡ and wish to predict some corresponding outputs ğ‘¦ 0 , â€¦ , ğ‘¦ ğ‘‡ at each time. As presented in Table 2, there are 10 different weather parameters in data at a given time ğ‘¡, ğ‘¥ ğ‘¡ = [ğ‘ 1 , â€¦ , ğ‘ 10 ]. The aim is to predict the value ğ‘¦ ğ‘¡ at time ğ‘¡, which is constrained to only previously observed inputs: ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘¡-1 . Therefore, the sequence modelling network can be defined as a function â„± âˆ¶ ğ’³ T+1 â†’ ğ’´ ğ‘‡+1 that produces the mapping ğ‘¦ Ì‚0, â€¦ , ğ‘¦ Ì‚ğ‘‡ = â„±(ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘‡ ), if it satisfies the causal constraints, i.e. ğ‘¦ ğ‘¡ only depends on ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘¡ and not on any future inputs ğ‘¥ ğ‘¡+1 , â€¦ , ğ‘¥ ğ‘‡ . The main idea of learning in the sequence modelling is to find a network â„± which minimizes the loss (â„“) between the actual outputs and the predictions, â„“(ğ‘¦ 0 , â€¦ , ğ‘¦ ğ‘‡ , â„±(ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘‡ )) in which the sequences and predictions are drawn according to some distribution.The modelling task has been highlighted before defining a network structure which involves time-series weather data sequence ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘‡ and wish to predict some corresponding outputs ğ‘¦ 0 , â€¦ , ğ‘¦ ğ‘‡ at each time. As presented in Table 2, there are 10 different weather parameters in data at a given time ğ‘¡, ğ‘¥ ğ‘¡ = [ğ‘ 1 , â€¦ , ğ‘ 10 ]. The aim is to predict the value ğ‘¦ ğ‘¡ at time ğ‘¡, which is constrained to only previously observed inputs: ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘¡-1 . Therefore, the sequence modelling network can be defined as a function â„± âˆ¶ ğ’³ T+1 â†’ ğ’´ ğ‘‡+1 that produces the mapping ğ‘¦ Ì‚0, â€¦ , ğ‘¦ Ì‚ğ‘‡ = â„±(ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘‡ ), if it satisfies the causal constraints, i.e. ğ‘¦ ğ‘¡ only depends on ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘¡ and not on any future inputs ğ‘¥ ğ‘¡+1 , â€¦ , ğ‘¥ ğ‘‡ . The main idea of learning in the sequence modelling is to find a network â„± which minimizes the loss (â„“) between the actual outputs and the predictions, â„“(ğ‘¦ 0 , â€¦ , ğ‘¦ ğ‘‡ , â„±(ğ‘¥ 0 , â€¦ , ğ‘¥ ğ‘‡ )) in which the sequences and predictions are drawn according to some distribution.</p>
        <p>The WRF model with GFS-GRIB data can produce a large amount of historical weather data. Recurrent Neural Networks (RNN), LSTM, and TCN are extremely expressive models which are appropriate in such a scenario. These networks have attracted considerable attention due to their superior performance based on ability to learn highly complex vector-to-vector mapping [55], [56]. The LSTM/TCN is a specialised form of RNN that is designed for sequence modelling [55], [57]. Highly dimensional hidden states ğ‘¯ are the basic building blocks of RNN which are updated with non-linear activation function â„±. At a given time ğ‘¡, the hidden state ğ‘¯ ğ‘¡ is updated by ğ‘¯ ğ‘¡ = â„±(ğ‘¯ ğ‘¡-1 , ğ‘¥ ğ‘¡ ). The structure of ğ‘¯ works as the memory of the network. The state of the hidden layer at a given time is conditioned on its previous state. The RNN is extremely deep as they are maintained a vector activation through time at each timestep. This will result in high training time-consuming due to the exploding and the vanishing gradient problems [6]. The development of LSTM and TCN architectures have been addressed the gradient vanishing issue with RNN [58]. Therefore, the LSTM and TCN deep learning architectures are used in this study.The WRF model with GFS-GRIB data can produce a large amount of historical weather data. Recurrent Neural Networks (RNN), LSTM, and TCN are extremely expressive models which are appropriate in such a scenario. These networks have attracted considerable attention due to their superior performance based on ability to learn highly complex vector-to-vector mapping [55], [56]. The LSTM/TCN is a specialised form of RNN that is designed for sequence modelling [55], [57]. Highly dimensional hidden states ğ‘¯ are the basic building blocks of RNN which are updated with non-linear activation function â„±. At a given time ğ‘¡, the hidden state ğ‘¯ ğ‘¡ is updated by ğ‘¯ ğ‘¡ = â„±(ğ‘¯ ğ‘¡-1 , ğ‘¥ ğ‘¡ ). The structure of ğ‘¯ works as the memory of the network. The state of the hidden layer at a given time is conditioned on its previous state. The RNN is extremely deep as they are maintained a vector activation through time at each timestep. This will result in high training time-consuming due to the exploding and the vanishing gradient problems [6]. The development of LSTM and TCN architectures have been addressed the gradient vanishing issue with RNN [58]. Therefore, the LSTM and TCN deep learning architectures are used in this study.</p>
        <p>The proposed model is based on LSTM networks and uses temporal weather data to identify the patterns and produces weather predictions. As discussed in Section 5, we experiment with the state-of-the-art LSTM, which is a specialised form of RNN, and it is widely applied to handle temporal data. The key concepts of the LSTM have the ability to learn long-term dependencies by incorporating memory units. These memory units allow the network to learn, forget previously hidden states, and update hidden states [6], [9], [59].The proposed model is based on LSTM networks and uses temporal weather data to identify the patterns and produces weather predictions. As discussed in Section 5, we experiment with the state-of-the-art LSTM, which is a specialised form of RNN, and it is widely applied to handle temporal data. The key concepts of the LSTM have the ability to learn long-term dependencies by incorporating memory units. These memory units allow the network to learn, forget previously hidden states, and update hidden states [6], [9], [59].</p>
        <p>Figure 2 shows the deep learning model consisting of stacked LSTM layers for weather forecasting using surface weather parameters. Table 2 describes the surface weather parameters, which are used as the input parameters. The model provides outputs, which are the predicted weather parameters.Figure 2 shows the deep learning model consisting of stacked LSTM layers for weather forecasting using surface weather parameters. Table 2 describes the surface weather parameters, which are used as the input parameters. The model provides outputs, which are the predicted weather parameters.</p>
        <p>(1) The notations of Equation 1 are: ğ‘¤ * -weight matrices, ğ‘ * -biases, âŠ™element-wise vector product, ğ¼ ğ‘¡ -input gate and ğ½ ğ‘¡ -input moderation gate contributing to memory, ğ¹ ğ‘¡ -forget gate, and ğ‘‚ ğ‘¡ -output gate as a multiplier between memory gates. To allow the LSTM to make complex decisions over a short period of time, there are two types of hidden states, namely ğ¶ ğ‘¡ and ğ» ğ‘¡ [6], [60]. The LSTM has the ability to selectively consider its current inputs or forgets its previous memory by switching the gates ğ¼ ğ‘¡ and ğ¹ ğ‘¡ . Similarly, the output gate ğ‘‚ ğ‘¡ learns how much memory cell ğ¶ ğ‘¡ needs to be transferred to the hidden state ğ» ğ‘¡ . Compared to the RNN, these additional memory cells give the ability to learn enormously complex and long-term temporal dynamics with the LSTM.(1) The notations of Equation 1 are: ğ‘¤ * -weight matrices, ğ‘ * -biases, âŠ™element-wise vector product, ğ¼ ğ‘¡ -input gate and ğ½ ğ‘¡ -input moderation gate contributing to memory, ğ¹ ğ‘¡ -forget gate, and ğ‘‚ ğ‘¡ -output gate as a multiplier between memory gates. To allow the LSTM to make complex decisions over a short period of time, there are two types of hidden states, namely ğ¶ ğ‘¡ and ğ» ğ‘¡ [6], [60]. The LSTM has the ability to selectively consider its current inputs or forgets its previous memory by switching the gates ğ¼ ğ‘¡ and ğ¹ ğ‘¡ . Similarly, the output gate ğ‘‚ ğ‘¡ learns how much memory cell ğ¶ ğ‘¡ needs to be transferred to the hidden state ğ» ğ‘¡ . Compared to the RNN, these additional memory cells give the ability to learn enormously complex and long-term temporal dynamics with the LSTM.</p>
        <p>In this work, we propose two types of deep models to solve the regression problem involving weather forecasting, namely Multi-Input Multi-Output (MIMO) and Multi-Input Single-Output (MISO).In this work, we propose two types of deep models to solve the regression problem involving weather forecasting, namely Multi-Input Multi-Output (MIMO) and Multi-Input Single-Output (MISO).</p>
        <p>In the MIMO, all the weather parameters (i.e. 10 surface weather parameters in this study) are fed into the network, which is expected to predict the same number of parameters (i.e. 10 parameters in this study) as the output. Therefore, only one model is required for weather forecasting. In MISO approach, all of the weather parameters (i.e. 10 surface weather parameters in this study) are fed into the network, which is expected to predict a single parameter. Whereas, in the MISO, 10 different models are required as each of them is trained to predict a particular weather parameter.In the MIMO, all the weather parameters (i.e. 10 surface weather parameters in this study) are fed into the network, which is expected to predict the same number of parameters (i.e. 10 parameters in this study) as the output. Therefore, only one model is required for weather forecasting. In MISO approach, all of the weather parameters (i.e. 10 surface weather parameters in this study) are fed into the network, which is expected to predict a single parameter. Whereas, in the MISO, 10 different models are required as each of them is trained to predict a particular weather parameter.</p>
        <p>The main characteristic of the TCN is that the network can take a sequence of any length as inputs and map it to an output sequence of the same length, just similar to the RNN categories. These networks involve causal convolutions and initially developed to examine long-range patterns using a hierarchy of temporal convolutional filters [8], [61], [62]. TCN architecture is quite simple and is informed by recent generic convolutional architectures for sequential data. Figure 4 shows the general deep learning with stacked TCN architecture. The main purpose of the dilation to introduce a fixed step between every adjacent filter taps, and larger dilations and larger filter sizes k enable effectively expanding the receptive filed [8], [62]. The increment of ğ‘‘ exponentially increase the depth of the network in these convolutions and this guarantees that there is some filters that hits each input within the effective history [62] .The main characteristic of the TCN is that the network can take a sequence of any length as inputs and map it to an output sequence of the same length, just similar to the RNN categories. These networks involve causal convolutions and initially developed to examine long-range patterns using a hierarchy of temporal convolutional filters [8], [61], [62]. TCN architecture is quite simple and is informed by recent generic convolutional architectures for sequential data. Figure 4 shows the general deep learning with stacked TCN architecture. The main purpose of the dilation to introduce a fixed step between every adjacent filter taps, and larger dilations and larger filter sizes k enable effectively expanding the receptive filed [8], [62]. The increment of ğ‘‘ exponentially increase the depth of the network in these convolutions and this guarantees that there is some filters that hits each input within the effective history [62] .</p>
        <p>Similar to LSTM in section 5.1.1 and section 5.1.2, we also use the TCN in our proposed MIMO and MISO models.Similar to LSTM in section 5.1.1 and section 5.1.2, we also use the TCN in our proposed MIMO and MISO models.</p>
        <p>As discussed in Section 5.1 and Section 5.2, the LSTM and TCN deep learning approaches are proposed for weather forecasting. The MIMO and MISO are the two types of deep models to solve the regression problem. Therefore, proposed models for weather forecasting are MIMO-LSTM, MISO-LSTM, MIMO-TCN, and MISO-TCN. Deep learning models are discussed in [11], [35], [40], [43], [44] are single input single output models. The MISO are experimented in [36], [37] and a MIMO is discussed in [64]. All these models can be accepted up to four input parameters at a given time. Increased number of input parameters will increase the forecasting accuracy of an NWP model by distinguishing interrelationships among parameters [17], [50]. Our proposed model uses ten input parameters which has not been explored in the past for neural network-based weather forecasting. Subsequently, the research discusses in this article is explored for both MIMO and MISO.As discussed in Section 5.1 and Section 5.2, the LSTM and TCN deep learning approaches are proposed for weather forecasting. The MIMO and MISO are the two types of deep models to solve the regression problem. Therefore, proposed models for weather forecasting are MIMO-LSTM, MISO-LSTM, MIMO-TCN, and MISO-TCN. Deep learning models are discussed in [11], [35], [40], [43], [44] are single input single output models. The MISO are experimented in [36], [37] and a MIMO is discussed in [64]. All these models can be accepted up to four input parameters at a given time. Increased number of input parameters will increase the forecasting accuracy of an NWP model by distinguishing interrelationships among parameters [17], [50]. Our proposed model uses ten input parameters which has not been explored in the past for neural network-based weather forecasting. Subsequently, the research discusses in this article is explored for both MIMO and MISO.</p>
        <p>Moreover, [44] uses the bidirectional recurrent network with weather-related input parameters successfully to predict the wind power up to 6 hours. Therefore, bidirectional LSTM experiments in long-term forecasting and compare with the proposed model. Most of the researches discussed in Table 1 are attempted to forecasting a single or few parameters for a specific purpose rather developing a complete weather forecasting model. Our proposed model explores to complete AI-based fine-grained weather forecasting model.Moreover, [44] uses the bidirectional recurrent network with weather-related input parameters successfully to predict the wind power up to 6 hours. Therefore, bidirectional LSTM experiments in long-term forecasting and compare with the proposed model. Most of the researches discussed in Table 1 are attempted to forecasting a single or few parameters for a specific purpose rather developing a complete weather forecasting model. Our proposed model explores to complete AI-based fine-grained weather forecasting model.</p>
        <p>We use 
            <rs type="software">Keras</rs> as a tool to implement both LSTM and TCN deep learning networks [59], [65]- [67].
        </p>
        <p>This is an empirical-based study and is focused on analysing the quantitative temporal weather data. There are 10 surface weather parameters utilised in this research for weather prediction. These weather parameters are identified by considering their usefulness in precision farming. Moreover, these surface parameters can be captured at a chosen location using various sensors using a local weather station.This is an empirical-based study and is focused on analysing the quantitative temporal weather data. There are 10 surface weather parameters utilised in this research for weather prediction. These weather parameters are identified by considering their usefulness in precision farming. Moreover, these surface parameters can be captured at a chosen location using various sensors using a local weather station.</p>
        <p>The surface weather parameters are observed and reported in for monitoring and forecasting purposes [68]. In our previous study, we defined 10 surface weather parameters for the forecasting, which can be extruded from GRIB data using the WRF model [67]. Those 10 surface parameters, as shown in Table 2. The surface parameters of wind direction and wind speed can be calculated from the WRF surface variables ğ‘ˆ 10 and ğ‘‰ 10 [4]. Table 2 shows the surface weather parameters which are utilised in this research. The XLAT-Reference Latitude and XLONG-Reference Longitude parameters are used with each data point for the location identification.The surface weather parameters are observed and reported in for monitoring and forecasting purposes [68]. In our previous study, we defined 10 surface weather parameters for the forecasting, which can be extruded from GRIB data using the WRF model [67]. Those 10 surface parameters, as shown in Table 2. The surface parameters of wind direction and wind speed can be calculated from the WRF surface variables ğ‘ˆ 10 and ğ‘‰ 10 [4]. Table 2 shows the surface weather parameters which are utilised in this research. The XLAT-Reference Latitude and XLONG-Reference Longitude parameters are used with each data point for the location identification.</p>
        <p>As described in Sections 4, the GRIB data is used to run the WRF model. A total of 12 weather parameters is extracted from the period of January 2018 to May 2018. This is used as the training dataset to train the proposed models. Similarly, the parameters in June 2018 data are used to test the network. This is to test different trained deep models to identify the best model for forecasting. The parameters in July 2018 are considered as the validation dataset, which is used as the ground truth to compare perdition from the best model. The WRF model is being run in forecast mode using the same format GRIB data for the month of July 2018 to evaluate the overall prediction performance of the WRF model.As described in Sections 4, the GRIB data is used to run the WRF model. A total of 12 weather parameters is extracted from the period of January 2018 to May 2018. This is used as the training dataset to train the proposed models. Similarly, the parameters in June 2018 data are used to test the network. This is to test different trained deep models to identify the best model for forecasting. The parameters in July 2018 are considered as the validation dataset, which is used as the ground truth to compare perdition from the best model. The WRF model is being run in forecast mode using the same format GRIB data for the month of July 2018 to evaluate the overall prediction performance of the WRF model.</p>
        <p>The training data set has been normalised to keep each value in between -1 and 1, and the same maximum and minimum variable values are used to normalise the testing and the evaluation data set. We apply a sliding window of seven days temporal resolution on each dataset as input to the model and the temporal resolution of next 3 hours data as the model's output. By using this sliding window method, the size of our training dataset is ~6.5GB with a sample size of 675,924, and the testing dataset is ~1.19GB with a sample size of 114,450.The training data set has been normalised to keep each value in between -1 and 1, and the same maximum and minimum variable values are used to normalise the testing and the evaluation data set. We apply a sliding window of seven days temporal resolution on each dataset as input to the model and the temporal resolution of next 3 hours data as the model's output. By using this sliding window method, the size of our training dataset is ~6.5GB with a sample size of 675,924, and the testing dataset is ~1.19GB with a sample size of 114,450.</p>
        <p>There are six different configurations are considered for both MIMO-LSTM and MISO-LSTM models. Figure 2 depicts the general architecture of the proposed model. Each configuration has a different number of layers, and each layer consists of a different number of nodes. Each configuration is experimented with:There are six different configurations are considered for both MIMO-LSTM and MISO-LSTM models. Figure 2 depicts the general architecture of the proposed model. Each configuration has a different number of layers, and each layer consists of a different number of nodes. Each configuration is experimented with:</p>
        <p>â€¢ Fixed learning rate (LR) and adaptive learning rate [69]. In the fixed learning rate, we set LR=0.01.â€¢ Fixed learning rate (LR) and adaptive learning rate [69]. In the fixed learning rate, we set LR=0.01.</p>
        <p>In the adaptive learning rate method, the LR (initial LR=0.1) is reduced to half of the current LR in every 20 epochs to find the optimal model with best LR.In the adaptive learning rate method, the LR (initial LR=0.1) is reduced to half of the current LR in every 20 epochs to find the optimal model with best LR.</p>
        <p>â€¢ Adam [70] and SGD [71] optimizers to minimise a given cost function [59], [65].â€¢ Adam [70] and SGD [71] optimizers to minimise a given cost function [59], [65].</p>
        <p>The MIMO-TCN and MISO-TCN approaches have experimented with different configurations and controls, such as;The MIMO-TCN and MISO-TCN approaches have experimented with different configurations and controls, such as;</p>
        <p>â€¢ Filter sizes: 32, 64, 128, 256, and 512 â€¢ Stacked TCN layers: 1, 2, 3, and 4 and â€¢ With different activation functions such as 'linear' and 'tanh'â€¢ Filter sizes: 32, 64, 128, 256, and 512 â€¢ Stacked TCN layers: 1, 2, 3, and 4 and â€¢ With different activation functions such as 'linear' and 'tanh'</p>
        <p>According to [8], [62], [73], the following controls are kept constant within these experiments as these do not impact on final results significantly in the regression model for time-series data; kernel size: 2, dilations: 7, where dilation values are: 1, 2, 4, 8, 16, 32, 64, batch size-64, and dropout rate-0, learning rate-0.01.According to [8], [62], [73], the following controls are kept constant within these experiments as these do not impact on final results significantly in the regression model for time-series data; kernel size: 2, dilations: 7, where dilation values are: 1, 2, 4, 8, 16, 32, 64, batch size-64, and dropout rate-0, learning rate-0.01.</p>
        <p>The proposed deep regression models are evaluated using the most common metrics of Mean Squared Error (MSE), which is calculated as:The proposed deep regression models are evaluated using the most common metrics of Mean Squared Error (MSE), which is calculated as:</p>
        <p>Where ğ‘¦ ğ‘ is the actual expected output, ğ‘¦ ğ‘ is the model's prediction, and ğ‘› is number of samples.Where ğ‘¦ ğ‘ is the actual expected output, ğ‘¦ ğ‘ is the model's prediction, and ğ‘› is number of samples.</p>
        <p>Performances of the proposed LSTM and TCN models are compared with the following three types of baseline approaches. These approaches do not consider the temporal information rather count as another dimension in multivariate weather data. We use both linear and RBF (Radial Basis Function) kernels for SVR in our experiments and use the grid search algorithm technique to optimize both C and Î³ parameters. In linear kernel, the parameter C is selected among the range [0.01 -10000] with multiples of 10. In RGB kernel, the parameters C is selected as above but Î³ is selected among the range [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9]. For RF [73], we select number of trees as [100, 250, 500]. For ARIMA model, we use the parameters p=2, d=0, and q=1 [74]. For VAR and VECM, the auto option is selected for weather forecasting [75], [76]. The given software package is used for the AFE [77].Performances of the proposed LSTM and TCN models are compared with the following three types of baseline approaches. These approaches do not consider the temporal information rather count as another dimension in multivariate weather data. We use both linear and RBF (Radial Basis Function) kernels for SVR in our experiments and use the grid search algorithm technique to optimize both C and Î³ parameters. In linear kernel, the parameter C is selected among the range [0.01 -10000] with multiples of 10. In RGB kernel, the parameters C is selected as above but Î³ is selected among the range [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9]. For RF [73], we select number of trees as [100, 250, 500]. For ARIMA model, we use the parameters p=2, d=0, and q=1 [74]. For VAR and VECM, the auto option is selected for weather forecasting [75], [76]. The given software package is used for the AFE [77].</p>
        <p>The baseline performances are compared with the proposed LSTM and TCN networks. These models are evaluated using the testing dataset to select the optimal model or a model with the least MSE, which can be used as a tool for future forecasting. The selected optimal is used to forecast the weather parameters for the validation dataset (Model Prediction), and the model predicted values are evaluated with respect to the ground truth. Similarly, the WRF model has been run in forecast mode using the same format GRIB data for the month of July 2018 (WRF Prediction). These WRF predicted values are evaluated with respect to the ground truth. Then, we compare the model prediction and WRF perdition to determine the possibility to use the proposed model for shortterm weather forecasting (i.e. 3-hour prediction). Then, the optimal model is re-tuned for long-term weather forecasting, such as 6, 9, 12, 24, and 48 hours. Similar to the short-term forecasting, we compare the model predictions and WRF predictions to determine up to what extent the proposed model can be used for weather forecasting.The baseline performances are compared with the proposed LSTM and TCN networks. These models are evaluated using the testing dataset to select the optimal model or a model with the least MSE, which can be used as a tool for future forecasting. The selected optimal is used to forecast the weather parameters for the validation dataset (Model Prediction), and the model predicted values are evaluated with respect to the ground truth. Similarly, the WRF model has been run in forecast mode using the same format GRIB data for the month of July 2018 (WRF Prediction). These WRF predicted values are evaluated with respect to the ground truth. Then, we compare the model prediction and WRF perdition to determine the possibility to use the proposed model for shortterm weather forecasting (i.e. 3-hour prediction). Then, the optimal model is re-tuned for long-term weather forecasting, such as 6, 9, 12, 24, and 48 hours. Similar to the short-term forecasting, we compare the model predictions and WRF predictions to determine up to what extent the proposed model can be used for weather forecasting.</p>
        <p>There are three types of results, namely: 1) a comparison of various machine learning techniques, statistical forecasting approaches, and a dynamic ensemble method with the proposed approach for weather forecasting, 2) performance of short-term weather forecasting, and 3) performance of long-term weather forecasting using the proposed model. More specifically, the short-term weather forecasting refers to 3-hours weather prediction, and long-term weather forecasting refers to 6-hours, 9-hours, 12-hours, 24-hours, and 48-hours weather predictions.There are three types of results, namely: 1) a comparison of various machine learning techniques, statistical forecasting approaches, and a dynamic ensemble method with the proposed approach for weather forecasting, 2) performance of short-term weather forecasting, and 3) performance of long-term weather forecasting using the proposed model. More specifically, the short-term weather forecasting refers to 3-hours weather prediction, and long-term weather forecasting refers to 6-hours, 9-hours, 12-hours, 24-hours, and 48-hours weather predictions.</p>
        <p>As described in Section 6.5, we examine the classic machine learning approaches (i.e. SR, SVR, RF), statistical forecasting approaches (i.e. ARIMA, VAR, and VECM), and a dynamic ensemble method (i.e. AFE). Finally, we compare these performances with the proposed deep models (i.e. MISO-LSTM, MISO-TCN, MIMO-LSTM, MIMO-TCN) consisting of cutting-edge networks such as LSTM and TCN layers. As described in sections 5.1 and 5.2, these models are evaluated using two different regression types, namely MISO and MIMO.As described in Section 6.5, we examine the classic machine learning approaches (i.e. SR, SVR, RF), statistical forecasting approaches (i.e. ARIMA, VAR, and VECM), and a dynamic ensemble method (i.e. AFE). Finally, we compare these performances with the proposed deep models (i.e. MISO-LSTM, MISO-TCN, MIMO-LSTM, MIMO-TCN) consisting of cutting-edge networks such as LSTM and TCN layers. As described in sections 5.1 and 5.2, these models are evaluated using two different regression types, namely MISO and MIMO.</p>
        <p>We evaluate the MISO models to determine the MISO-optimal with the least MSE for weather prediction. Table 3 and Figure 6 represent the comparison of machine learning approaches for MISO. As per information from Table 3 and Figure 6, the MISO-LSTM provides better performance with the least MSE for 6 parameters out of 10. Thus, the LSTM combined model with 10 parameters (i.e. MISO-LSTM) has been selected as the MISO proposed model. Similarly, we evaluate the MIMO models to determine the MIMO-optimal with the least MSE for weather prediction. Table 4 and Figure 7 represent the comparison of machine learning approaches for MISO. We do not consider the approaches ARIMA, VAR, VECM, and AFE in MIMO. Therefore, we compare SR, multi-output SVR [78], and RF with the proposed deep models MIMO-LSTM and MIMO-TCN. The results are subsequently evaluated via the Mean Squared Error. This is used to assess the best model (i.e. least MSE) after comparing the performance of all models. As per Table 4 and Figure 7, the MIMO-LSTM provides high accuracy output with least MSE for 6 parameters out of 10. Therefore, the MIMO-LSTM has been selected as the proposed model (i.e. MIMO-optimal).We evaluate the MISO models to determine the MISO-optimal with the least MSE for weather prediction. Table 3 and Figure 6 represent the comparison of machine learning approaches for MISO. As per information from Table 3 and Figure 6, the MISO-LSTM provides better performance with the least MSE for 6 parameters out of 10. Thus, the LSTM combined model with 10 parameters (i.e. MISO-LSTM) has been selected as the MISO proposed model. Similarly, we evaluate the MIMO models to determine the MIMO-optimal with the least MSE for weather prediction. Table 4 and Figure 7 represent the comparison of machine learning approaches for MISO. We do not consider the approaches ARIMA, VAR, VECM, and AFE in MIMO. Therefore, we compare SR, multi-output SVR [78], and RF with the proposed deep models MIMO-LSTM and MIMO-TCN. The results are subsequently evaluated via the Mean Squared Error. This is used to assess the best model (i.e. least MSE) after comparing the performance of all models. As per Table 4 and Figure 7, the MIMO-LSTM provides high accuracy output with least MSE for 6 parameters out of 10. Therefore, the MIMO-LSTM has been selected as the proposed model (i.e. MIMO-optimal).</p>
        <p>In both MIMO and MISO, the LSTM and the TCN produce high performance with smaller errors compared to the classic machine learning approaches and statistical forecasting approaches as presented in Figure 6 and Figure 7. The reason is that the selected parameters do not follow a linear path within selected sequential timeslots [79], [80] and there is a non-linear interrelationship among parameters [6], [56], [81]. Besides, the sequential information is not encoded by the classic machine learning approaches and statistical forecasting models. The LSTM and TCN encode both multivariate and sequential information by taking them into another dimension in the input data [6], [62], [82].In both MIMO and MISO, the LSTM and the TCN produce high performance with smaller errors compared to the classic machine learning approaches and statistical forecasting approaches as presented in Figure 6 and Figure 7. The reason is that the selected parameters do not follow a linear path within selected sequential timeslots [79], [80] and there is a non-linear interrelationship among parameters [6], [56], [81]. Besides, the sequential information is not encoded by the classic machine learning approaches and statistical forecasting models. The LSTM and TCN encode both multivariate and sequential information by taking them into another dimension in the input data [6], [62], [82].</p>
        <p>The least MSE for the MIMO is identified in the configuration with three LSTM layers, with 128, 512, and 256 number of nodes, respectively (i.e. MIMO-optimal model). We use the SGD optimiser with a fixed learning rate of 0.01 to optimise the MSE regression loss function. The model is trained for 230 epochs. In MISO, all these 10 models have different configurations with a different number of LSTM layers and nodes, activation functions, and optimisers (i.e. MISO-optimal). Table 5 and Figure 8 graphically represents the comparison of MSE in each variable for both MIMO-optimal and MISO-optimal. Table 5 shows the comparison of MSE in each variable for both MIMO and MISO. Figure 8 graphically represents these values to get an idea of whether to use the MIMO model or the MISO combined model to use as the best model for future predictions.The least MSE for the MIMO is identified in the configuration with three LSTM layers, with 128, 512, and 256 number of nodes, respectively (i.e. MIMO-optimal model). We use the SGD optimiser with a fixed learning rate of 0.01 to optimise the MSE regression loss function. The model is trained for 230 epochs. In MISO, all these 10 models have different configurations with a different number of LSTM layers and nodes, activation functions, and optimisers (i.e. MISO-optimal). Table 5 and Figure 8 graphically represents the comparison of MSE in each variable for both MIMO-optimal and MISO-optimal. Table 5 shows the comparison of MSE in each variable for both MIMO and MISO. Figure 8 graphically represents these values to get an idea of whether to use the MIMO model or the MISO combined model to use as the best model for future predictions.</p>
        <p>According to Figure 8, there is no major gap between MSE values for each variable when compare the MIMOoptimal and MISO-optimal. These differences are less than 0.04 for each variable. These error figures are significantly smaller. Moreover, the MISO-optimal requires 10 different models for the prediction of 10 different weather parameters. Therefore, we consider the MIMO-optimal (i.e. MIMO-LSTM) model as a tool for future forecasting since it is easier to handle and less time and power consumption (only one model to run) than running 10 different models of MISO-optimal. As described in Section 6.5, the validation dataset is utilised to get weather prediction using the proposed model. Similarly, the WRF model is run in forecast mode using the July 2018 data to compare results. Both WRF and model predicted values are compared with respect to the ground truth and calculated the MSE. Table 6 and Figure 9 When comparing Table 6 and Figure 9, the proposed deep model (i.e. MIMO-LSTM) provides comparatively best results (bolded in the table) on eight occasions out of 10. The WRF model provides the best results for the Snow and Soil Moisture (SMOIS) variables. On both occasions, these error figures are quite small. For example, MSE for the variable snow is 0.0168574 kg/m 2 . This is quite a small and therefore, negligible. Similarly, the SMOIS has got a minimal and negligible error value. Figure 9k shows an overall comparison of both models.According to Figure 8, there is no major gap between MSE values for each variable when compare the MIMOoptimal and MISO-optimal. These differences are less than 0.04 for each variable. These error figures are significantly smaller. Moreover, the MISO-optimal requires 10 different models for the prediction of 10 different weather parameters. Therefore, we consider the MIMO-optimal (i.e. MIMO-LSTM) model as a tool for future forecasting since it is easier to handle and less time and power consumption (only one model to run) than running 10 different models of MISO-optimal. As described in Section 6.5, the validation dataset is utilised to get weather prediction using the proposed model. Similarly, the WRF model is run in forecast mode using the July 2018 data to compare results. Both WRF and model predicted values are compared with respect to the ground truth and calculated the MSE. Table 6 and Figure 9 When comparing Table 6 and Figure 9, the proposed deep model (i.e. MIMO-LSTM) provides comparatively best results (bolded in the table) on eight occasions out of 10. The WRF model provides the best results for the Snow and Soil Moisture (SMOIS) variables. On both occasions, these error figures are quite small. For example, MSE for the variable snow is 0.0168574 kg/m 2 . This is quite a small and therefore, negligible. Similarly, the SMOIS has got a minimal and negligible error value. Figure 9k shows an overall comparison of both models.</p>
        <p>As there are 125,373 samples in the July 2018 evaluation data, the proposed deep model and the WRF model will produce a similar number of samples as the predicted data. It is difficult to visualise all of these predictions because of the large sample size and therefore, a random sample of the 100 samples has been taken from the test set to compare with the respective ground truth. Figure 10As there are 125,373 samples in the July 2018 evaluation data, the proposed deep model and the WRF model will produce a similar number of samples as the predicted data. It is difficult to visualise all of these predictions because of the large sample size and therefore, a random sample of the 100 samples has been taken from the test set to compare with the respective ground truth. Figure 10</p>
        <p>As described in Section 7.2, the proposed model (i.e. MIMO-LSTM) can be utilised for short-term weather forecasting, and it yields more accurate results compare to the well-known WRF model. In this section, our study is focused on exploring long-term weather prediction using the same historical weather data with 10 surface weather parameters.As described in Section 7.2, the proposed model (i.e. MIMO-LSTM) can be utilised for short-term weather forecasting, and it yields more accurate results compare to the well-known WRF model. In this section, our study is focused on exploring long-term weather prediction using the same historical weather data with 10 surface weather parameters.</p>
        <p>As discussed in Section 7.1, the proposed model provides better performance compared to other machine learning techniques. Therefore, we use the same deep learning model with the LSTM layers for the long-term weather forecasting with the following variations. All these three variants use the same configuration and controls, which are comparable to the proposed MIMO-LSTM model. a) Load the MIMO-LSTM optimal model weights (3-hour) and fine-tune models for the long-term forecasting (shortened form: LSTM LW) b) Train models for each time frame without loading the optimal model weights (shortened form: LSTM WL). That is train the model at the beginning of the training dataset and new labels. c) We have also experimented with Bi-directional LSTM (Bi-LSTM). Compared to the LSTM, the Bi-LSTM has used two layers; one layer performs the operations following the forward direction (timeseries data) of the data sequence, and the other layer applies its operations on in the reverse direction of the data sequence [83].As discussed in Section 7.1, the proposed model provides better performance compared to other machine learning techniques. Therefore, we use the same deep learning model with the LSTM layers for the long-term weather forecasting with the following variations. All these three variants use the same configuration and controls, which are comparable to the proposed MIMO-LSTM model. a) Load the MIMO-LSTM optimal model weights (3-hour) and fine-tune models for the long-term forecasting (shortened form: LSTM LW) b) Train models for each time frame without loading the optimal model weights (shortened form: LSTM WL). That is train the model at the beginning of the training dataset and new labels. c) We have also experimented with Bi-directional LSTM (Bi-LSTM). Compared to the LSTM, the Bi-LSTM has used two layers; one layer performs the operations following the forward direction (timeseries data) of the data sequence, and the other layer applies its operations on in the reverse direction of the data sequence [83].</p>
        <p>The following Table 7 shows the comparison of these three variations for each timeslot. As shown in Table 7, the Bi-LSTM provides slightly better results compared to the LSTM LW except for the timeslot 3-hour. The LSTM WL produces weaker results compared to the both LSTM LW. The reason is that the LSTM LW used its optimal weight, which is already configured to retrain and yield a prediction. Moreover, this is re-tune the model which is matched to the new dataset [58]. The Bi-LSTM is also trained the model at the beginning similar to the LSTM WL. However, the Bi-LSTM provides more accurate results due to the ability to preserve the past and future values [83].The following Table 7 shows the comparison of these three variations for each timeslot. As shown in Table 7, the Bi-LSTM provides slightly better results compared to the LSTM LW except for the timeslot 3-hour. The LSTM WL produces weaker results compared to the both LSTM LW. The reason is that the LSTM LW used its optimal weight, which is already configured to retrain and yield a prediction. Moreover, this is re-tune the model which is matched to the new dataset [58]. The Bi-LSTM is also trained the model at the beginning similar to the LSTM WL. However, the Bi-LSTM provides more accurate results due to the ability to preserve the past and future values [83].</p>
        <p>The only drawback of the Bi-LSTM is that time taken to training, testing, and predicting data [84]. This is less efficient compared to the LSTM LW. Moreover, as can be observed in Table 7, there is a slight gap in the overall figures of MSE in both LSTM LW and Bi-LSTM. Therefore, we have selected the LSTM LW method for longterm forecasting for an effective and efficient outcome.The only drawback of the Bi-LSTM is that time taken to training, testing, and predicting data [84]. This is less efficient compared to the LSTM LW. Moreover, as can be observed in Table 7, there is a slight gap in the overall figures of MSE in both LSTM LW and Bi-LSTM. Therefore, we have selected the LSTM LW method for longterm forecasting for an effective and efficient outcome.</p>
        <p>The proposed model (i.e. MIMO-LSTM) consists of three LSTM layers with other controls. As described in the section 7.3.1 the LSTM with loading the optimal weight method is used for the long-term weather prediction. Therefore, the optimal model is re-tuned (i.e. load optimal model weight and re-train models) for timeslots 3-hour, 6-hour, 9-hour, 12-hour, 24-hour, and 48-hour. While re-tuning, the optimal models are found in different epochs such as 80, 10, 10, 10, and 10 for timeslots 6, 9, 12, 24, and 48 hours, respectively. Similar to the short-term weather forecasting, the optimal model for each timeslot is used to forecast the weather parameters for the July 2018 data (model prediction), and the model predicted values are evaluated with respect to the ground truth. The WRF model has been run in forecast mode using the same format GRIB data for the month of July 2018 (WRF prediction) based on the same conditions as model prediction (i.e. input seven days data and predict weather parameters for timeslot 6, 9, 12, 24 and 48). The WRF predicted values are evaluated with respect to the ground truth. Finally, compare the model prediction and WRF prediction to determine what extent the deep learning model can be used for weather forecasting. Figure 11 According to the results presented in Figure 11, it is obvious that the WRF model produces better forecasting results for the very long-term compared to the deep learning model. The reason is that the WRF model is combined with many other climate models [4], [85], [86] and data is coming to the system globally [4], [52]. The deep learning model has predicted these outputs based on five months of training data. We could receive better results if we increase the size of the training dataset [59]. The Rainc and Rainnc parameters show much better results in the deep learning model compared to the WRF model for long-term forecasting. The experiments of [40] already proved that the deep learning neural networks yield the highest accuracy for rain prediction.The proposed model (i.e. MIMO-LSTM) consists of three LSTM layers with other controls. As described in the section 7.3.1 the LSTM with loading the optimal weight method is used for the long-term weather prediction. Therefore, the optimal model is re-tuned (i.e. load optimal model weight and re-train models) for timeslots 3-hour, 6-hour, 9-hour, 12-hour, 24-hour, and 48-hour. While re-tuning, the optimal models are found in different epochs such as 80, 10, 10, 10, and 10 for timeslots 6, 9, 12, 24, and 48 hours, respectively. Similar to the short-term weather forecasting, the optimal model for each timeslot is used to forecast the weather parameters for the July 2018 data (model prediction), and the model predicted values are evaluated with respect to the ground truth. The WRF model has been run in forecast mode using the same format GRIB data for the month of July 2018 (WRF prediction) based on the same conditions as model prediction (i.e. input seven days data and predict weather parameters for timeslot 6, 9, 12, 24 and 48). The WRF predicted values are evaluated with respect to the ground truth. Finally, compare the model prediction and WRF prediction to determine what extent the deep learning model can be used for weather forecasting. Figure 11 According to the results presented in Figure 11, it is obvious that the WRF model produces better forecasting results for the very long-term compared to the deep learning model. The reason is that the WRF model is combined with many other climate models [4], [85], [86] and data is coming to the system globally [4], [52]. The deep learning model has predicted these outputs based on five months of training data. We could receive better results if we increase the size of the training dataset [59]. The Rainc and Rainnc parameters show much better results in the deep learning model compared to the WRF model for long-term forecasting. The experiments of [40] already proved that the deep learning neural networks yield the highest accuracy for rain prediction.</p>
        <p>Contrarily, the SMOIS and snow parameters show weak results in deep learning compared to the WRF model at all timeslots. Simply, these error patterns are rather low (maximum error: Snow-0.016kg/m2, SMOIS-0.00035 m3/m3) and can be negligible. This could be resolved by increasing the size of the sample data. All other occasions, the deep learning model provide more accurate prediction compared to the WRF model up to some extent, than the WRF model produces better prediction compared to the deep learning model. Figure 12 shows the comparison of overall error values of the WRF model and proposed deep learning model. As per Figure 13, the red line-chart (deep model prediction) followed closely to the blue line-chart (ground truth) up to some extent and diverted when time increases in many parameters. The green line-chart (WRF model prediction) also diverted from the blue line-chart when time increased, but this diversion is relatively small compared with the red line-chart. As shown in Figure 13 (vi) and 12 (vii), the rainc and rainnc values are accurate in the deep learning model compared to the WRF model for up to 48 hours. As discussed earlier, The WRF model produces a better prediction for the Snow and SMOIS parameters. As shown in Figure 13 (x), the difference is negligible for the parameter SMOIS. As shown in Figure 13 (viii), the maximum snow values are shown in the 3 hours line-chart. This value is equal to 0.24 kg/m 2, and this is a relatively negligible figure. Overall, the deep learning model delivers a better forecasting prediction compared to the WRF model for up to 12 hours.Contrarily, the SMOIS and snow parameters show weak results in deep learning compared to the WRF model at all timeslots. Simply, these error patterns are rather low (maximum error: Snow-0.016kg/m2, SMOIS-0.00035 m3/m3) and can be negligible. This could be resolved by increasing the size of the sample data. All other occasions, the deep learning model provide more accurate prediction compared to the WRF model up to some extent, than the WRF model produces better prediction compared to the deep learning model. Figure 12 shows the comparison of overall error values of the WRF model and proposed deep learning model. As per Figure 13, the red line-chart (deep model prediction) followed closely to the blue line-chart (ground truth) up to some extent and diverted when time increases in many parameters. The green line-chart (WRF model prediction) also diverted from the blue line-chart when time increased, but this diversion is relatively small compared with the red line-chart. As shown in Figure 13 (vi) and 12 (vii), the rainc and rainnc values are accurate in the deep learning model compared to the WRF model for up to 48 hours. As discussed earlier, The WRF model produces a better prediction for the Snow and SMOIS parameters. As shown in Figure 13 (x), the difference is negligible for the parameter SMOIS. As shown in Figure 13 (viii), the maximum snow values are shown in the 3 hours line-chart. This value is equal to 0.24 kg/m 2, and this is a relatively negligible figure. Overall, the deep learning model delivers a better forecasting prediction compared to the WRF model for up to 12 hours.</p>
        <p>As described in Section 7.3, the proposed model can be used for weather prediction. Even, this model generates more accurate predictions compared to the well-recognised WRF model for up to 12 hours. We use historical weather data to evaluate and validate these models. The only issue is we still use the WRF model to extract GRIB data to use as input for the new model (we use GFS GRIB data). On the other hand, it requires a minimum of three hours of access GFS data after taking the atmospheric measurements. This includes the time taken to upload data to the website [4], [87]. In addition, the WRF model also taken the time to extract the GFS data depend on the computer system. Hence, the input data which are used in the new model are not the current atmospheric measurement data (i.e. older more than 3 hours). Therefore, it is not practicable to use WRF data with the new model, and it will be highly beneficial to consider the use of local weather station data for weather forecasting.As described in Section 7.3, the proposed model can be used for weather prediction. Even, this model generates more accurate predictions compared to the well-recognised WRF model for up to 12 hours. We use historical weather data to evaluate and validate these models. The only issue is we still use the WRF model to extract GRIB data to use as input for the new model (we use GFS GRIB data). On the other hand, it requires a minimum of three hours of access GFS data after taking the atmospheric measurements. This includes the time taken to upload data to the website [4], [87]. In addition, the WRF model also taken the time to extract the GFS data depend on the computer system. Hence, the input data which are used in the new model are not the current atmospheric measurement data (i.e. older more than 3 hours). Therefore, it is not practicable to use WRF data with the new model, and it will be highly beneficial to consider the use of local weather station data for weather forecasting.</p>
        <p>In this article, we demonstrate that the proposed lightweight deep model can be utilised for weather forecasting up to 12 hours for 10 surface weather parameters. The model outperformed the state-of-the-art WRF model for up to 12 hours. The proposed model could run on a standalone computer, and it could easily be deployed in a selected geographical region for fine-grained short to medium-term weather prediction. Furthermore, the proposed model is able to overcome some challenges within the WRF model, such as the understanding of the model and its installation, as well as its execution and portability. In particular, the deep model is portable and can be easily installed into a Python environment for effective results [17], [59]. This process is highly efficient compared to the WRF model. This research is carried out using ten different surface weather parameters, and an increased number of inputs would probably lead to enhanced results. For example, there are 36 different pressure levels defined in the WRF model [17]. Only the pressure at two meters is considered within this research. There is a possibility to increase the accuracy of the results if we introduce all 36 possible pressure levels to the proposed model. However, it will increase the model complexity requiring a large number of parameters to estimate. Furthermore, January to May weather data is utilised for training the deep model, and the increase in the size of training dataset could help towards improved results in a deep learning network [59], [88].In this article, we demonstrate that the proposed lightweight deep model can be utilised for weather forecasting up to 12 hours for 10 surface weather parameters. The model outperformed the state-of-the-art WRF model for up to 12 hours. The proposed model could run on a standalone computer, and it could easily be deployed in a selected geographical region for fine-grained short to medium-term weather prediction. Furthermore, the proposed model is able to overcome some challenges within the WRF model, such as the understanding of the model and its installation, as well as its execution and portability. In particular, the deep model is portable and can be easily installed into a Python environment for effective results [17], [59]. This process is highly efficient compared to the WRF model. This research is carried out using ten different surface weather parameters, and an increased number of inputs would probably lead to enhanced results. For example, there are 36 different pressure levels defined in the WRF model [17]. Only the pressure at two meters is considered within this research. There is a possibility to increase the accuracy of the results if we introduce all 36 possible pressure levels to the proposed model. However, it will increase the model complexity requiring a large number of parameters to estimate. Furthermore, January to May weather data is utilised for training the deep model, and the increase in the size of training dataset could help towards improved results in a deep learning network [59], [88].</p>
        <p>Besides, we used the MIMO approach within this research to predict weather data. Table 4 and Figure 7 shows that the MISO approach produces better MSE values compared to the MIMO. Therefore, there is a huge potential that the MIMO approach will increase the accuracy of the results; even this method is less efficient compared to the MIMO. Besides, the Bi-LSTM yields high accuracy long-term prediction compared to the LSTM, as presented in Table 6. Therefore, we could get more accurate results if we use Bi-LSTM; even this method is not efficient due to high time-consumption.Besides, we used the MIMO approach within this research to predict weather data. Table 4 and Figure 7 shows that the MISO approach produces better MSE values compared to the MIMO. Therefore, there is a huge potential that the MIMO approach will increase the accuracy of the results; even this method is less efficient compared to the MIMO. Besides, the Bi-LSTM yields high accuracy long-term prediction compared to the LSTM, as presented in Table 6. Therefore, we could get more accurate results if we use Bi-LSTM; even this method is not efficient due to high time-consumption.</p>
        <p>These experiments show that we can apply the neural network approach for weather prediction. Based on the geographical appearance of location (such as the top of a mountain, land covered by several mountains, the slope of the land, etc.) the regional weather forecasting may not be accurate. As a solution, we could develop a lightweight (neural network based) short-term weather forecasting system for the community of users utilising weather station data. These are our future experimentation.These experiments show that we can apply the neural network approach for weather prediction. Based on the geographical appearance of location (such as the top of a mountain, land covered by several mountains, the slope of the land, etc.) the regional weather forecasting may not be accurate. As a solution, we could develop a lightweight (neural network based) short-term weather forecasting system for the community of users utilising weather station data. These are our future experimentation.</p>
        <p>This research work is partly supported by Clive Blaker and Rich Kavanagh (Precision Decisions Ltd). We are grateful to Prof Mark Anderson (Former Professor at Edge Hill University) for his valuable inputs and support at the initial stage of this study. We are also grateful to Dr Alan Gadian (National Centre for Atmospheric Sciences, University of Leeds) for his valuable support to identify weather parameters.This research work is partly supported by Clive Blaker and Rich Kavanagh (Precision Decisions Ltd). We are grateful to Prof Mark Anderson (Former Professor at Edge Hill University) for his valuable inputs and support at the initial stage of this study. We are also grateful to Dr Alan Gadian (National Centre for Atmospheric Sciences, University of Leeds) for his valuable support to identify weather parameters.</p>
    </text>
</tei>
