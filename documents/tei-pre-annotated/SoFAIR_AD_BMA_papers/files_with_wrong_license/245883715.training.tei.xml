<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T13:20+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Textual classification of SEC comment letters.Textual classification of SEC comment letters.</p>
        <p>Securities and Exchange Commission (SEC) reviews of reporting companies' annual financial reports represent a significant public enforcement activity relating to financial disclosure regulation in the United States. These reviews are conducted by the Division of Corporation Finance at least once every three years for all public issuers in accordance with Section 408 of the Sarbanes-Oxley Act of 2002 (SOX, 2002). The purpose of an annual report review is to ensure that the issuer is compliant with generally accepted accounting principles and SEC disclosure regulations. As such, annual report reviews represent a form of government oversight over financial reporting, rather than a traditional enforcement activity, such as that conducted by the Division of Enforcement, which is designed to sanction wrongdoing (Heese, Khan and Ramanna, 2017).Securities and Exchange Commission (SEC) reviews of reporting companies' annual financial reports represent a significant public enforcement activity relating to financial disclosure regulation in the United States. These reviews are conducted by the Division of Corporation Finance at least once every three years for all public issuers in accordance with Section 408 of the Sarbanes-Oxley Act of 2002 (SOX, 2002). The purpose of an annual report review is to ensure that the issuer is compliant with generally accepted accounting principles and SEC disclosure regulations. As such, annual report reviews represent a form of government oversight over financial reporting, rather than a traditional enforcement activity, such as that conducted by the Division of Enforcement, which is designed to sanction wrongdoing (Heese, Khan and Ramanna, 2017).</p>
        <p>When the SEC examiner finds one or more issues worthy of a request for clarification, change, or additional disclosure, they issue a comment letter requesting a reply within ten days. The issuer replies in writing, and can request an extension where the ten day timeframe is not feasible. These documents, filed on form UPLOAD for SEC comments, and on form CORRESP for company responses, are publicly available on the SEC's EDGAR web site.When the SEC examiner finds one or more issues worthy of a request for clarification, change, or additional disclosure, they issue a comment letter requesting a reply within ten days. The issuer replies in writing, and can request an extension where the ten day timeframe is not feasible. These documents, filed on form UPLOAD for SEC comments, and on form CORRESP for company responses, are publicly available on the SEC's EDGAR web site.</p>
        <p>The purpose of this study is to better understand the nature and impact of comment letters on financial reporting and firms' information environment. It is important to study comment letters because they are one of the primary disclosure compliance mechanisms for the US securities regulator. The SEC devotes considerable resources to conducting the reviews that generate comment letters, and issuers incur significant costs in responding to comment letters. Companies' responses to comment letters can reveal significant shortcomings in financial reporting practices. Managers and auditors may initiate investigations as a result of SEC comments that lead to the discovery of internal control weaknesses and misstatements. Investors should understand the implications of information revealed in comment letters for their estimates of earnings quality and valuation estimates, and there are prominent examples of investors using comment letters as a source of information, in particular short sellers (e.g., Sandler, 2013), who have the most incentive to iden-tify negative information and publicize it (Ljungqvist and Qian, 2016). 2 Comment letters are of interest to management and auditors as the content of comment letters reflects on firms' financial reporting capabilities. If comment letters reveal deficient disclosures or misstated financial statements, then the resulting corrections or restatements will have negative repercussions for both management and auditors (e.g., Hennes, Leone and Miller, 2014). Understanding the potential significance of a comment letter is therefore useful to management to inform the amount of attention and effort to put into a firm's response. Finally, regulators may find insights in this study since it speaks to the effectiveness of this channel of oversight over financial reporting.The purpose of this study is to better understand the nature and impact of comment letters on financial reporting and firms' information environment. It is important to study comment letters because they are one of the primary disclosure compliance mechanisms for the US securities regulator. The SEC devotes considerable resources to conducting the reviews that generate comment letters, and issuers incur significant costs in responding to comment letters. Companies' responses to comment letters can reveal significant shortcomings in financial reporting practices. Managers and auditors may initiate investigations as a result of SEC comments that lead to the discovery of internal control weaknesses and misstatements. Investors should understand the implications of information revealed in comment letters for their estimates of earnings quality and valuation estimates, and there are prominent examples of investors using comment letters as a source of information, in particular short sellers (e.g., Sandler, 2013), who have the most incentive to iden-tify negative information and publicize it (Ljungqvist and Qian, 2016). 2 Comment letters are of interest to management and auditors as the content of comment letters reflects on firms' financial reporting capabilities. If comment letters reveal deficient disclosures or misstated financial statements, then the resulting corrections or restatements will have negative repercussions for both management and auditors (e.g., Hennes, Leone and Miller, 2014). Understanding the potential significance of a comment letter is therefore useful to management to inform the amount of attention and effort to put into a firm's response. Finally, regulators may find insights in this study since it speaks to the effectiveness of this channel of oversight over financial reporting.</p>
        <p>Several studies use comment letters as a proxy for lower reporting and audit quality (e.g., Gietzmann and Pettinicchio, 2013;Hribar, Kravet and Wilson, 2014), under the expectation that firms with more deficiencies in their financial reports and securities filings are more likely to receive comment letters. The emerging literature examining SEC comment letters illustrates a generally beneficial effect on the information environment of firms that receive them (Johnston and Petacchi, 2017). However, there is a documented lack of an average stock price response to the comment letter disclosure event, implying that comment letters do not present clearly good or bad news, on average (Dechow, Lawrence and Ryans, 2016;Johnston and Petacchi, 2017). This is a somewhat unexpected result, because the issuance of a comment letter is prima facia evidence that SEC reviewers found comment-worthy disclosure issues in an issuer's financial statements. Bozanic, Dietrich and Johnson (2017) shows that comment letters are issued in more than half of reviews in most years, indicating that many comment letters may involve only innocuous comments, or at a minimum that receipt of a comment letter does not, by itself, indicate below-average reporting quality.Several studies use comment letters as a proxy for lower reporting and audit quality (e.g., Gietzmann and Pettinicchio, 2013;Hribar, Kravet and Wilson, 2014), under the expectation that firms with more deficiencies in their financial reports and securities filings are more likely to receive comment letters. The emerging literature examining SEC comment letters illustrates a generally beneficial effect on the information environment of firms that receive them (Johnston and Petacchi, 2017). However, there is a documented lack of an average stock price response to the comment letter disclosure event, implying that comment letters do not present clearly good or bad news, on average (Dechow, Lawrence and Ryans, 2016;Johnston and Petacchi, 2017). This is a somewhat unexpected result, because the issuance of a comment letter is prima facia evidence that SEC reviewers found comment-worthy disclosure issues in an issuer's financial statements. Bozanic, Dietrich and Johnson (2017) shows that comment letters are issued in more than half of reviews in most years, indicating that many comment letters may involve only innocuous comments, or at a minimum that receipt of a comment letter does not, by itself, indicate below-average reporting quality.</p>
        <p>The initial analysis in this study develops a Naive Bayesian (NB) textual classification of comment letters that are expected to be associated with two specific future financial reporting outcomes: restatements and write-downs. A training set of comment letters is coded as being a restatement comment letters if the recipient firm has a restatement in the year following comment letter disclosure, and a not-restatement comment letter if there is no restatement in the year following comment letter disclosure. The NB classifier creates a statistical model based on the differences between words used in the restatement training documents compared to the nonrestatement training documents. When presented with a new comment letter, the model calculates the likelihood that the letter belongs to the restatement class or the non-restatement class. The training sample begins with 10-K comment letters issued in 2006 and 2007, used to predict the class of comment letters issued in 2008, which become the first year of the testing sample. I(NB Restatement) is set to 1 for testing sample comment letters expected to be associated with future restatements, and 0 otherwise, and the process is repeated each year to create a full testing samples that extends through 2016. The process is repeated a second time to create an NB classification signal for write-downs. The NB write-down signal, I(NB Write-Down), is set to 1 for testing sample comment letters expected to be associated with future write-downs, and 0 otherwise.The initial analysis in this study develops a Naive Bayesian (NB) textual classification of comment letters that are expected to be associated with two specific future financial reporting outcomes: restatements and write-downs. A training set of comment letters is coded as being a restatement comment letters if the recipient firm has a restatement in the year following comment letter disclosure, and a not-restatement comment letter if there is no restatement in the year following comment letter disclosure. The NB classifier creates a statistical model based on the differences between words used in the restatement training documents compared to the nonrestatement training documents. When presented with a new comment letter, the model calculates the likelihood that the letter belongs to the restatement class or the non-restatement class. The training sample begins with 10-K comment letters issued in 2006 and 2007, used to predict the class of comment letters issued in 2008, which become the first year of the testing sample. I(NB Restatement) is set to 1 for testing sample comment letters expected to be associated with future restatements, and 0 otherwise, and the process is repeated each year to create a full testing samples that extends through 2016. The process is repeated a second time to create an NB classification signal for write-downs. The NB write-down signal, I(NB Write-Down), is set to 1 for testing sample comment letters expected to be associated with future write-downs, and 0 otherwise.</p>
        <p>The NB classifications are compared to other quantitative metrics that also plausibly idenitfy important comment letters. A common critique of textual analysis applied in the accounting and finance literature is that it can be difficult to replicate, as the model parameters and training data are not available to test in other settings (Loughran and McDonald, 2016). 3 The literature suggests other quantitative signals of comment letter importance. One is the number of letters in a comment letter conversation, which reflects the cost of responding (Cassell, Dreher and Myers, 2013). A comment letter conversation comprises all the comment letters (form UPLOAD) and company responses (form CORRESP) that relate to a single review, and they are identified by being disclosed on EDGAR at the same time and by referring to the same 10-K filing. A second quantitative signal is an indicator for comment letters addressing revenue recognition issues appear to be more material to insiders (Dechow et al., 2016). This study also proposes additional quantitative metrics of comment letter importance. Significantly negative abnormal returns at comment letter disclosure reflects the market's assessment of comment letter information content, and abnormal investor downloads of the comment letters from the SEC's EDGAR web site reflects greater investor attention. This study compares the relative effectiveness of these quantitative classifications with the NB text classifications, to illustrate the relative effectiveness of these measures for predicting future restatements, write-downs, earnings levels, persistence. It is important to understand the relative performance of these indicators, given the greater complexity involved in determining the textual classifications compared to using quantitative measures.The NB classifications are compared to other quantitative metrics that also plausibly idenitfy important comment letters. A common critique of textual analysis applied in the accounting and finance literature is that it can be difficult to replicate, as the model parameters and training data are not available to test in other settings (Loughran and McDonald, 2016). 3 The literature suggests other quantitative signals of comment letter importance. One is the number of letters in a comment letter conversation, which reflects the cost of responding (Cassell, Dreher and Myers, 2013). A comment letter conversation comprises all the comment letters (form UPLOAD) and company responses (form CORRESP) that relate to a single review, and they are identified by being disclosed on EDGAR at the same time and by referring to the same 10-K filing. A second quantitative signal is an indicator for comment letters addressing revenue recognition issues appear to be more material to insiders (Dechow et al., 2016). This study also proposes additional quantitative metrics of comment letter importance. Significantly negative abnormal returns at comment letter disclosure reflects the market's assessment of comment letter information content, and abnormal investor downloads of the comment letters from the SEC's EDGAR web site reflects greater investor attention. This study compares the relative effectiveness of these quantitative classifications with the NB text classifications, to illustrate the relative effectiveness of these measures for predicting future restatements, write-downs, earnings levels, persistence. It is important to understand the relative performance of these indicators, given the greater complexity involved in determining the textual classifications compared to using quantitative measures.</p>
        <p>The results indicate that both textual and quantitative classification signals are associated with future restatements, write-downs, and earnings. Different classification signals, both text-based and quantitative, are associated with different outcomes, so there does not appear to be one "best" measure of comment letter importance. Different signals appear to identify information revealed through the SEC review, leading to variation in investor responses and firm outcomes. The finding that comment letters identified by these metrics are predictors of future financial reporting outcomes is consistent with the view that comment letters reveal new information and are associated with managements' future financial reporting choices and real activities, including disclosure changes (e.g., Bozanic et al., 2017;Brown, Tian and Tucker, 2018), fair value estimate credibility (Bens, Cheng and Neamtiu, 2016), and earnings management behavior (Cunningham, Johnson, Johnson and Lisic, 2019).The results indicate that both textual and quantitative classification signals are associated with future restatements, write-downs, and earnings. Different classification signals, both text-based and quantitative, are associated with different outcomes, so there does not appear to be one "best" measure of comment letter importance. Different signals appear to identify information revealed through the SEC review, leading to variation in investor responses and firm outcomes. The finding that comment letters identified by these metrics are predictors of future financial reporting outcomes is consistent with the view that comment letters reveal new information and are associated with managements' future financial reporting choices and real activities, including disclosure changes (e.g., Bozanic et al., 2017;Brown, Tian and Tucker, 2018), fair value estimate credibility (Bens, Cheng and Neamtiu, 2016), and earnings management behavior (Cunningham, Johnson, Johnson and Lisic, 2019).</p>
        <p>The textual classification signal for restatements is a statistically significant predictor of future restatements, with a univariate increase in predictive power of 60.1 percent over non-signaled comment letters, and a 29.7 percent increase over the sample base rate of restatements in a probit regression that includes other known predictors of restatements as controls. The textual classification signal for write-downs has an increase in predictive power of 25.3 percent over non-signaled comment letters on a univariate basis, and an 11.7 percent increase over the sample base rate after controlling for other known predictors of write-downs.The textual classification signal for restatements is a statistically significant predictor of future restatements, with a univariate increase in predictive power of 60.1 percent over non-signaled comment letters, and a 29.7 percent increase over the sample base rate of restatements in a probit regression that includes other known predictors of restatements as controls. The textual classification signal for write-downs has an increase in predictive power of 25.3 percent over non-signaled comment letters on a univariate basis, and an 11.7 percent increase over the sample base rate after controlling for other known predictors of write-downs.</p>
        <p>Quantitative classifications of comment letters also provide useful measures of comment letter importance. The EDGAR download classification is an effective predictor of both future restatements and write-downs, and is associated with lower levels of future earnings. The negative abnormal returns classification is associated with lower future earnings as well as a higher likelihood of future write-downs. The number of comment letters in a conversation-based classification is associated with lower earnings persistence and future write-downs. Overall, these results indicate that certain comment letters are predictably associated with future financial reporting outcomes, and that different classification measures identify variation in comment letter materiality.Quantitative classifications of comment letters also provide useful measures of comment letter importance. The EDGAR download classification is an effective predictor of both future restatements and write-downs, and is associated with lower levels of future earnings. The negative abnormal returns classification is associated with lower future earnings as well as a higher likelihood of future write-downs. The number of comment letters in a conversation-based classification is associated with lower earnings persistence and future write-downs. Overall, these results indicate that certain comment letters are predictably associated with future financial reporting outcomes, and that different classification measures identify variation in comment letter materiality.</p>
        <p>This study also documents the nature of, and trends in, comment letter topics classified using Latent Dirichlet Allocation (LDA). LDA identifies statistical "topics" through groupings of words that commonly occur together within a set of documents. The resulting statistics can be used to describe a single document by the fraction its words associated with each of the identified topics. Aggregated, these results can describe the distribution of topics across a large set of documents, illustrating how the SEC's focus on particular topics changes over time. The associations between LDA topics assigned to individual comment letter conversation and those letters' textual and quantitative classifications gives evidence for the mechanisms affecting future earnings, the cost of comment letter remediation, and investor attention.This study also documents the nature of, and trends in, comment letter topics classified using Latent Dirichlet Allocation (LDA). LDA identifies statistical "topics" through groupings of words that commonly occur together within a set of documents. The resulting statistics can be used to describe a single document by the fraction its words associated with each of the identified topics. Aggregated, these results can describe the distribution of topics across a large set of documents, illustrating how the SEC's focus on particular topics changes over time. The associations between LDA topics assigned to individual comment letter conversation and those letters' textual and quantitative classifications gives evidence for the mechanisms affecting future earnings, the cost of comment letter remediation, and investor attention.</p>
        <p>Plausible topics are associated with the textual classifications. For example, the NB writedown signal is associated with comment letters that emphasize goodwill impairment, segment reporting, and operating performance topics-all key elements of the impairment testing process.Plausible topics are associated with the textual classifications. For example, the NB writedown signal is associated with comment letters that emphasize goodwill impairment, segment reporting, and operating performance topics-all key elements of the impairment testing process.</p>
        <p>Topic analysis also provides insights where the associated topics are not intuitively obvious, for example that investor attention measured by EDGAR downloads is associated with comment letters on licensing agreements, non-GAAP issues, and taxes. Furthermore, the analysis reveals that the presence of most topics, by themselves, are not statistically significantly predictors of future restatements and write-downs, although the goodwill impairment topic by itself is a significant predictor of write-downs. In descriptive analysis of topic trends over time, there is considerable variation in the prominence of several topics over the 2006 to 2016 period. For example, there was a significant increase in executive compensation-related comments during the 2008-2010 period, reflecting an SEC priority for enforcing new disclosure regulations.Topic analysis also provides insights where the associated topics are not intuitively obvious, for example that investor attention measured by EDGAR downloads is associated with comment letters on licensing agreements, non-GAAP issues, and taxes. Furthermore, the analysis reveals that the presence of most topics, by themselves, are not statistically significantly predictors of future restatements and write-downs, although the goodwill impairment topic by itself is a significant predictor of write-downs. In descriptive analysis of topic trends over time, there is considerable variation in the prominence of several topics over the 2006 to 2016 period. For example, there was a significant increase in executive compensation-related comments during the 2008-2010 period, reflecting an SEC priority for enforcing new disclosure regulations.</p>
        <p>In additional analyses, this study tests whether comment letters classified as important by textual and quantitative classification signals are associated with improvements in firms' earnings credibility. Johnston and Petacchi (2017) This study contributes to several areas of literature. First, it contributes to the emerging literature on SEC comment letters and financial reporting quality, which has examined the likelihood of receiving a comment letter and the cost of comment letter remediation (Cassell et al., 2013).In additional analyses, this study tests whether comment letters classified as important by textual and quantitative classification signals are associated with improvements in firms' earnings credibility. Johnston and Petacchi (2017) This study contributes to several areas of literature. First, it contributes to the emerging literature on SEC comment letters and financial reporting quality, which has examined the likelihood of receiving a comment letter and the cost of comment letter remediation (Cassell et al., 2013).</p>
        <p>Other studies examine the relation between comment letters and disclosure changes (e.g., Robinson, Xue and Yu, 2011;Brown et al., 2018;Bens et al., 2016;Bozanic et al., 2017). Although some comment letters appear important as evidenced by increased insider sales around their disclosure (Dechow et al., 2016), Johnston and Petacchi (2017) do not find an average price response to their disclosure. Comment letters have been used as proxies for financial reporting and audit quality (e.g., Ertimur and Nondorf, 2006;Gietzmann and Pettinicchio, 2013;Hribar et al., 2014). Cunningham et al. (2019) finds that comment letters are associated with a reduction in financial earnings management and a substitution towards real earnings management. Johnston and Petacchi (2017) show an overall increase in ERCs following comment letter disclosure. This paper extends the comment letter literature by identifying that specific classifications of comment letters are associated with future financial reporting outcomes: lower earnings, earnings persistence, restatements, and write-downs, and by describing the topics associated with these classifications and outcomes. This study also contributes descriptive analyses by illustrating variation in the distribution of comment letter topics over time and how these topics related to regulatory, market, and disclosure trends. This study further shows that un-important comment letters can be used to identify firms with higher earnings credibility, since less-important comment letters relate to post-disclosure improvements in ERCs.Other studies examine the relation between comment letters and disclosure changes (e.g., Robinson, Xue and Yu, 2011;Brown et al., 2018;Bens et al., 2016;Bozanic et al., 2017). Although some comment letters appear important as evidenced by increased insider sales around their disclosure (Dechow et al., 2016), Johnston and Petacchi (2017) do not find an average price response to their disclosure. Comment letters have been used as proxies for financial reporting and audit quality (e.g., Ertimur and Nondorf, 2006;Gietzmann and Pettinicchio, 2013;Hribar et al., 2014). Cunningham et al. (2019) finds that comment letters are associated with a reduction in financial earnings management and a substitution towards real earnings management. Johnston and Petacchi (2017) show an overall increase in ERCs following comment letter disclosure. This paper extends the comment letter literature by identifying that specific classifications of comment letters are associated with future financial reporting outcomes: lower earnings, earnings persistence, restatements, and write-downs, and by describing the topics associated with these classifications and outcomes. This study also contributes descriptive analyses by illustrating variation in the distribution of comment letter topics over time and how these topics related to regulatory, market, and disclosure trends. This study further shows that un-important comment letters can be used to identify firms with higher earnings credibility, since less-important comment letters relate to post-disclosure improvements in ERCs.</p>
        <p>More broadly, this paper also contributes to the accounting literature on financial reporting and audit quality (e.g., Kinney, Palmrose and Scholz, 2004;Hribar and Jenkins, 2004;Hennes et al., 2014). Teoh and Wong (1993) builds on Holthausen and Verrecchia (1988) to show that ERCs are increasing in the perceived credibility of the earnings report. Other financial reporting outcomes related to earnings quality include restatements and write-downs (e.g., Kinney and McDaniel, 1989;DeFond and Jiambalvo, 1991;Hribar and Jenkins, 2004;Palmrose, Richardson and Scholz, 2004;Liu, Raghunandan and Rama, 2009;Dechow, Ge, Larson and Sloan, 2011;Francis, 2011;Ramanna and Watts, 2012;Lawrence, Sloan and Sun, 2013;Laurion, Lawrence and Ryans, 2017).More broadly, this paper also contributes to the accounting literature on financial reporting and audit quality (e.g., Kinney, Palmrose and Scholz, 2004;Hribar and Jenkins, 2004;Hennes et al., 2014). Teoh and Wong (1993) builds on Holthausen and Verrecchia (1988) to show that ERCs are increasing in the perceived credibility of the earnings report. Other financial reporting outcomes related to earnings quality include restatements and write-downs (e.g., Kinney and McDaniel, 1989;DeFond and Jiambalvo, 1991;Hribar and Jenkins, 2004;Palmrose, Richardson and Scholz, 2004;Liu, Raghunandan and Rama, 2009;Dechow, Ge, Larson and Sloan, 2011;Francis, 2011;Ramanna and Watts, 2012;Lawrence, Sloan and Sun, 2013;Laurion, Lawrence and Ryans, 2017).</p>
        <p>Second, this study speaks to the effects of public enforcement of securities laws, through the SEC's monitoring role over registrant's annual financial statements. La Porta, Lopez-de Silanes and Shleifer (2006) proposes that public enforcement is relatively unimportant, but that greater disclosure has a positive impact on market development through private enforcement mechanisms. Christensen, Hail and Leuz (2013) finds a positive impact of government accounting enforcement in the IFRS adoption setting. Dyck, Morse and Zingales (2010) show that the SEC is one of a variety of actors that detect and enforce securities laws. Duro, Heese and Ormazabal (2019) conclude that private enforcement is improved with the disclosure of comment letters through the private enforcement channel via institutional shareholdings. Naughton, Rogo, Sunder and Zhang (2018) demonstrate a tradeoff between foreign and domestic public enforcement activities for cross-listed firms using comment letter reviews. The AAER literature is also related as it studies the effect of the SEC's Division of Enforcement (e.g., Feroz, Park and Pastena, 1991;Dechow, Sloan and Sweeney, 1995;Dyck et al., 2010), which is a less frequent but more severe channel of public enforcement compared to comment letter reviews by the SEC's Division of Corporation Finance (Heese et al., 2017). Comment letters are a mechanism by which the SEC encourages greater disclosures by US registrants, and reveals when the securities regulator believes the registrant is out of compliance with accounting or disclosure regulations, when an important comment letter is issued, or is largely compliant, when an innocuous letter is issued. This study's findings that a subset of comment letters are predictably associated with future reporting outcomes and improved earnings credibility provides direct evidence of the impact of the SEC's monitoring activities.Second, this study speaks to the effects of public enforcement of securities laws, through the SEC's monitoring role over registrant's annual financial statements. La Porta, Lopez-de Silanes and Shleifer (2006) proposes that public enforcement is relatively unimportant, but that greater disclosure has a positive impact on market development through private enforcement mechanisms. Christensen, Hail and Leuz (2013) finds a positive impact of government accounting enforcement in the IFRS adoption setting. Dyck, Morse and Zingales (2010) show that the SEC is one of a variety of actors that detect and enforce securities laws. Duro, Heese and Ormazabal (2019) conclude that private enforcement is improved with the disclosure of comment letters through the private enforcement channel via institutional shareholdings. Naughton, Rogo, Sunder and Zhang (2018) demonstrate a tradeoff between foreign and domestic public enforcement activities for cross-listed firms using comment letter reviews. The AAER literature is also related as it studies the effect of the SEC's Division of Enforcement (e.g., Feroz, Park and Pastena, 1991;Dechow, Sloan and Sweeney, 1995;Dyck et al., 2010), which is a less frequent but more severe channel of public enforcement compared to comment letter reviews by the SEC's Division of Corporation Finance (Heese et al., 2017). Comment letters are a mechanism by which the SEC encourages greater disclosures by US registrants, and reveals when the securities regulator believes the registrant is out of compliance with accounting or disclosure regulations, when an important comment letter is issued, or is largely compliant, when an innocuous letter is issued. This study's findings that a subset of comment letters are predictably associated with future reporting outcomes and improved earnings credibility provides direct evidence of the impact of the SEC's monitoring activities.</p>
        <p>Third, this study contributes to the literature on the use of textual analysis in accounting and finance. Naive Bayesian (NB) classification techniques have been used to classify tone in financial disclosures, analyst reports, and stock message boards (e.g., Antweiler and Frank, 2004;Li, 2010;De Franco, Vasvari, Vyas and Wittenberg-Moerman, 2013;Huang, Zang and Zheng, 2014). This study is applies Naive Bayesian classification to accounting disclosures using a training classification based on actual financial reporting outcomes, rather than based on hand coding of document words or sentences. LDA topic analysis has been applied to describe the evolution of 10-K disclosures (Dyer, Lang and Stice-Lawrence, 2017), and to identify the focus of analyst discussions (Huang, Lehavy, Zang and Zheng, 2018). In this study, LDA topic analysis provides descriptive evidence of the content of comment letters and is used to illustrate the mechanisms by which the different comment letter classifications are related to outcomes, market response, and investor attention.Third, this study contributes to the literature on the use of textual analysis in accounting and finance. Naive Bayesian (NB) classification techniques have been used to classify tone in financial disclosures, analyst reports, and stock message boards (e.g., Antweiler and Frank, 2004;Li, 2010;De Franco, Vasvari, Vyas and Wittenberg-Moerman, 2013;Huang, Zang and Zheng, 2014). This study is applies Naive Bayesian classification to accounting disclosures using a training classification based on actual financial reporting outcomes, rather than based on hand coding of document words or sentences. LDA topic analysis has been applied to describe the evolution of 10-K disclosures (Dyer, Lang and Stice-Lawrence, 2017), and to identify the focus of analyst discussions (Huang, Lehavy, Zang and Zheng, 2018). In this study, LDA topic analysis provides descriptive evidence of the content of comment letters and is used to illustrate the mechanisms by which the different comment letter classifications are related to outcomes, market response, and investor attention.</p>
        <p>Caveats apply to this study. NB textual classification and LDA topic analysis are derived from specific collections of texts, and can be difficult to replicate in different settings or with a different set of documents. To mitigate this issue, this study compares the performance of textual classification to more transparent quantitative metrics. The online appendix provides the classification models and examples for how to reproduce the text-based signals used in this study and apply them to new comment letters. As comment letter topics evolve over time, these specific textual classification models will likely exhibit lower power, since the topics and words used in future comment letters will differ from those in the training sample. In order to adapt to these changes, the same NB procedure described herein may be used to re-estimate the classification models using new training documents. Another caveat is that the evidence presented here is not designed to provide a causal interpretation of the effect of comment letters on financial reporting quality: the evidence related to future restatements, write-downs, earnings, and ERC changes, following a comment letter, may indicate either that comment letters causally change financial reporting, or that comment letters simply reveal new information about the existing state of the target firm. The tests presented here do not distinguish between the two interpretations.Caveats apply to this study. NB textual classification and LDA topic analysis are derived from specific collections of texts, and can be difficult to replicate in different settings or with a different set of documents. To mitigate this issue, this study compares the performance of textual classification to more transparent quantitative metrics. The online appendix provides the classification models and examples for how to reproduce the text-based signals used in this study and apply them to new comment letters. As comment letter topics evolve over time, these specific textual classification models will likely exhibit lower power, since the topics and words used in future comment letters will differ from those in the training sample. In order to adapt to these changes, the same NB procedure described herein may be used to re-estimate the classification models using new training documents. Another caveat is that the evidence presented here is not designed to provide a causal interpretation of the effect of comment letters on financial reporting quality: the evidence related to future restatements, write-downs, earnings, and ERC changes, following a comment letter, may indicate either that comment letters causally change financial reporting, or that comment letters simply reveal new information about the existing state of the target firm. The tests presented here do not distinguish between the two interpretations.</p>
        <p>As a result of the major bankruptcy and fraud cases in the early 2000's, Section 408 of the Sarbanes-Oxley Act of 2002 was enacted with a mandate for the SEC to review the annual financial reports of every public issuer at least once every three years, for the protection of investors (SOX, 2002). If a review identifies issues that warrant additional disclosure, correction, or clarification, the SEC issues a comment letter and a written correspondence with the issuer proceeds until the SEC is satisfied that all questions are resolved. Beginning with comments on filings made after August 1, 2004, the SEC began posting all comment letters and the issuer's responses on the EDGAR web site for public dissemination 45 calendar days (20 business days beginning in 2012) after a review's completion. Considerable resources are expended by the SEC and reporting companies and their advisors, including public accounting firms and lawyers, in making and responding to these comment letters: in 2012, the SEC conducted 4,380 reviews, representing 48 percent of all issuers, and wrote 3,566 comment letters referencing annual reports. These reviews represent the significant majority of the Division of Corporation Finance's headcount and $135 million annual budget (SEC, 2015), and presumably the cost of responding borne by reporting companies is several times greater than the SEC's cost of issuing questions.As a result of the major bankruptcy and fraud cases in the early 2000's, Section 408 of the Sarbanes-Oxley Act of 2002 was enacted with a mandate for the SEC to review the annual financial reports of every public issuer at least once every three years, for the protection of investors (SOX, 2002). If a review identifies issues that warrant additional disclosure, correction, or clarification, the SEC issues a comment letter and a written correspondence with the issuer proceeds until the SEC is satisfied that all questions are resolved. Beginning with comments on filings made after August 1, 2004, the SEC began posting all comment letters and the issuer's responses on the EDGAR web site for public dissemination 45 calendar days (20 business days beginning in 2012) after a review's completion. Considerable resources are expended by the SEC and reporting companies and their advisors, including public accounting firms and lawyers, in making and responding to these comment letters: in 2012, the SEC conducted 4,380 reviews, representing 48 percent of all issuers, and wrote 3,566 comment letters referencing annual reports. These reviews represent the significant majority of the Division of Corporation Finance's headcount and $135 million annual budget (SEC, 2015), and presumably the cost of responding borne by reporting companies is several times greater than the SEC's cost of issuing questions.</p>
        <p>Because important comment letters may cause firms to identify previously unrecognized shortcomings, or to release strategically withheld news, the disclosure of important comment letters should be associated with investor attention and stock price responses. Studies of investor attention note that investor demand for news articles is associated with the information content of those articles (e.g., Engelberg and Parsons, 2011). EDGAR downloads are a direct measure of investor demand, and such downloads are associated with information events, and have been shown to be related to the efficiency of earnings news dissemination (Drake, Roulstone and Thornock, 2015). Loughran and McDonald (2017) examines characteristics of the EDGAR log file data, and Ryans (2017) notes that care needs to be taking cleaning the raw EDGAR log file data set to accurately count comment letter downloads, which are usually filed as PDF documents. Drake, Johnson, Roulstone and Thornock (2019) examine the demand for EDGAR filings, and provide evidence that information acquisition, particularly for sophisticated investors, is predictive of future firm performance.Because important comment letters may cause firms to identify previously unrecognized shortcomings, or to release strategically withheld news, the disclosure of important comment letters should be associated with investor attention and stock price responses. Studies of investor attention note that investor demand for news articles is associated with the information content of those articles (e.g., Engelberg and Parsons, 2011). EDGAR downloads are a direct measure of investor demand, and such downloads are associated with information events, and have been shown to be related to the efficiency of earnings news dissemination (Drake, Roulstone and Thornock, 2015). Loughran and McDonald (2017) examines characteristics of the EDGAR log file data, and Ryans (2017) notes that care needs to be taking cleaning the raw EDGAR log file data set to accurately count comment letter downloads, which are usually filed as PDF documents. Drake, Johnson, Roulstone and Thornock (2019) examine the demand for EDGAR filings, and provide evidence that information acquisition, particularly for sophisticated investors, is predictive of future firm performance.</p>
        <p>If some investors access the comment letters, and their attention is higher when the comment letters are more important, then EDGAR downloads should identify comment letters that are more likely associated with negative future financial reporting outcomes. Consistent with downloads reflecting more important comment letters, Dechow et al. (2016) finds greater insider selling activity prior to the disclosure of comment letters with above-median EDGAR downloads.If some investors access the comment letters, and their attention is higher when the comment letters are more important, then EDGAR downloads should identify comment letters that are more likely associated with negative future financial reporting outcomes. Consistent with downloads reflecting more important comment letters, Dechow et al. (2016) finds greater insider selling activity prior to the disclosure of comment letters with above-median EDGAR downloads.</p>
        <p>The investor attention-based classification of comment letter importance, I(EDGAR) is set to 1 for above-median EDGAR downloads in the three days following comment letter disclosure, and 0 otherwise.The investor attention-based classification of comment letter importance, I(EDGAR) is set to 1 for above-median EDGAR downloads in the three days following comment letter disclosure, and 0 otherwise.</p>
        <p>A second metric reflecting the information content of a comment letter is the market response to the disclosure (Ball and Brown, 1968;Beaver, 1968), although observing a response is a joint test of the information content and investors' attention and their ability to interpret the information (Hirshleifer and Teoh, 2003). Because comment letters reflect deficient disclosures as perceived by the SEC examiners, the expected market response to an important comment letter is negative at the disclosure event. To account for the possibility that limited attention causes a delayed response to the comment letter disclosure, cumulative abnormal returns beginning one day prior to the comment letter disclosure and ending 10 days following disclosure is used. The returnsbased classification of comment letter importance, I(CAR [-1,10]) is set to 1 for bottom quartile returns over this disclosure-returns window, and 0 otherwise. Dechow et al. (2016) expect that comment letters with revenue recognition-related issues as coded by the Audit Analytics taxonomy are more important, since revenue is the most common area of fraud and manipulation, and is strongly related to operating performance. The revenue recognition-based classification of comment letter importance, I(Revenue Recognition) is set to 1 for comment letter conversations which Audit Analytics indicates contains revenue recognition based comments, and 0 otherwise. Cassell et al. (2013) use the number of letters in a comment letter conversation as a proxy for the cost of remediation, and more costly comment letters are expected to have greater information content and a greater potential impact on an issuers' financial reporting practices. The cost-based classification indicator variable for comment letter importance, I(Number of Letters) is set to 1 for comment letter conversations with above-median number of letters, and 0 otherwise.A second metric reflecting the information content of a comment letter is the market response to the disclosure (Ball and Brown, 1968;Beaver, 1968), although observing a response is a joint test of the information content and investors' attention and their ability to interpret the information (Hirshleifer and Teoh, 2003). Because comment letters reflect deficient disclosures as perceived by the SEC examiners, the expected market response to an important comment letter is negative at the disclosure event. To account for the possibility that limited attention causes a delayed response to the comment letter disclosure, cumulative abnormal returns beginning one day prior to the comment letter disclosure and ending 10 days following disclosure is used. The returnsbased classification of comment letter importance, I(CAR [-1,10]) is set to 1 for bottom quartile returns over this disclosure-returns window, and 0 otherwise. Dechow et al. (2016) expect that comment letters with revenue recognition-related issues as coded by the Audit Analytics taxonomy are more important, since revenue is the most common area of fraud and manipulation, and is strongly related to operating performance. The revenue recognition-based classification of comment letter importance, I(Revenue Recognition) is set to 1 for comment letter conversations which Audit Analytics indicates contains revenue recognition based comments, and 0 otherwise. Cassell et al. (2013) use the number of letters in a comment letter conversation as a proxy for the cost of remediation, and more costly comment letters are expected to have greater information content and a greater potential impact on an issuers' financial reporting practices. The cost-based classification indicator variable for comment letter importance, I(Number of Letters) is set to 1 for comment letter conversations with above-median number of letters, and 0 otherwise.</p>
        <p>Comment letters present a challenge to researchers studying their information content and consequences, because they have an unstructured format and do not present consistent numerical statistics, such as earnings and revenues which are available in standard financial statements. As a result, textual analysis techniques may provide useful inferences about the nature of comment letters and their effect on issuers.Comment letters present a challenge to researchers studying their information content and consequences, because they have an unstructured format and do not present consistent numerical statistics, such as earnings and revenues which are available in standard financial statements. As a result, textual analysis techniques may provide useful inferences about the nature of comment letters and their effect on issuers.</p>
        <p>Statistical text analysis has been used in accounting and finance research to study the text portion of disclosures, and these techniques developed as a response to the difficulty and cost of hand-coded content analysis, which necessitates small sample sizes (e.g., Bryan, 1997). Loughran and McDonald (2016) survey textual analysis techniques used in the accounting and finance literature. Dictionary based techniques use wordlists with pre-supposed meanings to identify the tone of a text by counting the number or fractions of words belonging to a list (e.g., Tetlock, 2007;Kothari, Li and Short, 2009a;Davis, Piger and Sedor, 2012). Document length or reading difficulty have been used as measures of reporting complexity (e.g., Li, 2008;You and Zhang, 2009;Peterson, 2012), or of management deceptiveness (e.g., Larcker and Zakolyukina, 2012). Feldman, Govindaraj, Livnat and Segal (2010) find significant market reaction to 10-Q and 10-K reports, conditioned on the tone of filings. Law and Mills (2015) find that firms with more negative annual report tone pursue more aggressive tax planning strategies. These studies indicate that textual analysis based on word lists can be effective, despite evidence that commonly used dictionaries can be misleading or ambiguous in the financial setting (Loughran and McDonald, 2011).Statistical text analysis has been used in accounting and finance research to study the text portion of disclosures, and these techniques developed as a response to the difficulty and cost of hand-coded content analysis, which necessitates small sample sizes (e.g., Bryan, 1997). Loughran and McDonald (2016) survey textual analysis techniques used in the accounting and finance literature. Dictionary based techniques use wordlists with pre-supposed meanings to identify the tone of a text by counting the number or fractions of words belonging to a list (e.g., Tetlock, 2007;Kothari, Li and Short, 2009a;Davis, Piger and Sedor, 2012). Document length or reading difficulty have been used as measures of reporting complexity (e.g., Li, 2008;You and Zhang, 2009;Peterson, 2012), or of management deceptiveness (e.g., Larcker and Zakolyukina, 2012). Feldman, Govindaraj, Livnat and Segal (2010) find significant market reaction to 10-Q and 10-K reports, conditioned on the tone of filings. Law and Mills (2015) find that firms with more negative annual report tone pursue more aggressive tax planning strategies. These studies indicate that textual analysis based on word lists can be effective, despite evidence that commonly used dictionaries can be misleading or ambiguous in the financial setting (Loughran and McDonald, 2011).</p>
        <p>Tone and reading-ease measures do not seem particularly applicable in the comment letter setting, since comment letters are primarily technical documents discussing the application of accounting and disclosure standards. Given the nature of the comment letter process, which relates to the enforcement of disclosure regulation, comment letters are often associated with outcomes such as restatements and write-downs, so an intuitive approach is to classify documents according to their relation to these outcomes. While many comment letters request that a registrant restates a financial disclosure during the comment letter conversation, these comment letters are less informative at their release, since the restatement was revealed prior to the disclosure of the related comment letter (Johnston and Petacchi, 2017). Rather, the more interesting comment letters for the purpose of this study are those that can be identified as associated with restatements that occur following the comment letter's disclosure. To investigate the ability of a widely-used statistical text classification technique to identify comment letters associated with future restatements and write-downs, this study implements two Naive Bayesian text classifications specifically targeted on these future outcomes. Documents may be classified according to any arbitrary classification scheme, and the NB classification technique has been widely used in many settings (e.g., Lewis, 1998). The NB classification method uses a set of training documents, which belong to known classes, for example authorship (Shakespeare, not-Shakespeare) or tone (positive, negative), where the class is either known to the researcher by other means or is coded based on the researcher's opinion, to statistically identify the words or multiple-word features in the documents which differentiate it as belonging to a particular class. The classification algorithm identifies all features in the document set, and then calculates the likelihood of each feature appearing in the documents belonging to each class, based on each feature's empirical frequency. When presented with a new document of unknown class, the NB algorithm observes the frequency of each of the features in the new document, and calculates the likelihood that the document belongs to each class, according to Bayes Theorem. The class with the greatest likelihood is the predicted class of the new document.Tone and reading-ease measures do not seem particularly applicable in the comment letter setting, since comment letters are primarily technical documents discussing the application of accounting and disclosure standards. Given the nature of the comment letter process, which relates to the enforcement of disclosure regulation, comment letters are often associated with outcomes such as restatements and write-downs, so an intuitive approach is to classify documents according to their relation to these outcomes. While many comment letters request that a registrant restates a financial disclosure during the comment letter conversation, these comment letters are less informative at their release, since the restatement was revealed prior to the disclosure of the related comment letter (Johnston and Petacchi, 2017). Rather, the more interesting comment letters for the purpose of this study are those that can be identified as associated with restatements that occur following the comment letter's disclosure. To investigate the ability of a widely-used statistical text classification technique to identify comment letters associated with future restatements and write-downs, this study implements two Naive Bayesian text classifications specifically targeted on these future outcomes. Documents may be classified according to any arbitrary classification scheme, and the NB classification technique has been widely used in many settings (e.g., Lewis, 1998). The NB classification method uses a set of training documents, which belong to known classes, for example authorship (Shakespeare, not-Shakespeare) or tone (positive, negative), where the class is either known to the researcher by other means or is coded based on the researcher's opinion, to statistically identify the words or multiple-word features in the documents which differentiate it as belonging to a particular class. The classification algorithm identifies all features in the document set, and then calculates the likelihood of each feature appearing in the documents belonging to each class, based on each feature's empirical frequency. When presented with a new document of unknown class, the NB algorithm observes the frequency of each of the features in the new document, and calculates the likelihood that the document belongs to each class, according to Bayes Theorem. The class with the greatest likelihood is the predicted class of the new document.</p>
        <p>NB classification is one of the most established methodologies used to classify text (e.g., Lewis, 1998;Loughran and McDonald, 2016), and has been used in the past to determine document classification based upon authorship (e.g., Mosteller and Wallace, 1984), genre (e.g., Karlgren and Cutting, 1994;Kessler, Numberg and Schutze, 1997), news category (e.g., Feldman and Dagan, 1995;Dagan, Feldman and Hirsh, 1996), and the sentiment of movie reviews (e.g., Pang, Lee and Vaithyanathan, 2002). In the law literature, Talley and O'Kane (2012) identifies the properties of specific clauses within merger agreements. NB classification is used in the accounting and finance literature for classifying the tone of individual sentences in financial disclosures, analyst reports, and stock message boards (e.g., Antweiler and Frank, 2004;Li, 2010;De Franco et al., 2013;Huang et al., 2014). In these studies, the NB classification involves the researcher manually determining the classifications of training documents. This manual coding exercise is a disadvantage because it is costly and difficult to replicate by other researchers, and prior literature notes that it is potentially subject to bias (e.g., Loughran and McDonald, 2016). To prepare the NB analysis, first the complete text is downloaded for all comment letters and company responses relating to sample 10-K comment letters. All letters (forms UPLOAD and CORRESP) in a conversation are concatenated into a single disclosure, consistent with their being disclosed simultaneously. Second, the text was preprocessed according to standard pby converting to lowercase, removing punctuation, numbers, and common english stop words, or frequent words that appear too commonly to be discriminatory such as to, so, and, and is. The remaining words were stemmed, so that derivative words are replaced by their common word stem, e.g., operating and operations become operat. This ensures that similar words are counted as a common feature, and further reduces computational complexity. Third, all consecutive oneand two-word features (i.e., unigrams and bigrams) in the document set selected as the feature set. The use of bigrams preserves some of the ordering of words in the document, for example, it allows the feature income statement to be maintained, rather then being split into two separate features income and statement, resulting in the retention of two-word accounting terms. A matrix where each row represents a specific document and each column represents a feature is created, with each cell in the resulting term document matrix representing the term frequency-inverse document frequency ("tf-idf") statistic for the column's feature in the row's document. The tfidf statistic increases proportionately with the number of times the word appears in the particular document and decreases proportionately for the number of times the word appears throughout all the documents combined. The term document matrix is finally simplified by removing any terms that appear in fewer than 1 percent of the documents and in more than 90 percent of the documents, as very infrequent and very frequent terms have little contribution to the classification, and fewer terms make computations less costly. The final feature set is 1,880 unigrams and bigrams. Further details of the NB classification and its calculation mechanics can be found in numerous prior studies that apply NB classification (e.g., Antweiler and Frank, 2004;Li, 2010;De Franco et al., 2013;Huang et al., 2014). The rolling window design results in all observations, after the minimum first year training sample is reserved, being used in a testing sample, resulting in 7,692 of 8,483 (91 percent) of the 10-K comment letter observations being used in a testing sample. This has the advantage of giving a significantly larger sample size for running analyses than would be available in a typical 50 percent random or time-based sample. The rolling window method also eliminates any look-ahead bias, where future documents train a model that predicts past outcomes. The rolling window approach allows the classifications to evolve over time, so that as the SEC's focus issues evolve, the classifications incorporate resulting changes in comment letter vocabulary. The results are robust to using other sampling approaches, such as a 50/50 percent random training/testing sample pooled across all available years, or a first half training sample, second half testing sample approach.NB classification is one of the most established methodologies used to classify text (e.g., Lewis, 1998;Loughran and McDonald, 2016), and has been used in the past to determine document classification based upon authorship (e.g., Mosteller and Wallace, 1984), genre (e.g., Karlgren and Cutting, 1994;Kessler, Numberg and Schutze, 1997), news category (e.g., Feldman and Dagan, 1995;Dagan, Feldman and Hirsh, 1996), and the sentiment of movie reviews (e.g., Pang, Lee and Vaithyanathan, 2002). In the law literature, Talley and O'Kane (2012) identifies the properties of specific clauses within merger agreements. NB classification is used in the accounting and finance literature for classifying the tone of individual sentences in financial disclosures, analyst reports, and stock message boards (e.g., Antweiler and Frank, 2004;Li, 2010;De Franco et al., 2013;Huang et al., 2014). In these studies, the NB classification involves the researcher manually determining the classifications of training documents. This manual coding exercise is a disadvantage because it is costly and difficult to replicate by other researchers, and prior literature notes that it is potentially subject to bias (e.g., Loughran and McDonald, 2016). To prepare the NB analysis, first the complete text is downloaded for all comment letters and company responses relating to sample 10-K comment letters. All letters (forms UPLOAD and CORRESP) in a conversation are concatenated into a single disclosure, consistent with their being disclosed simultaneously. Second, the text was preprocessed according to standard pby converting to lowercase, removing punctuation, numbers, and common english stop words, or frequent words that appear too commonly to be discriminatory such as to, so, and, and is. The remaining words were stemmed, so that derivative words are replaced by their common word stem, e.g., operating and operations become operat. This ensures that similar words are counted as a common feature, and further reduces computational complexity. Third, all consecutive oneand two-word features (i.e., unigrams and bigrams) in the document set selected as the feature set. The use of bigrams preserves some of the ordering of words in the document, for example, it allows the feature income statement to be maintained, rather then being split into two separate features income and statement, resulting in the retention of two-word accounting terms. A matrix where each row represents a specific document and each column represents a feature is created, with each cell in the resulting term document matrix representing the term frequency-inverse document frequency ("tf-idf") statistic for the column's feature in the row's document. The tfidf statistic increases proportionately with the number of times the word appears in the particular document and decreases proportionately for the number of times the word appears throughout all the documents combined. The term document matrix is finally simplified by removing any terms that appear in fewer than 1 percent of the documents and in more than 90 percent of the documents, as very infrequent and very frequent terms have little contribution to the classification, and fewer terms make computations less costly. The final feature set is 1,880 unigrams and bigrams. Further details of the NB classification and its calculation mechanics can be found in numerous prior studies that apply NB classification (e.g., Antweiler and Frank, 2004;Li, 2010;De Franco et al., 2013;Huang et al., 2014). The rolling window design results in all observations, after the minimum first year training sample is reserved, being used in a testing sample, resulting in 7,692 of 8,483 (91 percent) of the 10-K comment letter observations being used in a testing sample. This has the advantage of giving a significantly larger sample size for running analyses than would be available in a typical 50 percent random or time-based sample. The rolling window method also eliminates any look-ahead bias, where future documents train a model that predicts past outcomes. The rolling window approach allows the classifications to evolve over time, so that as the SEC's focus issues evolve, the classifications incorporate resulting changes in comment letter vocabulary. The results are robust to using other sampling approaches, such as a 50/50 percent random training/testing sample pooled across all available years, or a first half training sample, second half testing sample approach.</p>
        <p>The main observable output of NB classification, other than the classification signal itself, is statistics about the contribution of each feature towards the likelihood calculation. These statistics can be summarized by a word list of features ordered by their contribution to the classification.The main observable output of NB classification, other than the classification signal itself, is statistics about the contribution of each feature towards the likelihood calculation. These statistics can be summarized by a word list of features ordered by their contribution to the classification.</p>
        <p>A, with columns for each year to illustrate the evolution of the classifier over time. Restatementrelated comment letters appear to discuss compensation (e.g., compens, goal, target, compns committe, bonus) and loans (e.g., loan, reserv. The NB write-down classification features are shown in Panel B, and are related to loans (e.g., loan, reserv), internal controls (e.g., control procedur, disclosure procedur), compensation (e.g., compens). While these feature lists help to identify some words that might give rise to a classification, they also appear to identify similar words as being important to both classification (e.g., those relating to loans and compensation). As a practical matter, each word in a document contributes a small amount to the overall likelihood of classification, and the resulting lack of transparency into particular classifications gives rise to a view of NB as something of a black box. To address this criticism, LDA topic analysis gives topic-based insights into the underlying mechanisms associated with the NB classifications and financial reporting outcomes.A, with columns for each year to illustrate the evolution of the classifier over time. Restatementrelated comment letters appear to discuss compensation (e.g., compens, goal, target, compns committe, bonus) and loans (e.g., loan, reserv. The NB write-down classification features are shown in Panel B, and are related to loans (e.g., loan, reserv), internal controls (e.g., control procedur, disclosure procedur), compensation (e.g., compens). While these feature lists help to identify some words that might give rise to a classification, they also appear to identify similar words as being important to both classification (e.g., those relating to loans and compensation). As a practical matter, each word in a document contributes a small amount to the overall likelihood of classification, and the resulting lack of transparency into particular classifications gives rise to a view of NB as something of a black box. To address this criticism, LDA topic analysis gives topic-based insights into the underlying mechanisms associated with the NB classifications and financial reporting outcomes.</p>
        <p>Beginning with 77,215 Compustat observations with available total assets, shares outstanding, SIC codes, and CIK codes that can be matched to EDGAR and Audit Analytics Comment Letter data by CIK, there are 17,719 comment letter conversation events regarding a Form 10-K filing.Beginning with 77,215 Compustat observations with available total assets, shares outstanding, SIC codes, and CIK codes that can be matched to EDGAR and Audit Analytics Comment Letter data by CIK, there are 17,719 comment letter conversation events regarding a Form 10-K filing.</p>
        <p>After matching to CRSP, there are 9,191 events with sufficient pre-and post-event returns data to calculate the required abnormal returns during the comment letter disclosure event period. The final sample is reduced to 8,483 observations with the necessary one year pre-and post-event control and outcome variables. The full text of all 10-K SEC comment letters (Form UPLOAD) and company responses (Form CORRESP) are obtained from Audit Analytics for these observations in order to perform the text classification and topic analyses. Each event, for a firm-comment letter i, disclosed in fiscal year t, involves three time periods, illustrated using an example timeline, in Figure 2. Financial variables are calculated using amounts available from the fiscal year end prior to the comment letter's disclosure, year t -1.After matching to CRSP, there are 9,191 events with sufficient pre-and post-event returns data to calculate the required abnormal returns during the comment letter disclosure event period. The final sample is reduced to 8,483 observations with the necessary one year pre-and post-event control and outcome variables. The full text of all 10-K SEC comment letters (Form UPLOAD) and company responses (Form CORRESP) are obtained from Audit Analytics for these observations in order to perform the text classification and topic analyses. Each event, for a firm-comment letter i, disclosed in fiscal year t, involves three time periods, illustrated using an example timeline, in Figure 2. Financial variables are calculated using amounts available from the fiscal year end prior to the comment letter's disclosure, year t -1.</p>
        <p>Earnings are measured in year t, the first full fiscal year after comment letter disclosure, and future restatements, and future write-downs are measured for year t + 1, the first full fiscal year beginning after the comment letter's disclosure.Earnings are measured in year t, the first full fiscal year after comment letter disclosure, and future restatements, and future write-downs are measured for year t + 1, the first full fiscal year beginning after the comment letter's disclosure.</p>
        <p>Cumulative abnormal returns are based on the four factor model in Carhart (1997). Specifically, cumulative abnormal returns are calculated using the market model:Cumulative abnormal returns are based on the four factor model in Carhart (1997). Specifically, cumulative abnormal returns are calculated using the market model:</p>
        <p>where AR id is the abnormal return for firm i on day d, r id is the excess return of the stock i For each comment letter observation, the ERC sample includes four quarters of earnings announcements prior to the comment letter disclosure, identified with an indicator variable POS T = 0, and four quarters following the comment letter disclosure, identified with POS T = 1. S UE is calculated as in Livnat and Mendenhall (2006), using the difference between IBES actual and consensus earnings per share, and four quarter lagged operating earnings per share if IBES estimates are not available, scaled by share price. The mean market capitalization of firms in the all 10-K sample is $8,366 million, which is larger than the mean Compustat population of $4,773 million (untabulated) over the same period, and is consistent with Cassell et al. (2013), who show that size is positively associated with comment letter receipt. The mean Book to Market ratio is 0.594, similar to the Compustat population of 0.595 over the same period. Over the entire period, the mean number of EDGAR downloads for all comment letters in this three day window is 9.1 for all 10-K firms, and the median is 6 downloads, the threshold for the quantitative classification indicator variable I(EDGAR), which is 1 if downloads are greater than 6, and 0 otherwise. For all firms with comment letter conversations, mean (median) CAR[-1, 1] is negligible at 0.000 (-0.001), as is the mean (median) CAR[-1, 10] at 0.001 (-0.002) and CAR[-1, 90] at 0.005 (-0.002), confirming prior studies that show comment letters, on average, do not have a significantwhere AR id is the abnormal return for firm i on day d, r id is the excess return of the stock i For each comment letter observation, the ERC sample includes four quarters of earnings announcements prior to the comment letter disclosure, identified with an indicator variable POS T = 0, and four quarters following the comment letter disclosure, identified with POS T = 1. S UE is calculated as in Livnat and Mendenhall (2006), using the difference between IBES actual and consensus earnings per share, and four quarter lagged operating earnings per share if IBES estimates are not available, scaled by share price. The mean market capitalization of firms in the all 10-K sample is $8,366 million, which is larger than the mean Compustat population of $4,773 million (untabulated) over the same period, and is consistent with Cassell et al. (2013), who show that size is positively associated with comment letter receipt. The mean Book to Market ratio is 0.594, similar to the Compustat population of 0.595 over the same period. Over the entire period, the mean number of EDGAR downloads for all comment letters in this three day window is 9.1 for all 10-K firms, and the median is 6 downloads, the threshold for the quantitative classification indicator variable I(EDGAR), which is 1 if downloads are greater than 6, and 0 otherwise. For all firms with comment letter conversations, mean (median) CAR[-1, 1] is negligible at 0.000 (-0.001), as is the mean (median) CAR[-1, 10] at 0.001 (-0.002) and CAR[-1, 90] at 0.005 (-0.002), confirming prior studies that show comment letters, on average, do not have a significant</p>
        <p>Topic analysis of comment letters provides both descriptive analysis of the content of this enforcement channel, and helps to illustrate the potential mechanisms behind the NB and quantitative classifications. The NB classification is based upon a "bag-of-words" approach, whereby the word frequency identifies the class of a document. 4 The restatement classification may be an effective predictor of future outcomes, but it provides little interpretable insight into how the content of the particular comment letter relates to the outcomes. This study conducts the LDA topic analysis to be able to describe the content of both a single comment letter, and also to give descriptive evidence regarding variation in topics over time.Topic analysis of comment letters provides both descriptive analysis of the content of this enforcement channel, and helps to illustrate the potential mechanisms behind the NB and quantitative classifications. The NB classification is based upon a "bag-of-words" approach, whereby the word frequency identifies the class of a document. 4 The restatement classification may be an effective predictor of future outcomes, but it provides little interpretable insight into how the content of the particular comment letter relates to the outcomes. This study conducts the LDA topic analysis to be able to describe the content of both a single comment letter, and also to give descriptive evidence regarding variation in topics over time.</p>
        <p>Following a growing body of literature on LDA topic analysis research in accounting and finance (e.g., Bao and Datta, 2014;Dyer et al., 2017;Hoberg and Lewis, 2017;Huang et al., 2018), this study uses LDA to identify a set of topics that are empirically observed in comment letters. The LDA technique, described in detail by Blei, Ng and Jordan (2003), determines the probability that each term in the feature set (e.g., unigrams and bigrams) belongs to a topic, based the rates at which terms co-appear in a set of documents. The algorithm identifies the features and probabilities associated with each topic, as well as statistics about the distribution of topic-words present in each document. Dyer et al. (2017) uses LDA to illustrate how the contents of 10-K reports has developed over time.Following a growing body of literature on LDA topic analysis research in accounting and finance (e.g., Bao and Datta, 2014;Dyer et al., 2017;Hoberg and Lewis, 2017;Huang et al., 2018), this study uses LDA to identify a set of topics that are empirically observed in comment letters. The LDA technique, described in detail by Blei, Ng and Jordan (2003), determines the probability that each term in the feature set (e.g., unigrams and bigrams) belongs to a topic, based the rates at which terms co-appear in a set of documents. The algorithm identifies the features and probabilities associated with each topic, as well as statistics about the distribution of topic-words present in each document. Dyer et al. (2017) uses LDA to illustrate how the contents of 10-K reports has developed over time.</p>
        <p>This study creates an LDA topic distribution for the entire comment letter sample, using the same document features (unigrams and bigrams) as the NB classification. The main parameter choice is the number of topics. For analyzing comment letters, 20 topics was selected based on manual inspection of the resulting word sets assigned to each topic, after iterating from 5 to 50 topics and observing the resulting word lists associated with each topic. With 20 topics, the resulting term lists revealed distinct but consistent features that could be identified as a group of related financial reporting terms. When fewer than 20 topics are used, the words associated with a single topic clearly discussed different reporting concepts, such as revenues and taxes, indicating that multiple financial reporting topics were combined into one LDA topic. When greater than 20 topics are used, the words associated with several different topics became indistinguishable from each other, for example two or more topics containing revenue-related words. Using 20 topics, the groups of features appear both distinct and non-overlapping.This study creates an LDA topic distribution for the entire comment letter sample, using the same document features (unigrams and bigrams) as the NB classification. The main parameter choice is the number of topics. For analyzing comment letters, 20 topics was selected based on manual inspection of the resulting word sets assigned to each topic, after iterating from 5 to 50 topics and observing the resulting word lists associated with each topic. With 20 topics, the resulting term lists revealed distinct but consistent features that could be identified as a group of related financial reporting terms. When fewer than 20 topics are used, the words associated with a single topic clearly discussed different reporting concepts, such as revenues and taxes, indicating that multiple financial reporting topics were combined into one LDA topic. When greater than 20 topics are used, the words associated with several different topics became indistinguishable from each other, for example two or more topics containing revenue-related words. Using 20 topics, the groups of features appear both distinct and non-overlapping.</p>
        <p>(Insert Table 3 about here.)(Insert Table 3 about here.)</p>
        <p>Table 3 provides descriptive statistics for the relative frequency at which each topic appears in the entire sample. Similar to prior LDA literature, the topic description is given by manually examining the documents which score highest with each topic (following, e.g., Quinn, Monroe, Colaresi, Crespin and Radev, 2010;Bao and Datta, 2014;Huang et al., 2018). In the comment letter setting, top scoring documents often have just one or two questions which could clearly be described by the description given in the Topic Description column.Table 3 provides descriptive statistics for the relative frequency at which each topic appears in the entire sample. Similar to prior LDA literature, the topic description is given by manually examining the documents which score highest with each topic (following, e.g., Quinn, Monroe, Colaresi, Crespin and Radev, 2010;Bao and Datta, 2014;Huang et al., 2018). In the comment letter setting, top scoring documents often have just one or two questions which could clearly be described by the description given in the Topic Description column.</p>
        <p>The value in the Mean Column of Table 3 describes the average fraction of words in all comment letters assigned to each topic. These descriptives illustrate that the largest amount of comment letter text is devoted to standardized language-the opening and closing paragraphs-with Topic 19, at 12.3 percent, and Topic 18, at 9.0 percent of all comment letter text. After the standardized language, questions on operating performance (Topic 6, 8.0 percent), compensation factors (Topic 10, 7.5 percent), revenue recognition (Topic 4, 5.5 percent), and internal controls (Topic 13, 5.5 percent) appear to be most prominent.The value in the Mean Column of Table 3 describes the average fraction of words in all comment letters assigned to each topic. These descriptives illustrate that the largest amount of comment letter text is devoted to standardized language-the opening and closing paragraphs-with Topic 19, at 12.3 percent, and Topic 18, at 9.0 percent of all comment letter text. After the standardized language, questions on operating performance (Topic 6, 8.0 percent), compensation factors (Topic 10, 7.5 percent), revenue recognition (Topic 4, 5.5 percent), and internal controls (Topic 13, 5.5 percent) appear to be most prominent.</p>
        <p>Appendix C provides additional descriptive details about the LDA classification and its application to an example comment letter. Table C.1 lists the most significant words identified with each topic by the LDA algorithm. Each panel lists the top topic features, along with the probability that the feature appears in a document, given that the topic is present in the document.Appendix C provides additional descriptive details about the LDA classification and its application to an example comment letter. Table C.1 lists the most significant words identified with each topic by the LDA algorithm. Each panel lists the top topic features, along with the probability that the feature appears in a document, given that the topic is present in the document.</p>
        <p>For example, the term loan appears in 7.4 percent of documents containing Topic 1, referred to as Loan Loss Allowances. Some topics have a sharp distribution towards just a few words, for example loan for Topic 1, Loan Loss Allowances, and tax and income for Topic 20 Income Tax.For example, the term loan appears in 7.4 percent of documents containing Topic 1, referred to as Loan Loss Allowances. Some topics have a sharp distribution towards just a few words, for example loan for Topic 1, Loan Loss Allowances, and tax and income for Topic 20 Income Tax.</p>
        <p>The LDA topic analysis appears to be effective at describing the contents of the comment letters, as can be seen from inspecting a sample document. For the empirical tests using LDA topics, it is useful to create dummy variables for a comment letter to indicate the presence of a topic. The LDA algorithm provides continuous topic allocation measures and so each letter has at least some small probability of including every topic. In order to code the significant topics present in a comment letter, this study uses indicator variables for each comment letter conversation, equal to one when the comment letter's topic weighting is in the top quartile of all comment letters for that topic. Table 3 enumerates the 75 percentile threshold, illustrating, for example, that a comment letter requires 6.8 percent of its words to These trends appear to be grounded in economic and regulatory events. Goodwill impairment comments (Topic 2), were elevated during the stock market decline of 2009, when firms were more likely to be trading below book value, a condition which appears to prompt the SEC to question the carrying value of goodwill and companies' impairment testing procedures. Executive compensation comments (Topic 10) increased significantly from 2008 to 2010, peaking in the range of 15 to 20 percent of all comment letter words during this period. This is consistent with a broad lack of compliance with new and revised compensation rules that came into effect beginning November 7, 2006. In fact, the SEC launched a targeted review of filings related to compensation disclosures, completed in September 2007. This targeted review identified consistent areas of weakness, such as failure to disclosure performance targets. 5 . In follow up to these identified areas of disclosure non-compliance, the SEC appears to have included compensation issues in a large fraction of annual reviews for all filers during the subsequent three-year review cycle.The LDA topic analysis appears to be effective at describing the contents of the comment letters, as can be seen from inspecting a sample document. For the empirical tests using LDA topics, it is useful to create dummy variables for a comment letter to indicate the presence of a topic. The LDA algorithm provides continuous topic allocation measures and so each letter has at least some small probability of including every topic. In order to code the significant topics present in a comment letter, this study uses indicator variables for each comment letter conversation, equal to one when the comment letter's topic weighting is in the top quartile of all comment letters for that topic. Table 3 enumerates the 75 percentile threshold, illustrating, for example, that a comment letter requires 6.8 percent of its words to These trends appear to be grounded in economic and regulatory events. Goodwill impairment comments (Topic 2), were elevated during the stock market decline of 2009, when firms were more likely to be trading below book value, a condition which appears to prompt the SEC to question the carrying value of goodwill and companies' impairment testing procedures. Executive compensation comments (Topic 10) increased significantly from 2008 to 2010, peaking in the range of 15 to 20 percent of all comment letter words during this period. This is consistent with a broad lack of compliance with new and revised compensation rules that came into effect beginning November 7, 2006. In fact, the SEC launched a targeted review of filings related to compensation disclosures, completed in September 2007. This targeted review identified consistent areas of weakness, such as failure to disclosure performance targets. 5 . In follow up to these identified areas of disclosure non-compliance, the SEC appears to have included compensation issues in a large fraction of annual reviews for all filers during the subsequent three-year review cycle.</p>
        <p>The fact that executive compensation questions declined significantly following 2010 indicates that the comments were largely effective in helping companies conform to the new compensation disclosure requirements.The fact that executive compensation questions declined significantly following 2010 indicates that the comments were largely effective in helping companies conform to the new compensation disclosure requirements.</p>
        <p>It is also noteworthy that the LDA analysis clearly identifies the change in standardized language in the pre and post 2010 periods, illustrated in the panels for Topic 18 and Topic 19 of Other trends evident in Figure 3 are that segment reporting questions have increased in recent years, as have questions on operating performance. Non-GAAP issues were important in 2007, and after a period of decline, increased in prominence again after 2015. Topic 14, relating to the SEC's questions about export control disclosure compliance have increased steadily over the sample period. Other questions, such as those relating to tax, fair value estimates, and consolidation have remained relatively constant over time.It is also noteworthy that the LDA analysis clearly identifies the change in standardized language in the pre and post 2010 periods, illustrated in the panels for Topic 18 and Topic 19 of Other trends evident in Figure 3 are that segment reporting questions have increased in recent years, as have questions on operating performance. Non-GAAP issues were important in 2007, and after a period of decline, increased in prominence again after 2015. Topic 14, relating to the SEC's questions about export control disclosure compliance have increased steadily over the sample period. Other questions, such as those relating to tax, fair value estimates, and consolidation have remained relatively constant over time.</p>
        <p>In reviews, the SEC frequently urges managers to provide additional disclosures, and such requests may require managers to reveal strategically withheld information as well as identify firms with inadequate financial reporting practices. Responding to comment letters may also cause managers and auditors to uncover information or revise their assumptions for subsequent reporting periods, including possible restatements and write-downs.In reviews, the SEC frequently urges managers to provide additional disclosures, and such requests may require managers to reveal strategically withheld information as well as identify firms with inadequate financial reporting practices. Responding to comment letters may also cause managers and auditors to uncover information or revise their assumptions for subsequent reporting periods, including possible restatements and write-downs.</p>
        <p>If the comment letter process either reveals that a firm had no significant disclosure deficiencies, or if the comments resulted in disclosure improvements without proprietary cost effects, then earnings should not be affected by the review process, and the market response and investors' perceptions of earnings credibility could be positive, consistent with prior literature regarding disclosure quality and performance (e.g., Lang and Lundholm, 1993;Francis, LaFond, Olsson and Schipper, 2005;Francis, Nanda and Olsson, 2008).If the comment letter process either reveals that a firm had no significant disclosure deficiencies, or if the comments resulted in disclosure improvements without proprietary cost effects, then earnings should not be affected by the review process, and the market response and investors' perceptions of earnings credibility could be positive, consistent with prior literature regarding disclosure quality and performance (e.g., Lang and Lundholm, 1993;Francis, LaFond, Olsson and Schipper, 2005;Francis, Nanda and Olsson, 2008).</p>
        <p>However, when managers avoid disclosing proprietary information or bad news, and such undisclosed information is not reflected in market prices (e.g., Dye, 1985;Jung and Kwon, 1988;Bloomfield, 2002), then efforts by the SEC to improve disclosures through the review process could reveal new information in response letters and subsequent periodic filings. Johnston and Petacchi (2017) consider the effects of restatements that occur during the review process, which can preempt the informativeness of the comment letter disclosure itself, since the remedy is already publicly known. But there may be additional information provided in the comment letter correspondence, and the effects of the review may carry on into subsequent periods, with additional disclosures of unfavorable information, resulting in negative returns and a lower market perception of earnings credibility (e.g. Kothari, Shu and Wysocki, 2009b).However, when managers avoid disclosing proprietary information or bad news, and such undisclosed information is not reflected in market prices (e.g., Dye, 1985;Jung and Kwon, 1988;Bloomfield, 2002), then efforts by the SEC to improve disclosures through the review process could reveal new information in response letters and subsequent periodic filings. Johnston and Petacchi (2017) consider the effects of restatements that occur during the review process, which can preempt the informativeness of the comment letter disclosure itself, since the remedy is already publicly known. But there may be additional information provided in the comment letter correspondence, and the effects of the review may carry on into subsequent periods, with additional disclosures of unfavorable information, resulting in negative returns and a lower market perception of earnings credibility (e.g. Kothari, Shu and Wysocki, 2009b).</p>
        <p>Restatements have been shown to be important for auditors as well as managers, since restatements may lead to the dismissal of an audit firm (Hennes et al., 2014). Restatements reflect lower financial reporting quality and affect stock returns (e.g., Hribar and Jenkins, 2004;Kinney et al., 2004;Palmrose et al., 2004;Liu et al., 2009;Dechow et al., 2011;Francis, 2011). Auditors are often copied in the comment letter correspondence (Laurion et al., 2017), and the auditor may subsequently modify their assessment of audit risk, increasing scrutiny of areas of financial reporting weakness raised by the SEC. Comment letters that lead auditors and managers to produce new information or review accounting estimates and policies may reveal underlying shortcomings, which when fully investigated during the subsequent audit cycle, can lead to future restatements or write-downs.Restatements have been shown to be important for auditors as well as managers, since restatements may lead to the dismissal of an audit firm (Hennes et al., 2014). Restatements reflect lower financial reporting quality and affect stock returns (e.g., Hribar and Jenkins, 2004;Kinney et al., 2004;Palmrose et al., 2004;Liu et al., 2009;Dechow et al., 2011;Francis, 2011). Auditors are often copied in the comment letter correspondence (Laurion et al., 2017), and the auditor may subsequently modify their assessment of audit risk, increasing scrutiny of areas of financial reporting weakness raised by the SEC. Comment letters that lead auditors and managers to produce new information or review accounting estimates and policies may reveal underlying shortcomings, which when fully investigated during the subsequent audit cycle, can lead to future restatements or write-downs.</p>
        <p>For less important comment letters, the information revealed through the comment letter process may prove immaterial, and these letters would not be expected to have an impact on returns or earnings credibility, except perhaps through the mechanism by which an innocuous comment letter represents an implicit stamp of approval that the SEC found no material issues in the company's financial reporting. signal is associated with a 25.3 percent increase in the rate of future write-downs.For less important comment letters, the information revealed through the comment letter process may prove immaterial, and these letters would not be expected to have an impact on returns or earnings credibility, except perhaps through the mechanism by which an innocuous comment letter represents an implicit stamp of approval that the SEC found no material issues in the company's financial reporting. signal is associated with a 25.3 percent increase in the rate of future write-downs.</p>
        <p>These univariate result gives initial validation that NB textual classification appears effective in the comment letter setting. The univariate results also indicate that the NB classification is specific to the outcome used to train the classifier, since the NB restatement classification is not statistically useful for identifying future write-downs, and vice-versa. The quantitative signals, while not significant predictors of all outcomes, are effective predictors of at least some outcomes.These univariate result gives initial validation that NB textual classification appears effective in the comment letter setting. The univariate results also indicate that the NB classification is specific to the outcome used to train the classifier, since the NB restatement classification is not statistically useful for identifying future write-downs, and vice-versa. The quantitative signals, while not significant predictors of all outcomes, are effective predictors of at least some outcomes.</p>
        <p>The abnormal returns, revenue recognition, and number of letters based measures appear to have an association with future earnings, and the EDGAR-based signal is a strong predictor of both future restatements and write-downs, indicating that investors appear to recognize the importance of comment letters as revealed by their attention.The abnormal returns, revenue recognition, and number of letters based measures appear to have an association with future earnings, and the EDGAR-based signal is a strong predictor of both future restatements and write-downs, indicating that investors appear to recognize the importance of comment letters as revealed by their attention.</p>
        <p>To study the association between signaled comment letters and higher rates of future material restatements, the following probit regression model is tested for the quantitative and NB restatement classification signals:To study the association between signaled comment letters and higher rates of future material restatements, the following probit regression model is tested for the quantitative and NB restatement classification signals:</p>
        <p>+  4 I(Receivables) i,t-1 +  5 Inventory i,t-1 +  6 Soft Assets i,t-1 +  7 Leverage i,t-1 +  8 I(Secondary Offering) i,t-1 +  9 Earnings i,t-1 +  10 Big4 i,t-1 +  11 Age i,t-1 +  12 Book to Market i,t-1 +  13 log(Market Capitalization) i,t-1 +  14 Insider Sales i,t + Industry FE + Year FE +  i,t .+  4 I(Receivables) i,t-1 +  5 Inventory i,t-1 +  6 Soft Assets i,t-1 +  7 Leverage i,t-1 +  8 I(Secondary Offering) i,t-1 +  9 Earnings i,t-1 +  10 Big4 i,t-1 +  11 Age i,t-1 +  12 Book to Market i,t-1 +  13 log(Market Capitalization) i,t-1 +  14 Insider Sales i,t + Industry FE + Year FE +  i,t .</p>
        <p>(1)(1)</p>
        <p>To study the association between signaled comment letters and higher rates of material writedowns, the following probit regression model is tested for the quantitative and NB write-down classification signals: there is no intercept. The coefficient on  1 is of interest as it indicates that the signal is associated with future levels of earnings. The coefficient on  2 is also of interest, as it indicates the signal is associated with higher future earnings in the presence of higher current earnings, in other words, greater earnings persistence. The regression includes year and Fama-French 49 industry fixed effects. Control variables have been shown in prior literature to affect earnings persistence (e.g., Li, 2008), as well as a control for insider sales. See Appendix B for all variable definitions.To study the association between signaled comment letters and higher rates of material writedowns, the following probit regression model is tested for the quantitative and NB write-down classification signals: there is no intercept. The coefficient on  1 is of interest as it indicates that the signal is associated with future levels of earnings. The coefficient on  2 is also of interest, as it indicates the signal is associated with higher future earnings in the presence of higher current earnings, in other words, greater earnings persistence. The regression includes year and Fama-French 49 industry fixed effects. Control variables have been shown in prior literature to affect earnings persistence (e.g., Li, 2008), as well as a control for insider sales. See Appendix B for all variable definitions.</p>
        <p>(Insert Table 7 about here.)(Insert Table 7 about here.)</p>
        <p>Table 7 reports regression results for estimating Equations 3. Column 1 regresses next-year earnings on the signal, I(EDGAR), earnings, the signal interacted with earnings, and finds a negative impact of the signal on future earnings of 0.01 (p &lt; 0.05), or 1 percentage point of ROA, though the association with earnings persistence is not statistically significant ( 2 ). Column 2 reports that the abnormal returns-based signal has an effect of 0.01 (p &lt; 0.01) on future earnings, but no statistically significant association with earnings persistence. Column 4 reports that the number of letters-based signal is associated with lower earnings persistence, with a coefficient on the interaction variable of -0.18 (p &lt; 0.01), though no statistically significant association with the level of earnings. Column 5 reports a marginally significant association with earnings, with a coefficient of -0.01 (p &lt; 0.1), though no statistically significant association with the persistence coefficient. The revenue recognition and NB write-down signals exhibit no statistically significant association between earnings or earnings persistence and these signals.Table 7 reports regression results for estimating Equations 3. Column 1 regresses next-year earnings on the signal, I(EDGAR), earnings, the signal interacted with earnings, and finds a negative impact of the signal on future earnings of 0.01 (p &lt; 0.05), or 1 percentage point of ROA, though the association with earnings persistence is not statistically significant ( 2 ). Column 2 reports that the abnormal returns-based signal has an effect of 0.01 (p &lt; 0.01) on future earnings, but no statistically significant association with earnings persistence. Column 4 reports that the number of letters-based signal is associated with lower earnings persistence, with a coefficient on the interaction variable of -0.18 (p &lt; 0.01), though no statistically significant association with the level of earnings. Column 5 reports a marginally significant association with earnings, with a coefficient of -0.01 (p &lt; 0.1), though no statistically significant association with the persistence coefficient. The revenue recognition and NB write-down signals exhibit no statistically significant association between earnings or earnings persistence and these signals.</p>
        <p>Overall, these results imply that the EDGAR and CAR signals have some predictive power for lower future earnings, and the number of letters is associated with lower earnings persistence. The textual classification signals, while useful for predicting their respective future restatement and write-down outcomes, do not have statistically significant predictive power for earnings-related outcomes.Overall, these results imply that the EDGAR and CAR signals have some predictive power for lower future earnings, and the number of letters is associated with lower earnings persistence. The textual classification signals, while useful for predicting their respective future restatement and write-down outcomes, do not have statistically significant predictive power for earnings-related outcomes.</p>
        <p>The 8 reports the extent to which each topic is associated with these signals. Given the large number of independent variables, a high standard of statistical significance should be considered, so as to not make inferences based upon spurious associations.The 8 reports the extent to which each topic is associated with these signals. Given the large number of independent variables, a high standard of statistical significance should be considered, so as to not make inferences based upon spurious associations.</p>
        <p>(Insert Table 8 about here.)(Insert Table 8 about here.)</p>
        <p>With many significant associations-both positive, where the topic is more likely to appear in letters classified by the signal, and negative, where the topic is less likely to occur in letters classified by the signal-it is prohibitive to detail each individually. This discussion highlights the associations that confirm the intuitive nature of the classification signals, or which may be of interest to future analysis. Column 1 identifies topics associated with the EDGAR classification, and indicates that comment letters with investor attention discuss segment reporting, licensing agreements, goodwill impairment, tax and insurance. Investors show the least demand for comment letters dominated by standardized language (topics 18 and 19), as would be expected.With many significant associations-both positive, where the topic is more likely to appear in letters classified by the signal, and negative, where the topic is less likely to occur in letters classified by the signal-it is prohibitive to detail each individually. This discussion highlights the associations that confirm the intuitive nature of the classification signals, or which may be of interest to future analysis. Column 1 identifies topics associated with the EDGAR classification, and indicates that comment letters with investor attention discuss segment reporting, licensing agreements, goodwill impairment, tax and insurance. Investors show the least demand for comment letters dominated by standardized language (topics 18 and 19), as would be expected.</p>
        <p>Column 2 of Table 8 indicates that the greatest negative stock return response is to comment letters discussing licensing agreements, indicating that firms fail to properly disclose material license agreements when they are unfavorable or where their disclosure involves significant proprietary costs, resulting in negative price response to their disclosure in comment letter responses.Column 2 of Table 8 indicates that the greatest negative stock return response is to comment letters discussing licensing agreements, indicating that firms fail to properly disclose material license agreements when they are unfavorable or where their disclosure involves significant proprietary costs, resulting in negative price response to their disclosure in comment letter responses.</p>
        <p>Column 3 of Table 8 indicates that the LDA revenue recognition top is strongly related (tstatistic of 42.9) with the audit analytics taxonomy coding used to define the Revenue Recognition classification signal, confirming the consistency of the LDA topic classification mechanism with a human-coded classification. Insurance, capitalization and cash flows, and licensing agreement topics are related to the audit analytics revenue recognition taxonomy coding, and these items seem logically consistent with revenue-related discussions, except for the insurance topic, whose association with revenue questions is not intuitively clear.Column 3 of Table 8 indicates that the LDA revenue recognition top is strongly related (tstatistic of 42.9) with the audit analytics taxonomy coding used to define the Revenue Recognition classification signal, confirming the consistency of the LDA topic classification mechanism with a human-coded classification. Insurance, capitalization and cash flows, and licensing agreement topics are related to the audit analytics revenue recognition taxonomy coding, and these items seem logically consistent with revenue-related discussions, except for the insurance topic, whose association with revenue questions is not intuitively clear.</p>
        <p>Column 4 of Table 8 reveals that twelve of twenty topics are strongly related to the number of comment letters in a conversation. As a result, each of these topics may result in extensive comments, which are costly to remediate, while the remaining eight topics may be less complicated to resolve. The most costly topics appear to be topics relating to executive compensation, segment reporting, goodwill impairment, and non-GAAP reporting issues, whereas the least costly comment letters appear related to standardized language, an intuitively obvious result.Column 4 of Table 8 reveals that twelve of twenty topics are strongly related to the number of comment letters in a conversation. As a result, each of these topics may result in extensive comments, which are costly to remediate, while the remaining eight topics may be less complicated to resolve. The most costly topics appear to be topics relating to executive compensation, segment reporting, goodwill impairment, and non-GAAP reporting issues, whereas the least costly comment letters appear related to standardized language, an intuitively obvious result.</p>
        <p>The association between topics and the NB restatement classification is detailed in Column 5 of Table 8, and the analysis indicates that tax, insurance, and goodwill impairment topics are most associated with the restatement signal. For the NB write-down classification, described in Column 6, the most significantly associated topics are goodwill impairment, tax, and executive compensation. While the goodwill impairment result is expected as the topic is closely aligned with write-downs, the tax and executive compensation links are not as obvious. Robinson et al. (2011) examine the relationship between comment letters on executive compensation disclosure deficiencies, and find that such issues are related to excess compensation, but do not consider other future reporting outcomes such as write-downs.The association between topics and the NB restatement classification is detailed in Column 5 of Table 8, and the analysis indicates that tax, insurance, and goodwill impairment topics are most associated with the restatement signal. For the NB write-down classification, described in Column 6, the most significantly associated topics are goodwill impairment, tax, and executive compensation. While the goodwill impairment result is expected as the topic is closely aligned with write-downs, the tax and executive compensation links are not as obvious. Robinson et al. (2011) examine the relationship between comment letters on executive compensation disclosure deficiencies, and find that such issues are related to excess compensation, but do not consider other future reporting outcomes such as write-downs.</p>
        <p>(Insert Table 9 about here.)(Insert Table 9 about here.)</p>
        <p>Table 9 performs a probit regression analysis of the LDA topics directly on future restatements and write-downs to determine if the presence of these topics are themselves a sufficient signal for identifying important comment letters. The regression model controls are the same controls used in Equations 1 and 2. The coefficients are presented, with the marginal effect probability in parentheses to the right of the coefficient.Table 9 performs a probit regression analysis of the LDA topics directly on future restatements and write-downs to determine if the presence of these topics are themselves a sufficient signal for identifying important comment letters. The regression model controls are the same controls used in Equations 1 and 2. The coefficients are presented, with the marginal effect probability in parentheses to the right of the coefficient.</p>
        <p>In Column 1, the marginal effect of the loan loss topic (T1), for example, is significant at the p &lt; 0.1 level, with a marginal effect of 1.4 percentage points, on a base rate of 7.7 percent, which appears material. However, given that there are 20 independent variables of interest, a variable that achieves significance at the p &lt; 0.05 or p &lt; 0.1 level may be spurious. Held to this standard, none of the topics are highly significant predictors of future restatements. This may reflect either a lack of statistical power or the fact that comments on particular topics vary in their severity, and so additional quantitative or language cues are needed to identify important comment letters.In Column 1, the marginal effect of the loan loss topic (T1), for example, is significant at the p &lt; 0.1 level, with a marginal effect of 1.4 percentage points, on a base rate of 7.7 percent, which appears material. However, given that there are 20 independent variables of interest, a variable that achieves significance at the p &lt; 0.05 or p &lt; 0.1 level may be spurious. Held to this standard, none of the topics are highly significant predictors of future restatements. This may reflect either a lack of statistical power or the fact that comments on particular topics vary in their severity, and so additional quantitative or language cues are needed to identify important comment letters.</p>
        <p>In Column 2, the goodwill impairment topic (T2) is a significant predictor of future writedowns (p &lt; 0.01), with a marginal effect of 4.9 percent on a base rate of 23.7 percent. This result indicates that questions on this topic alone appear sufficiently powerful to be associated with higher rates of future write-downs. None of the other topics achieve a coefficient different from zero with a high level of statistical significance.In Column 2, the goodwill impairment topic (T2) is a significant predictor of future writedowns (p &lt; 0.01), with a marginal effect of 4.9 percent on a base rate of 23.7 percent. This result indicates that questions on this topic alone appear sufficiently powerful to be associated with higher rates of future write-downs. None of the other topics achieve a coefficient different from zero with a high level of statistical significance.</p>
        <p>Overall, this results indicate that different topics are clearly associated with the market, attention and reporting outcome based signals of future outcomes. The association between the LDA goodwill impairment topic and future write-downs is intuitive, but most other LDA topics are not otherwise sufficient to predict financial reporting outcomes directly. Some significant associations are less obvious and potentially interesting avenues for further investigation, for example an association between executive compensation-related letters and future write-downs (Dechow, Huson and Sloan, 1994).Overall, this results indicate that different topics are clearly associated with the market, attention and reporting outcome based signals of future outcomes. The association between the LDA goodwill impairment topic and future write-downs is intuitive, but most other LDA topics are not otherwise sufficient to predict financial reporting outcomes directly. Some significant associations are less obvious and potentially interesting avenues for further investigation, for example an association between executive compensation-related letters and future write-downs (Dechow, Huson and Sloan, 1994).</p>
        <p>The final set of analyses in this study investigates variation in improvements to earnings credibility surrounding comment letter disclosure, based upon the classifications of comment letter importance.The final set of analyses in this study investigates variation in improvements to earnings credibility surrounding comment letter disclosure, based upon the classifications of comment letter importance.</p>
        <p>Johnston and Petacchi (2017) find that comment letters, on average, improve firms' information environment through increases in earnings credibility, measured by ERCs, following comment letter disclosure. This gives rise to two interpretations: First, comment letters could causally affect a firm's reporting quality through channels such as modified accounting estimates or audit intensity, resulting in changes to earnings quality. Second, the comment letters could simply reveal information about the underlying financial reporting quality of the firm, without having a causal effect.Johnston and Petacchi (2017) find that comment letters, on average, improve firms' information environment through increases in earnings credibility, measured by ERCs, following comment letter disclosure. This gives rise to two interpretations: First, comment letters could causally affect a firm's reporting quality through channels such as modified accounting estimates or audit intensity, resulting in changes to earnings quality. Second, the comment letters could simply reveal information about the underlying financial reporting quality of the firm, without having a causal effect.</p>
        <p>The following analysis provides evidence, using textual and quantitative classifications, of which subsets of comment letters are associated with changes in earnings credibility. The first step of the analysis replicates the Johnston and Petacchi (2017) ERC result in this sample period.The following analysis provides evidence, using textual and quantitative classifications, of which subsets of comment letters are associated with changes in earnings credibility. The first step of the analysis replicates the Johnston and Petacchi (2017) ERC result in this sample period.</p>
        <p>Next, the ERC analysis is conducted on subsamples for each classification signal, to identify the effect of each type of important comment letter on ERC changes. The ERC analysis takes the form of an OLS regression using the following model, which is estimated for observations using four quarterly earnings announcements prior to, and four observations following, each comment letter:Next, the ERC analysis is conducted on subsamples for each classification signal, to identify the effect of each type of important comment letter on ERC changes. The ERC analysis takes the form of an OLS regression using the following model, which is estimated for observations using four quarterly earnings announcements prior to, and four observations following, each comment letter:</p>
        <p>POST is an indicator variable equal to 1 for quarterly earnings announcements after the comment letter disclosure, and 0 prior to the comment letter disclosure. The subsamples are for span the sample, there is no intercept. The coefficient on  3 is of interest as it indicates that the signal is associated with changes in the earnings response to SUE in the post-period. A positive coefficient on  3 is consistent with higher market response to earnings surprises, following comment letter disclosure. The regression includes all control variables interacted with SUE, firm and year fixed effects. The control variables are those used in Johnston and Petacchi (2017), following prior literature (e.g., Kormendi and Lipe, 1987;Mendenhall and Nichols, 1988;Collins and Kothari, 1989;Hayn, 1995;Bartov, Givoly and Hayn, 2002). See Appendix B for all variable definitions.POST is an indicator variable equal to 1 for quarterly earnings announcements after the comment letter disclosure, and 0 prior to the comment letter disclosure. The subsamples are for span the sample, there is no intercept. The coefficient on  3 is of interest as it indicates that the signal is associated with changes in the earnings response to SUE in the post-period. A positive coefficient on  3 is consistent with higher market response to earnings surprises, following comment letter disclosure. The regression includes all control variables interacted with SUE, firm and year fixed effects. The control variables are those used in Johnston and Petacchi (2017), following prior literature (e.g., Kormendi and Lipe, 1987;Mendenhall and Nichols, 1988;Collins and Kothari, 1989;Hayn, 1995;Bartov, Givoly and Hayn, 2002). See Appendix B for all variable definitions.</p>
        <p>(Insert Table 10 about here.)(Insert Table 10 about here.)</p>
        <p>Table 10 presents the results of this analysis. Due to the significant number of models and variables, the coefficients on the control variables are suppressed. The main result of Johnston and Petacchi (2017) is replicated in Column 1, with a positive and significant coefficient on SUE * POST (coef. = 0.146, p &lt; 0.05), indicating that ERCs are higher following comment letter disclosure, suggesting improved earnings credibility as a result of the comment letter process.Table 10 presents the results of this analysis. Due to the significant number of models and variables, the coefficients on the control variables are suppressed. The main result of Johnston and Petacchi (2017) is replicated in Column 1, with a positive and significant coefficient on SUE * POST (coef. = 0.146, p &lt; 0.05), indicating that ERCs are higher following comment letter disclosure, suggesting improved earnings credibility as a result of the comment letter process.</p>
        <p>The remaining columns examine this result for subsets of the comment letter sample based upon the textual and quantitative classifications.The remaining columns examine this result for subsets of the comment letter sample based upon the textual and quantitative classifications.</p>
        <p>There is little evidence that the important comment letters are related to improvements in ERCs. Rather, improvement in ERCs generally occur with the disclosure of innocuous comment letters, i.e. those not classified as important by the text and quantitative classification signals.There is little evidence that the important comment letters are related to improvements in ERCs. Rather, improvement in ERCs generally occur with the disclosure of innocuous comment letters, i.e. those not classified as important by the text and quantitative classification signals.</p>
        <p>Columns 2 and 3 of Table 10 examine The only signal of importance positively associated with ERC improvements is the returnsbased classification in columns 4 and 5 of Table 10, which illustrates that the effect of the negative returns classification is positive and significant (Column 5, coef. = 0.429, p &lt; 0.01), while the lack of a signal has a negative but insignificant coefficient (Column 4, coef. = -0.004, p &gt; 0.1).Columns 2 and 3 of Table 10 examine The only signal of importance positively associated with ERC improvements is the returnsbased classification in columns 4 and 5 of Table 10, which illustrates that the effect of the negative returns classification is positive and significant (Column 5, coef. = 0.429, p &lt; 0.01), while the lack of a signal has a negative but insignificant coefficient (Column 4, coef. = -0.004, p &gt; 0.1).</p>
        <p>These results provide an interesting perspective on the mechanisms by which comment letters affect earnings credibility. Comment letters classified as important using the textual and most of the quantitative signals do not have a significant association with improved ERCs, but comment letters classified as unimportant have a significant positive association with ERC improvement.These results provide an interesting perspective on the mechanisms by which comment letters affect earnings credibility. Comment letters classified as important using the textual and most of the quantitative signals do not have a significant association with improved ERCs, but comment letters classified as unimportant have a significant positive association with ERC improvement.</p>
        <p>This evidence supports the inference that innocuous comment letters reveal higher earnings quality compared to the market's perception prior to the comment letter review.This evidence supports the inference that innocuous comment letters reveal higher earnings quality compared to the market's perception prior to the comment letter review.</p>
        <p>The SEC comment letter process reveals valuable information about the financial reporting quality of public issuers with implications for future financial reporting outcomes and earnings credibility. Classifying comment letters based on quantitative measures (i.e., EDGAR downloads, announcement returns, revenue recognition comments, number of letters) and textual analysis (i.e., Naive Bayesian classifications for future restatements and write-downs) provides significant predictive power for future financial reporting outcomes such as future restatements, write-downs, and earnings.The SEC comment letter process reveals valuable information about the financial reporting quality of public issuers with implications for future financial reporting outcomes and earnings credibility. Classifying comment letters based on quantitative measures (i.e., EDGAR downloads, announcement returns, revenue recognition comments, number of letters) and textual analysis (i.e., Naive Bayesian classifications for future restatements and write-downs) provides significant predictive power for future financial reporting outcomes such as future restatements, write-downs, and earnings.</p>
        <p>While the textual classification signals are effective predictors of the specific outcomes for which they are developed, future restatements and write-downs, they are not particularly broad signals of comment letter importance, as they do not predict each other's outcomes, and do not have a statistically significant association with earnings or earnings persistence. The EDGAR download based signal of importance, which may be easier to calculate than a text based measure, appears to be a useful metric for predicting both future restatements and write-downs, Improvements in earnings credibility following comment letters, measured using changes in ERCs, is mostly dominated by comment letters classified as not important, except for the negative announcement return signal, which does indicate letters associated with ERC improvements. This provides evidence that it is generally the innocuous comment letters that are associated with the market's subsequent perception of higher earnings credibility.While the textual classification signals are effective predictors of the specific outcomes for which they are developed, future restatements and write-downs, they are not particularly broad signals of comment letter importance, as they do not predict each other's outcomes, and do not have a statistically significant association with earnings or earnings persistence. The EDGAR download based signal of importance, which may be easier to calculate than a text based measure, appears to be a useful metric for predicting both future restatements and write-downs, Improvements in earnings credibility following comment letters, measured using changes in ERCs, is mostly dominated by comment letters classified as not important, except for the negative announcement return signal, which does indicate letters associated with ERC improvements. This provides evidence that it is generally the innocuous comment letters that are associated with the market's subsequent perception of higher earnings credibility.</p>
        <p>Topics discussed in comment letters show variation over time, and reflect the priorities of the SEC for enforcing new rules and regulations, and changes in issuer reporting behavior. The topics discussed in the comment letters have plausible relationships to the signals of importance, and the goodwill impairment topic's by itself is predictive of future write-downs. The relationships between comment letter topics and investor attention and future financial reporting outcomes may suggest topics that appear important to investors but have not yet been explored in the literature.Topics discussed in comment letters show variation over time, and reflect the priorities of the SEC for enforcing new rules and regulations, and changes in issuer reporting behavior. The topics discussed in the comment letters have plausible relationships to the signals of importance, and the goodwill impairment topic's by itself is predictive of future write-downs. The relationships between comment letter topics and investor attention and future financial reporting outcomes may suggest topics that appear important to investors but have not yet been explored in the literature.</p>
        <p>Overall, this study illustrates the effectiveness of various textual and quantitative classifications of comment letter importance, and provides evidence that the SEC's oversight process is useful to investors.Overall, this study illustrates the effectiveness of various textual and quantitative classifications of comment letter importance, and provides evidence that the SEC's oversight process is useful to investors.</p>
        <p>Figure 1. Classification and analysis process. This table presents probit results from the model given by Equation 1, using the quantitative and textual classification signal of restatements as predictors of future restatements. The regressions also include Fama-French 49 industry and year fixed effects. Each observation is a firm-comment letter conversation disclosed in fiscal year t. Financial variables are calculated using amounts available from fiscal year year t -1, the year prior to the comment letter's disclosure. I(Restatement) t+1 is equal to one if a restatement is disclosed in year t + 1, the year following comment letter disclosure. Refer to Appendix B for variable definitions. This table presents probit results from the model given by Equation 2 using the quantitative and textual classification signal of write-downs as predictors of future write-downs. The regressions also include Fama-French 49 industry and year fixed effects. Each observation is a firm-comment letter conversation disclosed in fiscal year t. Financial variables are calculated using amounts available from fiscal year year t-1, the year prior to the comment letter's disclosure. I(Write-Down) t+1 is equal to one if a write-down is disclosed in year t + 1, the year following comment letter disclosure. Refer to Appendix B for variable definitions. Each column reports coefficients, with t-statistics underneath in parentheses, as well as the marginal probability change induced by a change from zero to one for the indicator signal variables, from the sample average. The marginal probability in Column 6 reflects the sum of the changes induced by a change from zero to one for each the indicator signal variables for the probit regression with all signals included. * p&lt;0.1; * * p&lt;0.05; * * * p&lt;0.01. Classification:Figure 1. Classification and analysis process. This table presents probit results from the model given by Equation 1, using the quantitative and textual classification signal of restatements as predictors of future restatements. The regressions also include Fama-French 49 industry and year fixed effects. Each observation is a firm-comment letter conversation disclosed in fiscal year t. Financial variables are calculated using amounts available from fiscal year year t -1, the year prior to the comment letter's disclosure. I(Restatement) t+1 is equal to one if a restatement is disclosed in year t + 1, the year following comment letter disclosure. Refer to Appendix B for variable definitions. This table presents probit results from the model given by Equation 2 using the quantitative and textual classification signal of write-downs as predictors of future write-downs. The regressions also include Fama-French 49 industry and year fixed effects. Each observation is a firm-comment letter conversation disclosed in fiscal year t. Financial variables are calculated using amounts available from fiscal year year t-1, the year prior to the comment letter's disclosure. I(Write-Down) t+1 is equal to one if a write-down is disclosed in year t + 1, the year following comment letter disclosure. Refer to Appendix B for variable definitions. Each column reports coefficients, with t-statistics underneath in parentheses, as well as the marginal probability change induced by a change from zero to one for the indicator signal variables, from the sample average. The marginal probability in Column 6 reflects the sum of the changes induced by a change from zero to one for each the indicator signal variables for the probit regression with all signals included. * p&lt;0.1; * * p&lt;0.05; * * * p&lt;0.01. Classification:</p>
        <p>(3)(3)</p>
        <p>(5) This table presents the top 10 Naive Bayes classification signal terms for each test sample year, listed in the column headers. The list is ordered by the greatest ratio of the term's presence when the classification signal is true to presence when the signal is false.(5) This table presents the top 10 Naive Bayes classification signal terms for each test sample year, listed in the column headers. The list is ordered by the greatest ratio of the term's presence when the classification signal is true to presence when the signal is false.</p>
        <p>Appendix C. Supplemental LDA Analysis We have reviewed your filings and have the following comments. Where indicated, we think you should revise your document in response to these comments. If you disagree, we will consider your explanation as to why our comment is inapplicable or a revision is unnecessary. Please be as detailed as necessary in your explanation. In some of our comments, we may ask you to provide us with information so we may better understand your disclosure. After reviewing this information, we may raise additional comments. Please understand that the purpose of our review process is to assist you in your compliance with the applicable disclosure requirements and to enhance the overall disclosure in your filings.Appendix C. Supplemental LDA Analysis We have reviewed your filings and have the following comments. Where indicated, we think you should revise your document in response to these comments. If you disagree, we will consider your explanation as to why our comment is inapplicable or a revision is unnecessary. Please be as detailed as necessary in your explanation. In some of our comments, we may ask you to provide us with information so we may better understand your disclosure. After reviewing this information, we may raise additional comments. Please understand that the purpose of our review process is to assist you in your compliance with the applicable disclosure requirements and to enhance the overall disclosure in your filings.</p>
        <p>We look forward to working with you in these respects. We welcome any questions you may have about our comments or any other aspect of our review. Feel free to call us at the telephone numbers listed at the end of this letter. {Letter body} As appropriate, please respond to our comments within 10 business days or tell us when you will provide us with a response. Please furnish a cover letter that keys your responses to our comments and provides any requested information. Detailed cover letters greatly facilitate our review. Please understand that we may have additional comments after reviewing responses to our comments. We urge all persons who are responsible for the accuracy and adequacy of the disclosure in the filing to be certain that the filing includes all information required under the Securities Exchange Act of 1934 and that they have provided all information investors require for an informed investment decision. Since the company and its management are in possession of all facts relating to a company's disclosure, they are responsible for the accuracy and adequacy of the disclosures they have made. {Contact information and signatures} We have reviewed your filing and have the following comments. In some of our comments, we may ask you to provide us with information so we may better understand your disclosure. Please respond to this letter within ten business days by providing the requested information or by advising us when you will provide the requested response. If you do not believe our comments apply to your facts and circumstances, please tell us why in your response.We look forward to working with you in these respects. We welcome any questions you may have about our comments or any other aspect of our review. Feel free to call us at the telephone numbers listed at the end of this letter. {Letter body} As appropriate, please respond to our comments within 10 business days or tell us when you will provide us with a response. Please furnish a cover letter that keys your responses to our comments and provides any requested information. Detailed cover letters greatly facilitate our review. Please understand that we may have additional comments after reviewing responses to our comments. We urge all persons who are responsible for the accuracy and adequacy of the disclosure in the filing to be certain that the filing includes all information required under the Securities Exchange Act of 1934 and that they have provided all information investors require for an informed investment decision. Since the company and its management are in possession of all facts relating to a company's disclosure, they are responsible for the accuracy and adequacy of the disclosures they have made. {Contact information and signatures} We have reviewed your filing and have the following comments. In some of our comments, we may ask you to provide us with information so we may better understand your disclosure. Please respond to this letter within ten business days by providing the requested information or by advising us when you will provide the requested response. If you do not believe our comments apply to your facts and circumstances, please tell us why in your response.</p>
        <p>After reviewing the information you provide in response to these comments, we may have additional comments. {Letter body} We urge all persons who are responsible for the accuracy and adequacy of the disclosure in the filing to be certain that the filing includes the information the Securities Exchange Act of 1934 and all applicable Exchange Act rules require. Since the company and its management are in possession of all facts relating to a company's disclosure, they are responsible for the accuracy and adequacy of the disclosures they have made.After reviewing the information you provide in response to these comments, we may have additional comments. {Letter body} We urge all persons who are responsible for the accuracy and adequacy of the disclosure in the filing to be certain that the filing includes the information the Securities Exchange Act of 1934 and all applicable Exchange Act rules require. Since the company and its management are in possession of all facts relating to a company's disclosure, they are responsible for the accuracy and adequacy of the disclosures they have made.</p>
        <p>In responding to our comments, please provide a written statement from the company acknowledging that:In responding to our comments, please provide a written statement from the company acknowledging that:</p>
        <p> the company is responsible for the adequacy and accuracy of the disclosure in the filing; the company is responsible for the adequacy and accuracy of the disclosure in the filing;</p>
        <p> staff comments or changes to disclosure in response to staff comments do not foreclose the Commission from taking any action with respect to the filing; and staff comments or changes to disclosure in response to staff comments do not foreclose the Commission from taking any action with respect to the filing; and</p>
        <p> the company may not assert staff comments as a defense in any proceeding initiated by the Commission or any person under the federal securities laws of the United States. the company may not assert staff comments as a defense in any proceeding initiated by the Commission or any person under the federal securities laws of the United States.</p>
        <p>{Contact information and signatures}{Contact information and signatures}</p>
        <p>t represents the comment letter classification signals, I(EDGAR) i,t , I(CAR[-1,10]) i,t , I(Revenue Recognition) i,t , I(Number of Letters) i,t , and I(NB Restatement) i,t , for comment letter conversation-firm i, in disclsoure year t. disclosure date, but 0 otherwise. All other variables are measured as of the most recent fiscal year end prior to the comment letter disclosure, year t -1. The regression includes year and Fama-French 49 industry fixed effects. Control variables have been shown in prior literature to predict restatements (e.g., fects analysis indicates that the presence of this signal increases the probability of restating during the next year by 1.99 percent, a significant increase over the base rate of next-year restatements of 7.71 percent. Columns 2 through 4 illustrate that the other quantitative classifications do not have a statistically significant association between the signals and next-year restatements, consistent witht represents the comment letter classification signals, I(EDGAR) i,t , I(CAR[-1,10]) i,t , I(Revenue Recognition) i,t , I(Number of Letters) i,t , and I(NB Restatement) i,t , for comment letter conversation-firm i, in disclsoure year t. disclosure date, but 0 otherwise. All other variables are measured as of the most recent fiscal year end prior to the comment letter disclosure, year t -1. The regression includes year and Fama-French 49 industry fixed effects. Control variables have been shown in prior literature to predict restatements (e.g., fects analysis indicates that the presence of this signal increases the probability of restating during the next year by 1.99 percent, a significant increase over the base rate of next-year restatements of 7.71 percent. Columns 2 through 4 illustrate that the other quantitative classifications do not have a statistically significant association between the signals and next-year restatements, consistent with</p>
        <p>I(Signal) i,t represents the comment letter signals of interest: I(EDGAR) i,t , I(CAR[-1,10]) i,t , I(Revenue Recognition) i,t , I(Number of Letters) i,t , and I(NB Write-Down) i,t , for comment letter conversation-firm i, in disclosure year t. Because the fixed effects span the sample, there is no intercept. The dependent variable, I(Write-Down) i,t+1 , is an indicator variable equal to 1 if the firm reports a write-down during the year following the comment letter disclosure date, but 0 otherwise. All other variables are measured as of the most recent fiscal year end prior to the comment letter disclosure, year t -1. The regression includes year and Fama-French 49 industry fixed effects. Control variables have been shown in prior literature to predict write-downs (e.g.,I(Signal) i,t represents the comment letter signals of interest: I(EDGAR) i,t , I(CAR[-1,10]) i,t , I(Revenue Recognition) i,t , I(Number of Letters) i,t , and I(NB Write-Down) i,t , for comment letter conversation-firm i, in disclosure year t. Because the fixed effects span the sample, there is no intercept. The dependent variable, I(Write-Down) i,t+1 , is an indicator variable equal to 1 if the firm reports a write-down during the year following the comment letter disclosure date, but 0 otherwise. All other variables are measured as of the most recent fiscal year end prior to the comment letter disclosure, year t -1. The regression includes year and Fama-French 49 industry fixed effects. Control variables have been shown in prior literature to predict write-downs (e.g.,</p>
        <p>Ramanna and Watts, 2012;Lawrence et al., 2013)Ramanna and Watts, 2012;Lawrence et al., 2013)</p>
        <p>, as well as a control for insider sales. All variables are defined in Appendix B. The coefficient of interest,  1 , will be positive if firms with comment letters classified according to a signal is more likely to record a write-down in the year following comment letter disclosure., as well as a control for insider sales. All variables are defined in Appendix B. The coefficient of interest,  1 , will be positive if firms with comment letters classified according to a signal is more likely to record a write-down in the year following comment letter disclosure.</p>
        <p>23.71 percent. Columns 2 and 4 illustrate the classifications based on CAR (p &lt; 0.1, marginal effect of 1.92 percent) and number of letters (p &lt; 0.1, marginal effect 1.77 percent) have power at marginal levels of statistical significance. Column 3 reveals no statistically significant power to detect an23.71 percent. Columns 2 and 4 illustrate the classifications based on CAR (p &lt; 0.1, marginal effect of 1.92 percent) and number of letters (p &lt; 0.1, marginal effect 1.77 percent) have power at marginal levels of statistical significance. Column 3 reveals no statistically significant power to detect an</p>
        <p>5.4. Earnings, Earnings Persistence, and Comment Letter Classifications5.4. Earnings, Earnings Persistence, and Comment Letter Classifications</p>
        <p>To study the association between signaled comment letters, earnings, and earnings persistence, the following OLS regression model is tested for the quantitative and NB text classification signals:To study the association between signaled comment letters, earnings, and earnings persistence, the following OLS regression model is tested for the quantitative and NB text classification signals:</p>
        <p>Earnings i,t =  1 Signal i,t +  2 Earnings i,t-1 * Signal i,t +  3 Earnings i,t-1 +  4 Accruals i,t-1 +  5 I(Dividend)Earnings i,t =  1 Signal i,t +  2 Earnings i,t-1 * Signal i,t +  3 Earnings i,t-1 +  4 Accruals i,t-1 +  5 I(Dividend)</p>
        <p>i,t-1 +  6 Special Items i,t-1 +  7 Num. Bus. Segments i,t-1 +  8 Num. Geo. Segments i,t-1 +  9 I(Secondary Offering) i,t-1 +  10 I(Acquisition) i,t-1 +  11 Age i,t-1 +  12 Book to Market i,t-1 +  13 log(Market Capitalization) i,t-1 +  14 Insider Sales i,t + Industry FE + Year FE +  i,t . (3) Signal i,t represents the comment letter signals of interest: I(EDGAR) i,t , I(CAR[-1,10]) i,t , I(Revenue Recognition) i,t , I(Number of Letters) i,t , I(NB Restatement) i,t , and I(NB Write-Down) i,t , for comment letter conversation-firm i, in disclsoure year t. Because the fixed effects span the sample,i,t-1 +  6 Special Items i,t-1 +  7 Num. Bus. Segments i,t-1 +  8 Num. Geo. Segments i,t-1 +  9 I(Secondary Offering) i,t-1 +  10 I(Acquisition) i,t-1 +  11 Age i,t-1 +  12 Book to Market i,t-1 +  13 log(Market Capitalization) i,t-1 +  14 Insider Sales i,t + Industry FE + Year FE +  i,t . (3) Signal i,t represents the comment letter signals of interest: I(EDGAR) i,t , I(CAR[-1,10]) i,t , I(Revenue Recognition) i,t , I(Number of Letters) i,t , I(NB Restatement) i,t , and I(NB Write-Down) i,t , for comment letter conversation-firm i, in disclsoure year t. Because the fixed effects span the sample,</p>
        <p>**</p>
        <p>**</p>
        <p>* p&lt;0.1; * * p&lt;0.05; * * * p&lt;0.01.* p&lt;0.1; * * p&lt;0.05; * * * p&lt;0.01.</p>
        <p>* p&lt;0.1; * ** p&lt;0.1; * *</p>
        <p>The online appendix contains the NB classification models and sample code needed to calculate the NB restatement and write-down signals for new comment letters.The online appendix contains the NB classification models and sample code needed to calculate the NB restatement and write-down signals for new comment letters.</p>
        <p>As described previously, the use of multi-word features such as bigrams, which are used in this study, can allow for some preservation of word order in NB analysis.As described previously, the use of multi-word features such as bigrams, which are used in this study, can allow for some preservation of word order in NB analysis.</p>
        <p>See Securities and Exchange Commission. Staff Observations in the Review of Executive Compensation Disclosure. September 10, 2007. Available at http://www.sec.gov/divisions/corpfin/guidance/ execcompdisclosure.htm.See Securities and Exchange Commission. Staff Observations in the Review of Executive Compensation Disclosure. September 10, 2007. Available at http://www.sec.gov/divisions/corpfin/guidance/ execcompdisclosure.htm.</p>
        <p>Topic Description is a manually assigned brief summary of the topic, based on inspection of documents that score highest for percentage of content related to the topic. Short Name is an abbreviation of the topic description used where lack of space requires a brief topic identifier. Mean is the mean percentage of the topic weighting in the sample documents (N = 8,483), and represents the average topic weighting across all documents. In each document, the sum of the weightings for all topics adds to 1. Indicator variable set to one if quarter q occurs after comment letter disclosure. Q4 qTopic Description is a manually assigned brief summary of the topic, based on inspection of documents that score highest for percentage of content related to the topic. Short Name is an abbreviation of the topic description used where lack of space requires a brief topic identifier. Mean is the mean percentage of the topic weighting in the sample documents (N = 8,483), and represents the average topic weighting across all documents. In each document, the sum of the weightings for all topics adds to 1. Indicator variable set to one if quarter q occurs after comment letter disclosure. Q4 q</p>
        <p>Indicator variable set to one if quarter q is the firm's fourth quarter.Indicator variable set to one if quarter q is the firm's fourth quarter.</p>
        <p>Receivables as a fraction of total assets, winsorized at the one percent level (Compustat: rect t /at t ) I(Restatement) t+1Receivables as a fraction of total assets, winsorized at the one percent level (Compustat: rect t /at t ) I(Restatement) t+1</p>
        <p>Indicator variable equal to 1 if a material restatement was announced during the first full fiscal year beginning after the comment letter disclosure date (Audit Analytics Restatements). I(Revenue Recognition)Indicator variable equal to 1 if a material restatement was announced during the first full fiscal year beginning after the comment letter disclosure date (Audit Analytics Restatements). I(Revenue Recognition)</p>
        <p>Indicator variable equal to 1 if revenue recognition questions are asked by the SEC in form UPLOAD filings for the comment letter conversation, which is all comment letters (form UPLOAD) and company responses (form CORRESP) for a given filer (identified by CIK), disclosed on the same date. (Audit Analytics: LIST CL ISSUE PHRASE contains "[rR]evenue rec"'), as in Dechow et al. (2016) Sales Growth t Sales growth, winsorized at the one percent level (Compustat: (sale tsale t-1 )/sale t-1 ) I(Secondary Offering) t Indicator variable if the firm had a material issuance of equity during the fiscal year (Compustat: 1 if sstk t /at t-1 &gt; 0.1 but 0 otherwise).Indicator variable equal to 1 if revenue recognition questions are asked by the SEC in form UPLOAD filings for the comment letter conversation, which is all comment letters (form UPLOAD) and company responses (form CORRESP) for a given filer (identified by CIK), disclosed on the same date. (Audit Analytics: LIST CL ISSUE PHRASE contains "[rR]evenue rec"'), as in Dechow et al. (2016) Sales Growth t Sales growth, winsorized at the one percent level (Compustat: (sale tsale t-1 )/sale t-1 ) I(Secondary Offering) t Indicator variable if the firm had a material issuance of equity during the fiscal year (Compustat: 1 if sstk t /at t-1 &gt; 0.1 but 0 otherwise).</p>
        <p>Fraction of assets that are neither cash nor property, plant, and equipment, winsorized at the one percent level (Compustat: (at tppent tche t )/at t ). Special Items t Special items as a fraction of total assets winsorized at the one percent level (Compustat: spi t /at t ). SUE qFraction of assets that are neither cash nor property, plant, and equipment, winsorized at the one percent level (Compustat: (at tppent tche t )/at t ). Special Items t Special items as a fraction of total assets winsorized at the one percent level (Compustat: spi t /at t ). SUE q</p>
        <p>Standardized unexpected earnings (IBES: (ACT UAL q -MEANES T q ) * ad jex q /prccq q ). When IBES consensus is not available, earnings and lagged samequarter earnings from Compustat ((ibad jq q /cshoq qibad jq q-4 /cshoq q-4 )/prccq q ) is used (Livnat and Mendenhall, 2006). I(Write-Down) t+1Standardized unexpected earnings (IBES: (ACT UAL q -MEANES T q ) * ad jex q /prccq q ). When IBES consensus is not available, earnings and lagged samequarter earnings from Compustat ((ibad jq q /cshoq qibad jq q-4 /cshoq q-4 )/prccq q ) is used (Livnat and Mendenhall, 2006). I(Write-Down) t+1</p>
        <p>Indicator variable equal to 1 if the firm reports a write-down during the year following the comment letter disclosure date, but 0 otherwise (Compustat: 1 if either wd p t+1 &lt; 0 or gdwlip t+1 &lt; 0, 0 otherwise). We note the disclosure of the tax holiday for your business operations in Switzerland. Please tell us how your disclosure complies with the requirements of SAB Topic 11-C. Please also tell us why the impact of the incentives should not be separately disclosed from the impact of non-U.S. statutory rates in the Income Tax Expense Reconciliation.Indicator variable equal to 1 if the firm reports a write-down during the year following the comment letter disclosure date, but 0 otherwise (Compustat: 1 if either wd p t+1 &lt; 0 or gdwlip t+1 &lt; 0, 0 otherwise). We note the disclosure of the tax holiday for your business operations in Switzerland. Please tell us how your disclosure complies with the requirements of SAB Topic 11-C. Please also tell us why the impact of the incentives should not be separately disclosed from the impact of non-U.S. statutory rates in the Income Tax Expense Reconciliation.</p>
        <p>Refer to Rule 4-08(h) of Regulation S-X. We urge all persons who are responsible for the accuracy and adequacy of the disclosure in the filing to be certain that the filing includes the information the Securities Exchange Act of 1934 and all applicable Exchange Act rules require. Since the company and its management are in possession of all facts relating to a company's disclosure, they are responsible for the accuracy and adequacy of the disclosures they have made.Refer to Rule 4-08(h) of Regulation S-X. We urge all persons who are responsible for the accuracy and adequacy of the disclosure in the filing to be certain that the filing includes the information the Securities Exchange Act of 1934 and all applicable Exchange Act rules require. Since the company and its management are in possession of all facts relating to a company's disclosure, they are responsible for the accuracy and adequacy of the disclosures they have made.</p>
        <p>In responding to our comments, please provide a written statement from the company acknowledging that:In responding to our comments, please provide a written statement from the company acknowledging that:</p>
        <p> the company is responsible for the adequacy and accuracy of the disclosure in the filing;  staff comments or changes to disclosure in response to staff comments do not foreclose the Commission from taking any action with respect to the filing; and the company is responsible for the adequacy and accuracy of the disclosure in the filing;  staff comments or changes to disclosure in response to staff comments do not foreclose the Commission from taking any action with respect to the filing; and</p>
        <p> the company may not assert staff comments as a defense in any proceeding initiated by the Commission or any person under the federal securities laws of the United States. the company may not assert staff comments as a defense in any proceeding initiated by the Commission or any person under the federal securities laws of the United States.</p>
    </text>
</tei>
