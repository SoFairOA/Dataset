<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
<teiHeader>
<fileDesc xml:id="_1"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:35+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text xml:lang="en">
<p>English is the dominant language in the study of human cognition and behavior: the individuals studied by cognitive scientists, as well as most of the scientists themselves, are frequently English speakers. However, English differs from other languages in ways that have consequences for the whole of the cognitive sciences, reaching far beyond the study of language itself. Here, we review an emerging body of evidence that highlights how the particular characteristics of English and the linguistic habits of English speakers bias the field by both warping research programs (e.g., overemphasizing features and mechanisms present in English over others) and overgeneralizing observations from English speakers' behaviors, brains, and cognition to our entire species. We propose mitigating strategies that could help avoid some of these pitfalls.</p>
<p>The past decade has brought an urgent reflection and reassessment of the generality and scope of the cognitive sciences. Rather than studying diverse human populations, most of the discipline has focused narrowly on individuals from societies that are Western, Educated, Industrialized, Rich and Democratic (WEIRD) [1]. This discussion has resulted in increased awareness of the importance of culture in the cognitive sciences, although studies of non-WEIRD populations and diversity within WEIRD societies remain rare [2,3]. Much less recognized as a potential barrier to progress in the cognitive sciences is the overwhelming dominance of the English language and its speakers.</p>
<p>Globally, one in six people speaks some variety of English with some proficiency [4], which makes it the most widely used language to have existed in the history of our species. Its dominance extends well beyond raw numbers of speakers. English has become the lingua franca in most spheres of international interactions, including science, and English-speaking countries are dominant global actors. The cognitive sciences are no exception. This state of affairs has resulted in a homogenous Anglocentric setup: English-speaking scientists explore the nature of the human mind by studying other English-speaking individuals in English-speaking countries (Box 1). In addition, while English itself is constituted of a number of distinct varieties around the world, including regional dialects, vernaculars, and Creoles, it is only a narrow set of these that participate in this near monopoly, most prominently Standard American English and British English [5].</p>
<p>English, however, is just one of the roughly 7000 languages spoken or signed in the world today [6]. Linguistic research has uncovered substantial diversity: languages vary in their forms, be they speech sounds or manual signs, as well as in their vocabularies, grammars, and usage rules. English is similar to a handful of the world's languages (often related through history) but very different from most others (Figure 1). Crucially, this diversity is relevant not only for the language sciences (e.g., [3,7]) but also for the broader study of cognitive science, as differences in language</p>
<p>The cognitive sciences have been dominated by English-speaking researchers studying other English speakers.</p>
<p>We review studies examining language and cognition, contrasting English to other languages, by focusing on differences in modality, form-meaning mappings, vocabulary, morphosyntax, and usage rules.</p>
<p>Critically, the language one speaks or signs can have downstream effects on ostensibly nonlinguistic cognitive domains, ranging from memory, to social cognition, perception, decision-making, and more.</p>
<p>The over-reliance on English in the cognitive sciences has led to an underestimation of the centrality of language to cognition at large.</p>
<p>To live up to its mission of understanding the representational and computational capacities of the human mind, cognitive science needs to broaden the linguistic diversity represented in its participants and researchers.</p>
<p>structures can have knock-on consequences for other, ostensibly nonlinguistic, aspects of cognition (Figure 2).</p>
<p>Here we integrate a diverse body of recent evidence to highlight the theoretical and practical limitations stemming from this Anglocentric bias. We do not presume to be exhaustive, but rather aim to showcase a range of phenomena where over-reliance on English has led cognitive scientists to premature claims of universality (due to the over-sampling of English speakers) or has limited the cognitive constructs being examined (due to the use of English as a metalanguage in scientific endeavors). We consider examples of English use in its broadest possible sense, including the specific nature of its representational format (spoken, written), as well as its vocabulary and grammar, and the interactional style of its users. For each, we illustrate how the default presumptions stemming from English are hampering progress in various areas of cognitive science which, although including the study of language itself, go far beyond it into the cognitive and neuroscientific study of perception, memory, reasoning, social cognition, and more.</p>
<p>English is predominantly a spoken language, unlike the 300 or so signed languages of the world (Box 2). Among spoken languages, English shares some features with many languages (e.g., it does not rely on tones to distinguish between words, as around 40% of all languages do) and other features with fewer (e.g., it allows complex sequences of three or more consonants before a vowel within syllables, something that less than one-third of languages permit). Such differences in the repertoires of speech sounds are reflected in the brain, as experience with specific speech sounds affects auditory sensory memory [9] and speech encoding [10]. Spoken language exposure impacts musical cognition as well [11,12]. English speakers, for example, are particularly sensitive to rhythm and mistuning of pitch, but less so to melodic discrimination; the opposite trend is found among speakers of tonal languages, like Mandarin Chinese [11].</p>
<p>Speech sounds and phonetic features sometimes elicit specific percepts and meanings across languages [13,14], as demonstrated by the well-known preference across languages for associating the labels bouba and kiki with round and spiky shapes, respectively [15]. However, the Box 1. The English monolingual bias Although English is a second language for many people around the world, making bilingualism and multilingualism common globally, in the USA, roughly 80% of the population speaks only English at home [141] and 80% never learn another language at school [142]. This monolingual dominance (which is accompanied by an often neglected monoscriptal dominance as well [143]) may explain cognitive science's early focus on monolingual (English) speakers. In the past, bilingualism was deemed to be costly and burdensome, and monolingualism was implicitly taken as the canonical cognitive state that needs explaining [144]. This is partly supported by studies reporting language switching costs when participants switch from one language to another [145], similar to the cost observed when participants switch between nonlinguistic tasks. However, most studies of language switching costs were not taking into consideration code-switching habits (i.e., bilinguals switching between languages in conversation). Recent studies of speakers who frequently code-switch find no costs of switching when language stimuli align with bilingual experience [146,147].</p>
<p>In fact, researchers nowadays seek to draw attention to the potential benefits of bilingualism. For example, several studies report a 'bilingual advantage' for cognitive control: the ability to plan, focus, and execute a wide array of tasks is better among bilinguals compared with monolinguals, in particular among older adult bilinguals [148]. Nonetheless, this bilingual advantage is not replicated consistently [149,150], as the effect is heavily modulated by task, age of participants, and bilingual experience, including how frequently a person switches between languages [151][152][153]. The relation between bilingualism and cognition, in general, is not restricted to cognitive control, as documented effects range from differences in decision-making [154], the evaluation of social rules [155], false-belief tasks [156], and changes in the brain [157,158]. The extent and nature of these effects are currently being explored in different multilingual settings, prevalent around the globe, that could deliver new insights into the adaptive capacities of the bilingual mind [159]. source of these associations remains unclear, despite the abundant supporting behavioral and linguistic evidence for such mappings [13,16]. For example, English speakers associate higher pitch sounds with higher altitudes, potentially reflecting an evolutionary adaptation to auditory scene statistics [17]. However, Farsi and Turkish speakers, who do not describe pitch using a high-low metaphor, do not show robust high-low space-pitch mappings in nonlinguistic tasks [18,19], suggesting language itself is an important arbiter of these associations (Figure 2).</p>
<p>Unlike roughly 40% of the world's languages, English has a developed writing system [4]. English is alphabetic but only partly phonetic: a set of letters represents both vowels and consonants. By contrast, the vast majority of readers worldwide learn non-alphabetic scripts, such as abjads (where only consonants are represented, e.g., Arabic), abugidas (where consonants and vowels are represented within a single graphic unit, e.g., Hindi), or morphosyllabaries (where units stand for morphemes or syllables, e.g., Chinese [20]). Despite this, English is massively over-represented in reading research, even in comparison with other European languages, and accounts for the vast majority of eye-tracking research [21], even though evidence points to tight associations between script type and reading-related cognitive processes [22].</p>
<p>English has been dubbed an 'outlier' with regard to its orthography, with rare features both quantitatively and qualitatively [23]. Unlike other alphabetic writing systems, English generally has an irregular letter-phoneme mapping, so it is more difficult to learn and results in higher rates of diagnosed dyslexia, other things being equal [23]. Phonological awarenessdeemed . Linguistic similarity between English and languages from the World Atlas of Language Structures (WALS). This figure illustrates the diversity and geographic distribution of languages across the globe. Linguistic similarity is the fraction of linguistic features shared by a language with English for four areas of linguistic description based on WALS [8]: (i) grammaticalized categories (WALS 'nominal categories' and 'verbal categories') pertain to the presence or absence of linguistic categories (e.g., grammatical gender, past tense, etc.); (ii) morphology (WALS 'morphology') involves how linguistic information is coded and packed within words; (iii) phonology (WALS 'phonology') accounts for the presence of different speech sounds and aspects of prosody; and (iv) syntax (WALS 'nominal syntax', 'verbal syntax', 'simple clauses', 'complex sentences', and 'word order') encompasses strategies languages use to assemble phrases and sentences out of smaller components. essential for learning to read (from an English perspective)is not required for other languages, where syllabic awareness is more important initially [20]. So models of reading derived from English, and their accompanying intervention recommendations, are hampering broader progress in the field [20].</p>
<p>Mastering the English writing system involves acquiring mirrored graphs (e.g., b vs. d, p vs. q), but most scripts do not require lateral mirror invariance. Tamil, for example, is expressed in an abugida script and has more complex written characters than English (e.g., அ, ண, ற), but these do not have mirror relations to each other [24]. Individuals exposed to an alphabetic system like English show a differential mirror cost in contrast to users of languages like Tamil [25]: when asked to determine whether two shapes are the same regardless of orientation, they take longer when shapes are mirror transformed (b vs. d) than when they are strictly the same (b vs. b) (Figure 2). The symmetries present in a writing system like English influence visuospatial abilities and offer a backdoor for language to influence ostensibly nonverbal measures of intelligence, like Raven's Progressive Matrices [26].</p>
<p>Finally, English is written from left-to-right, but Semitic languages like Arabic and Hebrew are written right-to-left and a handful of other written languages use both or a different cardinal axis (e.g., Mongolian is written top-to-bottom). Writing direction affects memory, learning, and attention [27]. Learning (nonlinguistic) sequences of visual stimuli is facilitated when presented in accordance with the written system people use [28]. Moreover, writing direction predicts reaction times when experimental participants are asked to determine if a given visual image is part of a recently observed sequence, as if individuals are going over the memorized sequence following the convention of their writing system [29]. Additionally, writing directions influence visual aesthetic preferences [30], including the preferred order in which agents and patients are linearly arranged: English speakers prefer events where the agent is on the left of the patient, Arabic speakers prefer events with the opposite arrangement [31,32], and illiterate speakers of Spanish and Yucatec Maya (Mexico) do not display any preference [31]. In fact, studies with nonliterate communities show no clear directional biases for number, time, or events [33,34], despite claims of an innate preference for a left-to-right mapping (e.g., [35,36]). These induced biases are not confined to the visual modality; in auditory tests, speakers of left-to-right systems conceptualize time as flowing in that direction too [37] (Figure 2).</p>
<p>English is a spoken language with an important written tradition and these characteristics have led researchers in the cognitive sciences to extensively study the characteristics of spoken and written modalities. In comparison, sign languages are inherently visual, relying primarily on manual signs in combination with facial expressions, head positions, and body postures. The study of sign languages has brought unique insights into our understanding of language processing, as well as revealing substantive connections between language and cognition [160]. For example, signers display reduced working memory span compared with speakers (5 ± 2 instead of the classic 7 ± 2), which has led to insights regarding the neural underpinnings of short-term memory [161]. In contrast, signers display enhanced performance in an array of visuospatial tasks, including perspective-taking and mental rotation [162,163], face recognition [164], and processing of memory traces of arbitrary stimulus-response pairs involving the hands [163].</p>
<p>In parallel with the growth of sign language studies, there is an increased interest in the visual aspects of spoken languages in face-to-face communication. A large body of work demonstrates that co-speech gestures facilitate language processing [165], in particular, lexical retrieval among those who have weak short-term memory [166] and learning of nonlinguistic concepts (e.g., in mathematics [167]). It has been suggested this multimodal enhancement resembles low-level multisensory facilitation (e.g., participants identify a sheep faster in a picture when they also hear 'baa') found in non-human species, as well as humans [165].</p>
<p>The impact of multimodality in communication is likewise little understood from a crosslinguistic and crosscultural perspective. There are differences in how people point and what emblematic gestures exist within a society (e.g., forming a circle with the index finger and thumb means 'okay' in English-speaking communities, but indicates a bodily orifice in Greece). Representational gestures for space (literal and metaphorical) differ, as do the gestures accompanying the varying lexical and syntactic resources across languages. Finally, there are culture-specific gestural pragmatics (i.e., when, what, and how people gesture in different contexts; see [168] for review). For example, speakers in some languages do not look directly at each other during verbal interactions [108]. Speech and gesture are tightly coupled, but distinct. So understanding cultural variation in this arena is important to understand the nature and emergence of human communication.</p>
<p>Word meanings vary as widely as word forms across languages [38]. Whether it be sensory qualities, entities, or relations, English reflects only one way of partitioning meaning (Box 3). Consider how language maps onto sensory qualities. It has been widely assumed that language reflects a biological hierarchy of the senses with the visual modality dominating, followed by auditory, tactile, gustatory, and olfactory senses. But crosslinguistic investigation shows this sensory hierarchy is not pan-human: in one study of 20 diverse languages tested on the codability (i.e., naming agreement) of the perceptual senses, there were 13 different rank orders of the senses, with only English matching the predicted hierarchy better than chance [39]. Where English makes few distinctions (e.g., olfaction), other languages encode myriads [40] (Figure 2). This has wide-ranging implications as people's sensory experiences align with linguistic encoding [41], even determining the likelihood of an entity appearing in conscious awareness [42]. It also raises questions about the validity of using English speaker judgments in tasks purporting to tap into visual semantics (e.g., [43,44]) or visual complexity [45], since what is expressible in English may not be in other languages [39]. Speakers of different languages are 'not equivalent as observers' (as famously noted by Whorf [46]).</p>
<p>These biases seem to take hold early in life: for instance, shape has been postulated to be a critical semantic dimension readily available to all humans starting from as early as 2 years of age [47]. However, during language learning, both vocabulary and language structure influence attention to shape, such that the well-established English 'shape-bias' may not arise in other languages, such as Tsimane (Bolivia) [48]. Crucially, these differences between English and other languages cannot simply be reduced to passive exposure to different shape statistics, as supported by the fact that English children with hearing loss display a reduced shape bias compared with their hearing counterparts, even after controlling for vocabulary size [49].</p>
<p>While people can certainly entertain meanings not lexicalized in their language, in a handful of domains the absence of words for specific meanings has been shown to result in vague, if any, representation outside of language. For instance, English has a generative vocabulary for large Box 3. English as a meta-language for the cognitive sciences</p>
<p>The widespread assumption that language reflects rather than creates categories means that cognitive scientists often do not interrogate their theoretical constructs for broader applicability, even when they should [169][170][171]. Over-reliance on English labels means researchers can end up overlooking important dimensions of variation in how humans conceptualize the world. Theoretical notions such as 'mind' [172], 'knowledge' [173], 'musical ability' [174], or 'anger' [170,171] have been shown to vary across populations, showing the meta-linguistic labels used in scientific theorizing need to be adjusted so they do not presume a default English interpretation.</p>
<p>A corollary of this is that English-language researchers are not obliged to add qualifiers to the titles or abstracts of papers indicating their findings apply only to English, but the same standard is not applied to researchers of other languages who are told to demarcate their findings as applicable only to a specific language and context. There is an implicit assumption that findings from English are generalizable to all humans, but studies from other languages are not. This should be a matter of critical reflection for cognitive scientists. For example, research in the neuroscience of reading has proposed a universal functional architecture, but relies on alphabetic terminology (e.g., letters, graphemes) to label anatomical brain structures (e.g., letter detectors, letterbox area) (see critical discussion in [20]), even though, as outlined in the main text, alphabetic scripts are not universal. Similarly, the Visual Word Form Area (left ventral occipitotemporal cortex) is said not to be sensitive to case (e.g., b vs. B) [175], but in languages like German, where the initial letter of a noun is always capitalized, upper versus lower case is registered in this area [176].</p>
<p>The moral is not that cognitive scientists should abandon universal theorizing. Rather, universal theorizing requires adequately sampled (i.e., diverse) data and better appreciation of issues of comparability (cf. [177]), and the most powerful theories ought to predict and explain variation [178], not sweep variation under the rug. Until then, perhaps cognitive scientists should be required to use an 'in English' qualifier to keep their theorizing in check to the data they have to hand. cardinal numbers, whereas speakers of some other languages do not. It has been shown that speakers can successfully complete simple numerical matching tasks as long as they know the word for the numerosities being evaluated, which supports the proposal that there is a causal connection between knowing a word and being able to deploy the representation in a nonlinguistic task (e.g., [50][51][52], see also [53]; Figure 2).</p>
<p>In fact, words (or symbolic labels) and nameability (the ease with which a feature can be named) have been linked to category learning, problem-solving, and reasoning [54,55]. It is important, then, to note that of the multifarious semantic distinctions coded in the world's languages, English encodes only a subset. In English, the manner in which an action is performed is salient: amble, jump, limp (manners of walking), whisper, lisp, hoot (speaking), gobble, quaff, imbibe (ingesting), etc. [56]. In other languages, path information is as salient. In Maniq (Thailand), for example, monomorphemic verbs of moving, digging, and looking all specify the spatial paths of up, down, and across (e.g., balay 'to look up', y p 'to look down', ciyɛ k 'to look sideways') [57]. Gender is encoded in pronouns (e.g., he, she) and kinship relations (e.g., brother, sister) in English. In many other languages, however, all nouns (including inanimate ones) are categorized by grammatical gender [58], whereas languages like Turkish, Finnish, and Indonesian are categorized as 'genderless'; even their pronouns are gender neutral [59]. In Indonesian, a salient semantic feature, missing in English pronouns and kinship terms, is the social relation between participants (e.g., siblings are categorized for whether they are older or younger). These differences in encoding can affect memory: the English hypersensitivity to manner in events may make this semantic dimension more memorable for its speakers, at least in certain circumstances [60,61], and gender more memorable than seniority when considering sibling relations [62]. More generally, attentional preferences in vocabulary (and grammar) triggered by what and how events and referents are described may percolate into the representation of complex concepts such as economic risk and social hierarchy (Box 4). Box 4. The potential impact of language on societies and economics Languages differ in their obligatory grammatical distinctions that compel speakers to attend to certain features of the world. Could this fact influence people's thoughts and decisions in real situations, where costs and benefits matter, and account for societal-level differences in the steepness of social hierarchies, savings rates, or gender inequality? A growing literature in economics and political science has emerged that seeks to explain differences in societal outcomes based on crosslinguistic differences in the grammatical marking of different types of information.</p>
<p>Three areas have been explored in some detail: the potential role of grammatical gender (masculine vs. feminine) in shaping gender attitudes and equality [179][180][181], grammatical tense impacting decisions about the future related to savings, retirement, and the environment [182][183][184], and obligatory politeness distinctions encouraging hierarchy and authority [185,186]. In all cases, studies find associations between grammatical encoding and societal-level behavioral variables. For example, researchers found female immigrants in the USA who speak a gendered language exhibit lower labor force participation [180]. Comparing individuals within countries, speakers of languages without obligatory future tense save more, smoke less, practice safer sex, and are less obese, relative to demographically similar individuals who speak languages with an obligatory future tense [182]. Finally, periphrastic future tense is linked to a psychological measure of long-term orientation, gender in grammar is linked to attitudes favoring female inequality, and politeness distinctions to social hierarchy [186].</p>
<p>Taken at face value, these findings suggest, ceteris paribus, English shapes individuals into being relatively less sexbiased, more prone to horizontal social systems (because of the limited role of gender and politeness in grammar), and more inclined to discount the future (due to the marking of future tense). While potentially important for the study of cognition, these associations deserve critical scrutiny. Languages are not independent, but historically related, so some of these patterns might be due to nonlinguistic aspects of culture (see, e.g., [183,187]). Language is entwined with, and transmitted alongside, other aspects of culture, including norms, institutions, religious practices, etc. (e.g., [188]), which means distinguishing the effect of language from the rest of culture is challenging (Box 5). Finally, the correlational evidence underspecifies the actual mechanisms linking linguistic structures with human behavior, and experimental evidence currently suggests a more complex picture (e.g., [189]).</p>
<p>More broadly, crosslinguistic lexical-semantic diversity has ramifications for neuroscientific theories of conceptual knowledge. A comparison of (British) English and British Sign Language found notable differences in how basic level categories (e.g., lion, train) were represented in the brains of spoken and sign language users, although there were broad similarities across groups in how superordinate categories (e.g., animals, artifacts) were represented [63]. It seems conceptual representations are affected by phonological properties of words (according to whether a language is in the visual vs. auditory modality) in ways not predicted by categorization theories [63,64].</p>
<p>In fact, many contemporary theories claim sensory and motor features of concrete word meanings (e.g., object nouns and action verbs) are grounded in neural systems for perception and action [65][66][67][68][69]. The core hypothesis holds these semantic features are meaningful because they reuse, and so are identical to, the same high-level modality-specific representations that categorize entities and events for nonlinguistic purposes, such as visual perception and action planning. If this is the case, the neural systems for perception and action not only ground the sensory and motor features of word meanings, but do so in ways that are language-specific [70,71]. That is, the sensory and motor features of language-specific word meanings will be engaged within modality-specific neural systems, even when entities and events are processed for nonlinguistic purposes. After all, according to the hypothesis, if these semantic features did not also contribute to perception and action, they would not be truly grounded. If, however, they do satisfy these criteria for being grounded, the unavoidable consequence is that nonlinguistic tasks must be influenced by language-specific word meanings. So far, little neuroscientific research has tested this prediction directly. However, some supporting evidence comes from a recent study that found object naming in English and Mandarin Chinese is associated with different language-specific activation patterns in part of the left-hemisphere visual system that represents the shapes of objects [72].</p>
<p>Ultimately, any difference in the units of representation (e.g., words) has implications for the computations that support cognition too. An illustrative example is relational reasoning (Figure 2). To encode the spatial relations between objects in small arrays, English uses a relative, viewpoint-dependent frame of reference, with terms like left and right, whereas for the same type of array, many unrelated languages of the world (e.g., Guugu Yimithirr spoken in Australia and Hai//om in Namibia) use an absolute frame of reference, involving a cardinal-direction type system (e.g., north, south, etc.) [73]. Differences in linguistic encoding have been shown to influence a range of nonlinguistic behaviors, including the ability to learn the spatial configuration of objects [74], search and find a hidden object [75], track the movements of an object [73,76], or learn and perform dance routines [77]. Importantly, even when the same input-output states are observed, the underlying computations required to instantiate these are different depending on the frame of reference employed. So, when speakers of a relative frame of reference point to a geographically correct location in response to a query for directions, analysis of the timing and content of gestures suggest they are computing the final destination step-by-step from a viewpoint-dependent memory, which takes longer than reading directly off an absolute memory trace [73]. Since theories of cognition must specify both the units of representation and their associated computations, assuming English-specific categories means the concomitant computational architecture must also be questioned for its generalizability.</p>
<p>English has a relatively rigid word order: within phrases, the relative sequence of word types tends to be the same. As shown by the contrasting meanings of The dog chased the cat and The cat chased the dog, word order indicates who does what to whom. Other languages use different devices for this purpose, marking such information on nouns (e.g., case-marking in Korean or Hungarian) or verbs (e.g., Guarani, Zulu), so word order becomes more flexible and is available for conveying other types of information. These differences are reflected in the neural signatures of syntactic processing [78], including differences in brain lateralization found across speakers of the world's languages [79] with potentially broader significance for brain organization beyond the localization of language-specific neural circuits, since lateralization of language has been causally linked to lateralization of other functional brain asymmetries [80]. Unfortunately, comparative studies are few and far between and the lion's share of research remains focused on English [79]. This variation in how the human brain processes, stores, and represents grammars with word orders different from English has implications for current research in intelligence. Consider Language Models (i.e., deep neural networks trained on gigantic corpora that approximate the probability distributions of word sequences in a target language). Language Models have been hailed as a 'biologically feasible computational framework for studying the neural basis of language' [81] and are center stage in contemporary discussions of machine and human intelligence because they can be leveraged for a large number of verbally expressed cognitive tasks, from quantitative reasoning to moral judgment. Many influential Language Models sourced in English were trained on the next-word prediction task (i.e., predicting the individual word that follows in a word sequence, e.g., 'The girl went to the park to fly a […]'). It has been claimed that Language Models that are efficient in solving this task are also better at predicting human behavior (e.g., reading times [82]) and, vice versa, those with the most brain-like representations perform the best at this task [83], all of which reinforces the idea that the similarities between Language Models and humans might be rooted in processes and representations shared by both. Crucially, crosslinguistic evidence suggests speakers of languages like English, and, in particular, literate speakers [84], might engage in comparatively more prediction than speakers of other languages. This is because word order cues and forward prediction might be less important for speakers of languages that rely on other types of information when processing sentences [85,86] and is reflected in the fact that language modeling in these types of languages is also poorer than in English [87]. In addition, better predictive performance of Language Models might not be associated with their ability to capture human psychometric measures in other languages [88]. While this does not preclude the possibility that Language Models trained on different tasks could yield fruitful and crosslinguistically robust insights into the human mind and brain (e.g., [89]), the next-word prediction task might not be an adequate language-independent foundation for synthetic models of human cognition. Similar conclusions could be derived from other analogies being made in the field between language technologies and human cognition more broadly; they also remain both conceptually and practically focused on English and a handful of other languages [203,204].</p>
<p>The grammar of English also generates specific expectations about how information is ordered in sequences. Psychologists have long observed that subjects tend to have better recall for the last elements of a list in free recall tasks [90]. This 'recency effect' is explained by cognitive models assumed to be universal. However, language modulates this effect to the point that a 'primacy effect' (earlier elements are recalled with more precision) is observed instead [91]. The critical linguistic dimension underlying this variation is the internal structure of phrases. Across languages, phrases are structured around a special word ('head') that determines many properties of the phrase, so keeping track of the heads of phrases during language processing is fundamental for building sentences. In English, heads tend to be found at the beginning of phrases, whereas in other languages (e.g., Japanese), heads occur at the end. Thus, an English speaker can more rapidly infer the structure of a sentence in the moment, whereas speakers of Japanese potentially have to keep track of more information until they encounter a head word later in a phrase. These differences affect the accuracy of working memory when recalling sequences of figures depicting numbers, spatial arrangements, and animals [91]. In alignment with what would be expected from the different processing strategies, speakers of English recall with more precision the last rather than first element in a sequence, whereas speakers of languages like Japanese display the opposite pattern [91] (Figure 2).</p>
<p>The ordering of elements aside, languages construe similar messages by highlighting and marking different pieces of information in varied ways. When it comes to describing and individuating events, this can affect how a dynamic sequence is chunked and represented (see, e.g., [92]). For example, in English, a causal situation is more often judged to be a single event when it is described with a simple clause (e.g., The man moved the blue marble) than a complex clause (e.g., The man made the blue marble move) [93]. Similarly, in Avatime (Ghana), serial verb constructions, where multiple verbs describing smaller action units are packaged together in a single clause (e.g., I take throw put give old-man, 'I threw it to the old man'), allow for complex sequences to be conceptualized as one event, rather than multiple events as happens when the verbs appear in other types of clauses [94]. Similar crosslinguistic differences in event segmentation are seen for motion events. As noted earlier, languages differ in what information (manner or path) is packaged into verbs and this has knock-on effects on the expression of complex events. Manner verbs (as found in English or German) can combine with different path segments to form a single clause (e.g., The man ran from the kitchen up the stairs to his bedroom), but languages with path verbs (e.g., French) need to have separate expressions for each new trajectory, leading French speakers to have fine-grained event segmentation in nonlinguistic cognition [95].</p>
<p>Differences in event encoding extend to cause and effect dynamics, opening the door for a linguistic influence on causal cognition [96] (Figure 2). In caused motion events, two subevents are distinguished: the Means (i.e., the causal trigger for movement, e.g., a girl kicking a ball in a football match) and the Result (i.e., the movement of the ball across the field into the goal). In English, it is possible to describe both subevents within a single clause (e.g., 'the player kicked the ball into the goal') [97]. However, in languages like Greek, this is less straightforward, so speakers choose either a less informative verb that underspecifies the Means ('the player sent the ball into the goal') or concatenate two clauses ('the player kicked the ball and it went to the goal') [97]. A consequence is that English speakers describe Means more frequently than Greek speakers overall. When speakers are asked to describe or just silently look at a picture depicting a caused motion event, within the first 500 ms, English speakers focus their gaze more on Means than do speakers of Greek [97], suggesting linguistic encoding possibilities bias the allocation of visual attention.</p>
<p>Going beyond how information is bound together within sentences, languages have at their disposal a host of different strategies to construct complex messages. Languages like English use complement clauses, for instance, when communicating that someone holds an opinion, feeling, or emotion ('Aaliyah believed that they wanted to offer her a raise', 'My son thought that our family moved here in the early 19th century'). Mastery of this grammatical resource over development is linked to better performance in false-belief tasks : the canonical measure of Theory of Mind (ToM) (Figure 2). While the exact nature of this association remains a matter of debate, evidence from emerging sign languages [98] and experimental tests with training in complement clause comprehension [99] show language structure at the very least bolsters ToM. This raises the question of whether measuring ToM through false-belief tasks could be biased against individuals who speak languages that do not (frequently) use clausal embedding. In addition, there are linguistic traits not coded in English but coded in other languages, which may explain differences in the responses to false-belief tasks between English-versus Turkish-and Spanish-speaking children, other things being equal [100]. One such trait is the presence of negatively biased mental verbs (i.e., verbs that presuppose the falsity of their complement), such as the word yiwei (translated as 'falsely believes') in Mandarin Chinese [101]. All in all, this calls for finding common linguistic ground from which to understand and measure the potential linguistic roots of ToM, ideally tapping into linguistic resources with broad crosslinguistic attestation [102,103].</p>
<p>Cognitive scientists regularly prioritize the referential properties of language while ignoring its many other functions. Critically, language goes beyond just referring to things in the world: it expresses an individual's feelings and emotions, influences others, establishes social relations between people, and more. A narrow focus on English in the cognitive sciences, then, may constrain us in our broader understanding of human social cognition and social interaction. This section is by necessity briefer, as the social and cognitive consequences of crosscultural diversity in this arena are not as well explored [104,105] (see Outstanding questions).</p>
<p>Using a language involves knowledge of how and when to deploy linguistic utterances in the context of social interactions. Philosopher Paul Grice suggested a handful of simple rules that apply 'to conversation as such, regardless of its subject matter' [106]. The Gricean individual is a rational agent who is expected to quickly provide just enough information, not more, nor less, than necessary and relevant in any given communicative situation. When such an individual flouts one of these principles, their interlocutors will infer the intended meaning of an utterance is different from its literal meaning. The Gricean rules of conversation have served as the basis of a number of successful models of pragmatic reasoning [107].</p>
<p>However, speakers of languages other than English have been observed to adhere to different conversational norms: speech communities in both Africa [108] and East Asia [109] seemingly flip (at least some of) the Gricean expectations, as regular conversations typically involve ambiguous, indirect, and opaque utterances (Figure 2). Whether ambiguity or communicative efficiency (a la Grice) should be at center stage in our models of human interaction and pragmatic reasoning, therefore, seems to be at least partially mediated by language and its roots in culture (Box 5), which is reinforced by the observation of variation even within European languages [202] (see Outstanding questions). The very specific rules of English conversation have become reified as cognitive structures in the process of building social robots. It has been claimed that 'programming Box 5. The relationship between language, culture, and cognition English speakers display cognitive characteristics that align with properties of the English language and, as we have discussed in the main text, these traits are not necessarily universal. However, we have yet to unpack the exact relationship between language, cognition, and culture. Is it language that shapes cognition or cognition that shapes language? Or does culture shape both? These questions are the basis of ongoing debate and contention in the field.</p>
<p>Sometimes language is taken as a proxy for culture [130] and other times as a proxy for thought [190], making it challenging to ask how each affects the other. If we do distinguish the three, however, we still see a range of positions. On one account, language is a direct reflection of culture: 'there resides in every language a characteristic worldview', as Wilhem von Humboldt famously asserted [191]. Contemporary proponents claim language is the outcome of diverse communicative needs across societies (e.g., [192,193]) or a barometer of cultural change within society (e.g., [194][195][196]). According to this view, then, culture is the driving force behind variable language and cognition, leaving open whether the effect of culture on cognition is direct or, instead, mediated through language [197][198][199].</p>
<p>However, the correspondence between language and culture is not exact: in today's globalized world, the same language can be spoken across distinct cultural groups and a single culture may have speakers of multiple language varieties. This is illustrated with English itself, which is the dominant or official language in every continent and over 75 countries and territories, each with distinct political and cultural histories [200]. This could be considered an ideal natural experiment for separating the effects of (English) language and (variable) culture. However, linguists recognize a number of English varieties, World Englishes, identifiable by their distinctive phonology, lexicon, and grammar [200], opening again the possibility that language and culture are, for most practical means, inseparable. Indeed, the linguist Anna Wierzbicka has argued there is a core 'Anglo English' with its own cultural and historical reality [171,201].</p>
<p>Ultimately, to tease apart the contributions of language and culture on cognition requires careful and precise elucidation of each, at a fine grain of resolution (i.e., specifically which aspect of language, e.g., phonology, vocabulary, grammar, discourse, is related to which aspect of culture and cognition).</p>
<p>AI and other social robots to communicate in ways that are consistent with Grice's maxims would be advantageous, most of the time' [110]. Social robots, in order to fit different cultural contexts, need to adhere to language-specific rules beyond presumed general principles of conversation (e.g., [111,112,202]). Furthermore, communicative efficiency considerations, such as those derived from the Gricean model, can be trumped by language-specific practices rooted in culture. For instance, in a conversation, when someone has the floor, a listener of English will signal they are attentive by using 'backchannels', such as mm-hm, uh-huh, and yeah. The relatively high frequency of backchannels in conversation may explain why they display similarly economical forms across different languages [113]. However, listeners of Ruruuli/Lunyala (a Bantu language spoken in Uganda) repeat whole words said by the speaker, going well beyond the minimal mm-hmm in many contexts where the more economical form would be expected ( [114]; see also [115]). Speakers from another part of the world, Mesoamerica (e.g., Tzeltal, Yucatec, Zapotec), also use repetition as backchannels. In addition, repetition serves other purposes. For example, in response to yes-no questions, there may be use of repetition instead of a simple yes or no (e.g., A asks 'So the old man died?', B answers 'He died', followed by another repeat from A: 'He died.'). From the vantage point of English conversational conventions, this may seem redundant and inefficient, and in some other conversational contexts repeating what another person has said in English can be considered competitive because it suggests equal authority over the matter at hand. In these Mesomerican languages, however, repetition in the same sorts of situations is affiliative, leading to the claim that there is less territoriality about knowledge and experience in these communities, all other things being equal [116]. These interactional practices are critical for the establishment, maintenance, and conceptualization of social relations, and prosocial verbal cues play a central role [117]. One such cue is the expression of gratitude, which in English takes the form of 'thank you' and its variants. Young English-speaking children are socialized into saying 'thank you' early in life [118], and social psychologists have claimed expressing gratitude has a range of benefits, from creating better first impressions [119] to increasing satisfaction in romantic relationships [120], suggesting that complying to the expected frequency and context of this behavior is crucial for sustaining social connections. However, a study of everyday informal interaction in a range of languages found saying 'thank you' is not common in day-to-day communication when people are cooperating. Strikingly, English speakers were almost four times more likely to say 'thank you' than speakers of other languages, whereas Cha'palaa speakers (living in Ecuador) do not even have a conventional way to express 'thank you' in the first place [118]. In fact, in Cha'palaa one does not request things indirectly, as in English (e.g., Could I have some water, please?), instead Cha'palaa speakers use imperatives (Give me water) without the liberal sprinkles of 'thank you' and 'please' that follow in English and this is not considered rude or conflictual within the language community [105,121] (Figure 2). In contrast, other languages appear to require more frequent affiliative verbal cues than English. Returning to backchanneling, Japanese listeners produce these more frequently than English speakers, with the concomitant suggestion that Japanese speakers are monitoring each other's social behavior more closely [122].</p>
<p>Finally, the sheer amount of verbal interaction varies across languages and populations. This wide variation in input is critical for the construction of developmental models. Given large variance in input across languages, the more predictable and regular the cognitive and behavioral outcomes, the stronger the cognitive inductive priors on learning need to be [123]. Comparatively speaking, English speakers participate in highly frequent (directed) linguistic interactions, in particular in relation to children. Such increased verbal input and participation in conversational turn-taking have not only been linked to more successful language development but also enhanced cognitive abilities in English-speaking children from higher-income homes [124]. Known as the '30-million-word gap', its deficit orientation has been challenged by crosscultural language acquisition studies. For example, children in multigenerational, subsistence-farming households from Mexico, Papua New Guinea, and South Africa receive substantially less directed speech than the normative amounts reported in WEIRD samples, without indication of a lag in development [125,126].</p>
<p>Evidence from across the cognitive sciences reveals that a narrow focus on English compromises the scope and validity of the cognitive science enterprise. We have highlighted a handful of properties of English to demonstrate the potential limitations of current research in the field, while simultaneously highlighting how the study of worldwide linguistic diversity offers a vast array of phenomena with untapped potential for the broader study of the mind. Much remains to be explored concerning the dimensions on which languages differ, as about 40% of the current 7000 or so languages have yet to be described [4,7,127]. In the study of language and cognition, some linguistic phenomena (such as the coding of motion events and grammatical gender) have received a considerable amount of attention, whereas there has been no or very limited research on most other dimensions of linguistic variation. We do not predict nor expect all aspects of linguistic diversity will have important nonlinguistic effects, but we cannot determine which aspects are of relevance without the critical crosslinguistic studies. Recent bibliographic assessments (e.g., [2,3]) find the exploration of diversity in language and cognition remains a low priority in the field, despite repeated calls for change. Our paper aims to highlight the possibilities that a linguistically inclusive cognitive science has to offer.</p>
<p>The fact that linguistic diversity is not better represented in the agenda of the cognitive sciences reflects its failure to live up to its original mission of developing an interdisciplinary exploration of 'the mind' [128,129]; it may be its 'original sin' [130]. Cognitive psychology has become nearly synonymous with cognitive science, but the comparative study of human societies and languages remains shockingly absent or fringe in the discipline's publications, coursework, and faculty backgrounds [128]. It is hard to envision a radical change in the field if institutions (universities, journals, funding bodies) do not commit to research that seeks to systematically explore, generalize, and falsify our models of human cognition by exploring non-English-speaking peoples and societies.</p>
<p>While institutional change is slow, there are some mitigating strategies scholars can embrace to move research away from an English-blinkered cognitive science. First, there is a growing number of open databases with information about linguistic diversity, including, for example, lists of vocabularies (Lexibank, [131]) and grammatical structures (WALS, [8]), as well as their cultural and ecological correlates (D-PLACE, [132]) that can be consulted to ground claims of universality and diversity. While not necessarily unbiased representations of the cultural and linguistic diversity around the world [133,134], they are nevertheless valuable resources that cover swathes of human societies that research in psychology and cognitive science typically does not [2]. Second, crowdsourcing marketplaces (e.g., MTurk, Prolific) increasingly allow for the possibility of engaging speakers of languages other than English. All official languages of the United Nations (Arabic, Chinese, English, French, Russian, and Spanish) also feature in the top ten languages used on the internet as of 2020 (https://internetworldstats.com/stats7.htm). While almost 1.2 billion internet users are speakers of English, this is followed closely by Chinese (0.9 billion), Spanish (0.4 billion), and Arabic (0.2 billion) speakers, languages that all have a higher rate of growth on the internet today than English. This makes it even more perplexing that the cognitive sciences fail to engage What additional strategies can researchers utilize, aside from those sketched here, to move beyond English as the meta-language of science? What are the long-term consequences of the accelerated growth of large languages like English and the loss of linguistic diversity for our models of human cognition? What are the consequences of the 'Anglo English' bias for our understanding of human populations in the past and into the future? these language communities. Third, crosscultural field studies can provide critical data about lesser-studied languages and societies and allow researchers to sample more strategically for diversity of experience [135,136]. Finally, establishing scientific ties between institutions and individuals within the Anglosphere to those outside it could mitigate unrecognized biases [137], but here it is critical to foster equitable collaborations with fair authorship practices [138].</p>
<p>It is a truism that the human condition is inherently diverse and our species hosts a multitude of languages [139]. Here we have provided evidence of why this diversity is substantive and with far-reaching consequences for models of human cognition, which have relied too closely on English-speaking individuals. It is due time for linguistic diversity to be integrated into cognitive science to live up to its mission of understanding the representational and computational capacities of the human mind [140].</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12 1155</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12 1157</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12 1159</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12 1161</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12 1163</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12 1167</p>
<p>Trends in Cognitive Sciences, December 2022, Vol. 26, No. 12</p>
<p>The authors thank Felix Ameka, H. Clark Barrett, Vera Kempe, Gary Lupyan, Tanya Nikitina, Cole Robertson, Arturs Semenuks, Mariya Toneva, Jyotsna Vaid, Qi Wang, and three anonymous reviewers for comments on an earlier version of this paper, and Mona Xue for her assistance on formatting the first draft. D.E.B. acknowledges funding from Harvard's Data Science Initiative and the Branco Weiss Fellowship. E.A. acknowledges funding from the French National Research Agency (ANR-10-LABX-0083). A.M. was supported in part by the Radcliffe Institute for Advanced Study at Harvard University.</p>
<p>No interests are declared.</p>
</text>
</tei>