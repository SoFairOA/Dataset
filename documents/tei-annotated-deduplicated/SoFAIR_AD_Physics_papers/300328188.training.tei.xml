<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
<teiHeader>
<fileDesc xml:id="_1"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:35+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text xml:lang="en">
<p>Scanning probe microscopy (SPM) has revolutionized the fields of materials, nano-science, chemistry, and biology, by enabling mapping of surface properties and surface manipulation with atomic precision. However, these achievements require constant human supervision; fully automated SPM has not been accomplished yet. Here we demonstrate an artificial intelligence framework based on machine learning for autonomous SPM operation (<rs xml:id="12972073" type="software">DeepSPM</rs>). <rs xml:id="12972074" type="software">DeepSPM</rs> includes an algorithmic search of good sample regions, a convolutional neural network to assess the quality of acquired images, and a deep reinforcement learning agent to reliably condition the state of the probe. <rs xml:id="12972075" type="software">DeepSPM</rs> is able to acquire and classify data continuously in multi-day scanning tunneling microscopy experiments, managing the probe quality in response to varying experimental conditions. Our approach paves the way for advanced methods hardly feasible by human operation (e.g., large dataset acquisition and SPM-based nanolithography). <rs xml:id="12972076" type="software">DeepSPM</rs> can be generalized to most SPM techniques, with the source code publicly available.</p>
<p>canning probe microscopy (SPM) 1 consists of scanning an atomically sharp probe in close proximity (typically ≈1 nm) above a surface, while measuring a physical quantity [e.g., quantum tunneling current in scanning tunneling microscopy (STM) 2 and force in atomic force microscopy (AFM) 3 ] as a function of probe position. This allows for the construction of an image of the scanned surface. This method can be employed in a variety of environments, from ambient conditions to ultra-high vacuum at cryogenic temperatures, allowing for measurements on a wide range of samples 2,4 . Its unique capability to probe realspace physical properties (structural, electronic 5 and chemical 6 ) with atomic resolution and to manipulate adsorbates on a surface with atomic-scale precision 7 makes it highly relevant for chemistry 3 and biology 4 , and perhaps the most powerful characterization tool for materials, surface, and nano-science 1,2,8 .</p>
<p>The yield of SPM data acquisition-the fraction of good data usable for scientific analysis-is rarely reported and are generally low. There are two main factors limiting this yield: (i) the atomicscale morphology of the probe can result in imaging artefacts and (ii) the state of the sample imaging regions (e.g., scanning excessively rough or contaminated regions rarely produces usable data and can result in damaging the probe). Both factors vary during the course of an experiment and need to be addressed.</p>
<p>In state-of-the-art SPM, a human operator selects sample regions to scan and assesses the acquired images (good or bad quality). This assessment is based on the operator's experience. If she deems the image bad due to the state of the sample region or the probe, she changes the region or attempts to condition the probe. The de-facto procedure for the latter relies on trial-anderror. Conditioning actions (e.g., dipping the probe into the sample and applying a voltage pulse between probe and sample 9 ) are performed until the probe morphology and image quality are restored. The probe atomic-scale structure dramatically influences image quality and outcomes of conditioning actions are uncertain; success depends on the microscopist's experience and the time invested.</p>
<p>Previous studies have aimed to improve imaging efficiency, e.g., by linking probe morphology and image quality, via analytical simulations 10 , inverse imaging of the probe through sample features [11][12][13] , or probe characterization/manipulation (field ion microscopy 14 ). These approaches can suppress the need for heuristic probe conditioning. However, they are difficult to implement for general use, in particular for large dataset acquisition.</p>
<p>Another avenue for minimizing the need of human operation is SPM automation 15 . Examples include scripted SPM operation 16 to automatic imaging region selection 17 . A recent publication 18 presents an AFM system capable of autonomous sample region selection and measurement. However, these methods are limited to specific applications in stable measurement conditions and do not manage probe quality under general operation.</p>
<p>The latter can be addressed via machine learning (ML), which allows for predictions, assessments, and decision-making in systems that are not fully understood, or too complex to be characterized analytically. Rather than following a well-established set of rules, ML methods derive decision strategies from training data. In image processing (e.g., object recognition 19 and image segmentation 20 ), ML approaches routinely outperform humans. These accomplishments are often based on convolutional neural networks (CNNs) 19,21 . Such CNNs use image or image-like data as input to perform classification and regression tasks (e.g., object recognition and image quality optimization). A CNN is controlled by millions of parameters that can be tuned via supervised learning. In this process, the network is trained using large sets of input data (e.g., images) to which a label is associated. This label corresponds to the desired output of the CNN (e.g., for object recognition and the name of the object in the image). Once the CNN is trained, it can label new unseen data.</p>
<p>Supervised learning has been applied to SPM in a recent study 22 where ML assists a human operator in detecting and repairing a specific type of probe defect in the particular case of hydrogen-terminated silicon. In this work, a trained CNN assessed the quality of acquired SPM images; if necessary, a wellestablished probe-conditioning protocol was executed 23 . In another recent study 24 , ML was successfully used to determine imaging quality directly from a small number of acquired scan lines, without requiring complete images. However, fully autonomous operation for more general cases, where probe defects are varied and conditioning protocols are not well-defined, has not been demonstrated yet.</p>
<p>In ML applications where pre-labeled training data are not available, a CNN can still learn through trial-and-error, by receiving positive and negative feedback (rewards). This approach is known as (deep) reinforcement learning (RL) 25 . Such RL agents can learn to navigate complex environments 26 (e.g., they excel in sophisticated games 27,28 ).</p>
<p>Here we present
<rs xml:id="12972077" type="software">DeepSPM</rs>, an autonomous system capable of continuous SPM data acquisition. It consists of the following: (i) algorithmic solutions to select good imaging sample regions and perform measurements; (ii) a classifier CNN trained through supervised learning that assesses the state of the probe; and (iii) a deep RL agent that repairs the probe by choosing adequate conditioning actions.
<rs xml:id="12972078" type="software">DeepSPM</rs> also addresses other typically arising issues (lost contact, crashed probe, and moving probe larger (macroscopic) distances to new approach areas).
</p>
<p>To train and evaluate <rs xml:id="12972079" type="software">DeepSPM</rs>, we used a low-temperature STM with a metallic probe (Pt/Ir) to image a model sample: magnesium phthalocyanine (MgPc) molecules adsorbed on a silver surface (Fig. 1 and Methods). Such molecular systems are scientifically and technologically relevant, owing to their electronic, optical, and chemical properties 29,30 . SPM provides an ideal tool for their characterization but also presents challenges (e.g., imagealtering probe-molecule interactions). Although spatial resolution may be poorer in comparison with a semiconducting or functionalized probe 23 , a metallic probe is required for many SPM techniques [e.g., scanning tunneling spectroscopy (STS) 5 and Kelvin probe force microscopy (KPFM) 31 ].</p>
<p>
<rs xml:id="12972080" type="software">DeepSPM</rs> overview.
<rs xml:id="12972081" type="software">DeepSPM</rs> works as a control loop (Fig. 1a). The artificial intelligence system drives the SPM by selecting an appropriate scanning region (Supplementary Fig. 1), acquires an image, and assesses the acquired image data (Fig. 1b). If the image is deemed "good", it is processed and stored (Fig. 1c), and
<rs xml:id="12972082" type="software">DeepSPM</rs> proceeds with the next loop iteration. If the image is labeled "bad",
<rs xml:id="12972083" type="software">DeepSPM</rs> addresses the issues, maintaining continuous and stable operation (see Methods).
</p>
<p>In Fig. 2, we give a graphical description of <rs xml:id="12972084" type="software">DeepSPM</rs>. The system is able to assess and identify causes of a defective acquisition (e.g., lost sample-probe contact, probe crash, bad sample region, bad probe). If sample-probe contact is lost or the probe crashes, <rs xml:id="12972085" type="software">DeepSPM</rs> re-establishes contact in a new scanning region (Methods). Images of bad sample regions (e.g., excessive roughness and contamination) can be identified algorithmically by the fact that measured heights span over a larger range compared with clean regions (see Methods). If a region is identified as a "bad sample", <rs xml:id="12972086" type="software">DeepSPM</rs> selects a new one and performs a new measurement.</p>
<p>Intelligent probe quality assessment. If
<rs xml:id="12972087" type="software">DeepSPM</rs> concludes that the sample imaging region is "good", it assesses the state of the probe: the classifier CNN (Supplementary Table 1) inspects the recorded image and predicts the probability of it being recorded with a bad probe (Fig. 3a). To train the classifier, we used a dataset of 7589 images of the MgPc/Ag(100) sample, labeled as acquired either with a "good" or "bad probe". In addition, we used data augmentation to increase the amount of training data (see Methods). It is noteworthy that the category "bad probe" includes various kinds of probe defects (Fig. 1b). We tested its performance on an unseen test dataset, achieving an accuracy of ~94% (Supplementary Table 1), a positive predictive value ~87% and a negative predictive value ~96%. As point of reference, classification accuracy of a human in a benchmark visual object recognition challenge 32 (ImageNet) ranges from 88% to 95%, on par with our CNN classifier. It is noteworthy that classification performance is intrinsic to the type of data and the specific datasets considered. We are, in concurrence with other work 33 , among the first to present a dataset of this kind and there are currently no available baselines for comparison. However, the performance achieved by
<rs xml:id="12972088" type="software">DeepSPM</rs> enables autonomous data acquisition and long-term operation of
<rs xml:id="12972089" type="software">DeepSPM</rs>.
</p>
<p>Intelligent probe conditioning. If the classifier CNN concludes that the probe is bad, <rs xml:id="12972090" type="software">DeepSPM</rs> uses a deep RL agent to condition it (Fig. 3b). This RL agent is controlled by a second CNN (action CNN), which is trained by interacting with the SPM setup: the RL agent inspects the last recorded image and performs a probeconditioning action, selected from a list of 12 actions. We determined this list by considering actions commonly used for probe conditioning by expert human operators (Methods, Supplementary Note 1, and Supplementary Table 2); they consist of either a voltage pulse applied between probe and sample, or a dip of the probe into the sample 9 . After each conditioning step, <rs xml:id="12972091" type="software">DeepSPM</rs> evaluates the outcome of the conditioning process by acquiring the next image, which is then assessed by the classifier CNN. If the new image is classified as "bad probe", the agent receives a negative reward (r = -1) and proceeds with another action. If the image is classified as "good probe", the conditioning episode (sequence of conditioning steps; Fig. 3c) is terminated and the agent receives a positive reward (r = 10; Methods).</p>
<p>The RL agent learns an approximately optimal conditioning procedure by attempting to maximize the cumulative reward received for each conditioning episode, thus minimizing the number of required conditioning steps (Supplementary Note 2). To achieve this, we relied on Q-learning 34 (see Methods): the action CNN processes each recorded image and predicts the expected future reward (Q-value) resulting from each possible conditioning action. The RL agent then selects the action with the highest Q-value (ε-greedy policy; Methods and Supplementary Fig. 2).</p>
<p>To test the RL agent's performance, we compared it with a baseline case where conditioning actions are selected randomly from the list of common actions (Fig. 3b). During testing, we actively damaged the probe after each conditioning episode (see Methods). The trained RL agent is able to condition the probe efficiently (Fig. 3d and Supplementary Figs. 3 and4) and does so in an average number of conditioning steps ~28% smaller than in the random case. Intelligent selection of conditioning actions by the RL agent significantly outperforms random selection.</p>
<p>Autonomous SPM operation. We next demonstrate long-term autonomous operation of the entire <rs xml:id="12972092" type="software">DeepSPM</rs> system. For a period of 86 h, we let <rs xml:id="12972093" type="software">DeepSPM</rs> control the microscope. Figure 4a shows <rs xml:id="12972094" type="software">DeepSPM</rs>'s behavior in an approach area, highlighting occurrences of bad probe detection and conditioning, and avoiding "bad sample" regions. In Fig. 4b, we show the area scanned by the system as a function of time. In total, <rs xml:id="12972095" type="software">DeepSPM</rs> scanned a sample area of 1.2 μm 2 (Fig. 4), recorded &gt;16,000 images, handled 2 lost contacts, identified and avoided 1075 regions of excessive roughness, and repaired the probe 117 times (Supplementary Table 3).</p>
<p>To evaluate the overall performance of
<rs xml:id="12972096" type="software">DeepSPM</rs>, we manually inspected the recorded images (Supplementary Note 3). Out of all images labeled "good" by
<rs xml:id="12972097" type="software">DeepSPM</rs>, ~87% were found to be without defects or imaging artifacts. Out of all conditioning episodes initiated by
<rs xml:id="12972098" type="software">DeepSPM</rs>, ~86% were found to be really necessary (Supplementary Fig. 5, Methods, and Supplementary Fig. 6). It is noteworthy that these performance metrics are not related to static classification (as for the classifier CNN testing), as the state of the STM/sample system and the recorded images depend dynamically on the decisions made by
<rs xml:id="12972099" type="software">DeepSPM</rs>.
</p>
<p>During autonomous operation, the RL agent achieved an average conditioning episode length of 4.93, ~34% shorter than during testing (Fig. 3d). We attribute this to the fact that, during testing, the probe was actively damaged after each conditioning episode. This was not the case during autonomous operation, where arguably the state of the probe remains closer to a good one (Supplementary Note 3).</p>
<p>The available conditioning actions do not allow the RL agent to control the atomic-scale structure of the probe, which determines imaging quality. Their outcome is probabilistic and conditioning episode lengths vary (Fig. 3d). Nonetheless, our RL agent's betterthan-random performance shows that: (i) at each step of the conditioning process, it is in principle possible to intelligently choose an action that is likely to improve the probe, and (ii) that an ML system can learn to make this choice (Supplementary Note 4).</p>
<p>In our specific case here, the single images that <rs xml:id="12972100" type="software">DeepSPM</rs> records and that determine the RL agent's conditioning action selection do not enable the retrieval of the atomistic morphology of the probe. Therefore, the conditioning process behaves effectively as if it had memory; the probe state depends on the specific sequence of previous actions and images. Continuous training of the RL agent during operation allows it to follow the evolution of the probe state and is hence essential to achieve better-thanrandom performance during operation (Supplementary Fig. 4).</p>
<p>Here we used RL to optimize a data acquisition protocol. The benefit of RL for such a task is that the rules for optimization (optimal choices for probe conditioning) do not need to be known in advance; an agent with sufficient training can establish them by interacting with the experimental setup, without human guidance.</p>
<p>Automation of complex experimental procedures such as SPM frees valuable researcher time. <rs xml:id="12972101" type="software">DeepSPM</rs> brings state-of-the-art SPM closer to a turnkey application, enabling non-expert users to achieve optimal performance.</p>
<p><rs xml:id="12972102" type="software">DeepSPM</rs> can be applied directly to any sample, probe material, or STM/AFM setup, as long as specific training datasets are available (see Methods). It can further be expanded to other SPM spectroscopy techniques (e.g., STS and KPFM), where probe quality conditions would need to include additional spectroscopic requirements 5,31 (Supplementary Note 5). Fully autonomous SPM also opens the door to high-throughput and scalable atomically precise nano-fabrication 35 , hardly feasible via manual operation.</p>
<p>Future work can further extend our method by combining it with semi-automatic ML approaches used for, e.g., the identification of adverse imaging conditions 24,33 or imaging regions of interest 18 .</p>
<p>Sample preparation. The samples were prepared in-situ by sublimation of MgPc molecules (Sigma-Aldrich) at 650 K (deposition rate ≈ 0.014 molecules nm -2 min -1 ; sub-monolayer coverages) onto a clean Ag(100) surface (Mateck GmbH) held at room temperature. The Ag surface was prepared in ultra-high vacuum (UHV) by repeated cycles of Ar + sputtering and annealing at 720 K. The base pressure was below 1 × 10 -9 mbar during molecular deposition.</p>
<p>STM measurements. The STM measurements were performed using a commercial scanning probe microscope (Createc) capable of both STM and noncontact AFM at low temperature (down to 4.6 K) and in UHV. This setup includes two probe-positioning systems: a coarse one for macroscopic approaching and lateral positioning of the probe above the sample; a fine one consisting of a piezo scanner that allows for high-resolution imaging. The lateral range of the fine piezo scanner at 4.6 K is ±425 nm, i.e., each approach of the probe to the sample with the coarse system defines a scanning region area of 850 × 850 nm 2 ). Nanonis electronics and SPM software (SPECS) were used to operate the setup. All measurements were performed at 4.6 K with a Pt/Ir tip. All topographic images were acquired in constant-current mode (V bias = 1V, I t = 25 pA) at a scan speed of 80 nm s -1 .</p>
<p>After moving the probe macroscopically to a new sample area, <rs xml:id="12972103" type="software">DeepSPM</rs> extends the z piezo scanner to ~80% of its maximum extension, to maximize the range of tunneling current feedback controlling the z position of the scanner without crashing or losing contact. If tunneling contact is lost, <rs xml:id="12972104" type="software">DeepSPM</rs> reapproaches the probe. <rs xml:id="12972105" type="software">DeepSPM</rs> also handles probe crashes (see section below "Detection and fixing of lost contact/probe crash").</p>
<p>After approaching the probe to the sample, <rs xml:id="12972106" type="software">DeepSPM</rs> waits ~120 s before starting a new scan, to let thermal drift and (mainly) creep of the z piezo settle. New measurements start at the neutral position of the xy scan piezo (that is, x = y = 0), where no voltages are applied to the xy piezo scanner, to minimize the piezo creep in the xy scanning plane. <rs xml:id="12972107" type="software">DeepSPM</rs> selects the next imaging region by minimizing the distance that the probe travels between regions (see Fig. 4, section "Finding the next imaging region" and Supplementary Fig. 1), further reducing xy piezo creep. After moving the probe to a new imaging region, <rs xml:id="12972108" type="software">DeepSPM</rs> first records a partial image that is usually severely affected by distortions due to xy piezo creep. This image is discarded and a second image, not or only minimally affected, is recorded at the same position. During autonomous operation, the RL agent of <rs xml:id="12972109" type="software">DeepSPM</rs> continues to learn about probe conditioning (see main text and below). To avoid damaging a good probe by unnecessary conditioning during autonomous operation, <rs xml:id="12972110" type="software">DeepSPM</rs> initiates a probe-conditioning episode only after ten consecutive images have been classified as "bad probe" by the classifier CNN (Supplementary Fig. 6). The episode is terminated as soon as the first image is classified as "good probe" by the classifier CNN. Images that are not part of a conditioning episode (including the ten consecutive images that triggered it), or that have been disregarded due to "bad sample", lost probe-sample contact or crashed probe, are labeled as "good image".</p>
<p>Finding the next imaging region. For each new approach area, <rs xml:id="12972111" type="software">DeepSPM</rs> starts acquiring data at the center of the scanning range (Fig. 4a). <rs xml:id="12972112" type="software">DeepSPM</rs> uses a binary map to block the imaging regions that have already been scanned (Supplementary Fig. 1). If a region is identified as "bad sample" (e.g., excessive roughness is detected), <rs xml:id="12972113" type="software">DeepSPM</rs> defines a larger circular area around it (as further roughness is expected in the vicinity), and avoids scanning this area. The radius r forbidden of this region is increased as consecutive imaging regions are identified as "bad sample":</p>
<p>where t is the number of consecutive times an area with excessive roughness was detected.</p>
<p>As probe-conditioning actions can cause debris and roughness on the sample, <rs xml:id="12972114" type="software">DeepSPM</rs> blocks a similar circular area to avoid around the location of each performed conditioning action. The size of this area depends on the executed action (Supplementary Table 2). <rs xml:id="12972115" type="software">DeepSPM</rs> chooses the next imaging region centered at position v t ¼ x t x þ y t ŷ (x t , y t are coordinates with respect to the center of the approach area) that minimizes</p>
<p>provided that this is a valid imaging region according to the established binary map. Here, v t-1 denotes the position of the center of the last imaging region, ||…|| 1 is the Manhattan norm, and ||…|| 2 is the standard Euclidian norm. The parameter α controls the relative weight of the two distances, i.e., to the center of the last scanned region (to minimize travel distance), and to the center of the approach area (to efficiently use the entire available area). We found α = 1 works well. This algorithm minimizes the distance the probe travels between consecutive imaging regions, reducing the impact of xy piezo creep. Once the area defined by the fine piezo scanner range has been filled, or the distance to the center of the next available scanning region is larger than 500 nm, <rs xml:id="12972116" type="software">DeepSPM</rs> moves the probe (macroscopically, with the coarse positioning system) to a new approach area.</p>
<p><rs xml:id="12972117" type="software">DeepSPM</rs> architecture. The
<rs xml:id="12972118" type="software" subtype="environment">DeepSPM</rs> framework consists of two components: (i) the <rs xml:id="12972119" type="software" subtype="component" corresp="12972118">controller</rs>, written in <rs xml:id="12972120" type="language" corresp="12972119">Python</rs> and
<rs xml:id="12972121" type="software" corresp="12972118">TensorFlow</rs>, and (ii) a TCP server, written in
Labview. The <rs xml:id="12972122" type="software">controller</rs> contains the image processing, classifier CNN, and RL agent. The TCP server creates an interface between the <rs xml:id="12972123" type="software">controller</rs> and the
<rs xml:id="12972124" type="software">Nanonis SPM</rs> software. The <rs xml:id="12972125" type="software">controller</rs> sends commands via TCP, e.g., for acquiring and recording an image, executing a conditioning action at a certain location. The server receives these commands and executes them on the <rs xml:id="12972126" type="software">Nanonis/SPM</rs>. It returns the resulting imaging data via TCP to the <rs xml:id="12972127" type="software">controller</rs>, where it is processed to determine the next command. Based on this design, the agent can operate on hardware decoupled from the
<rs xml:id="12972128" type="software">Nanonis SPM</rs> software.
</p>
<p>Training and test dataset for classifier CNN. We compiled a dataset of 7589 images (constant-current STM topography, 64 × 64 pixels) of MgPc molecules on Ag(100), acquired via human operation. We assigned to each image a ground truth label of the categories "good probe" (25%) or "bad probe" (75%). We randomly split the data into a training (76%) and test set (24%). We used the latter to test the performance of the classifier CNN on unseen data (i.e., not used for training). The dataset is available online at https://alex-krull.github.io/stm-data.html.</p>
<p>It is important to note that the classifier CNN was trained to distinguish a "good probe" from a "bad probe". The classifier CNN was not trained to identify a specific type of probe defect in the case of a "bad probe". Figure 1b shows examples of possible imaging defects, including different types of probe defects (recognized as "bad probe" by the classifier CNN) and other image acquisition issues (e.g., lost contact and excessive sample roughness) that are detected algorithmically.</p>
<p>CNN architecture. We used the same sequential architecture for both the classifier CNN and the action CNN of the RL agent, differing only in their output layer and specific hyper-parameters (see below). The basic structure is adapted from the VGG network 21 . We used a total of 12 convolutional layers: four sets of three 3 × 3 layers (with 64, 128, 256, and 512 feature maps, respectively) and 2 × 2 maxpooling after the first two sets. The convolutional layers are followed by two fully connected layers, each consisting of 4096 neurons. Each layer, except the output layer, uses a ReLU activation function and batch normalization 36 . The input in all networks consisted of 64 × 64 pixel constant-current STM topography images. We used Dropout 37 with a probability of 0.5 after each fully connected layer to reduce overfitting. The network weights were initialized using Xavier initialization 38 .</p>
<p>Classifier CNN. The classifier CNN uses the architecture above. It has a single neuron output layer with a sigmoid activation function. This output (ranging from 0 to 1) gives the classifier CNN's estimate of the probability that the input image was recorded with a "good probe". The decision threshold was set to 0.9. It is noteworthy that
<rs xml:id="12972129" type="software">DeepSPM</rs> requires ten consecutive images classified as "bad probe" to start a conditioning episode (Supplementary Fig. 6). We trained the classifier CNN using the
<rs xml:id="12972130" type="software">ADAM</rs> <rs xml:id="12972131" type="bibr">39</rs> optimizer with a cross-entropy loss and L2 weight decay with a value of 5 × 10 -5 and a learning rate of 10 -3 . To account for the imbalance of our training set ("good probe" 25% and "bad probe" 75%), we weighed STM images labeled as "good probe" by a factor of 8 when computing the loss 40 . In addition, we increased the available amount of training data via data augmentation, randomly flipping the input SPM images horizontally or vertically. It is noteworthy that all training data consisted of experimental data previously acquired and labeled manually.
</p>
<p>Reinforcement learning agent and action CNN. Our RL agent responsible for the selection of probe-conditioning actions is based on double DQN 34 , which is an extension of DQN 28 . We modified the double DQN algorithm to suit the requirements of <rs xml:id="12972132" type="software">DeepSPM</rs> as follows. The action CNN controlling the RL agent uses the architecture above, with a single constant-current STM image as input. It is noteworthy that the original DQN uses a stack of four subsequent images. Our action CNN has an output layer consisting of 12 nodes, one for each conditioning action. The output of each node is interpreted as the Q-value of the corresponding action, i.e., the expected future reward to be received after executing it. We initialized the weights of the action CNN (excluding the output layer) with those of the previously trained classifier CNN, based on the assumption that the features learned by the latter are useful for the action CNN 41 . The output layer, which has a different size in both networks, is initialized with the Xavier initialization 38 . To train the action CNN, we let it operate the SPM, acquiring images, and selecting and executing probe-conditioning actions repeatedly when deemed necessary (Figs. 1 and2). Once sufficient probe quality was reached (i.e., the probability predicted by the classifier CNN exceeded 0.9), the conditioning episode was terminated-a conditioning episode consists of the sequence of probe-conditioning actions required to obtain a good probe. Random conditioning actions (up to five) were then applied to reset (i.e., re-damage the probe), until the predicted probability drops below 0.1. The RL agent received a constant reward of -1 for every executed probe-conditioning action. It received a reward of +10 for each terminated training episode, i.e., each time the probe was deemed good again. We chose these reward values heuristically by testing them in a simulated environment. In these simulations, the RL agent executed conditioning actions and the reward protocol was applied based on images resulting from the convolution of a good, clean synthetic image with a model kernel representing the probe morphology. Following a conditioning action, this kernel was updated stochastically. In this reward scheme, the RL agent receives a positive cumulative reward for and favors short conditioning episodes, whereas it receives a negative cumulative reward and is punished for longer episodes.</p>
<p>The RL agent uses ε-greedy exploration to gather experience 25 . For each conditioning step, the agent chooses a conditioning action probabilistically based on parameter ε (0 &lt; ε &lt; 1): it chooses randomly with a probability ε, and it chooses the action with the largest predicted future reward (Q-value) with probability (1 -ε). For example, if ε = 1, action selection is strictly random; if ε = 0, action selection is based strictly on predicted Q-value. We start training (Supplementary Fig. 2) with 500 random steps (ε = 1) that are used to pre-fill an experience replay buffer 28 . This buffer contains all experiences the agent has gathered so far, each consisting of an input image, the chosen action and its outcome (the next image assessed by the classifier CNN, as well as the reward received). We used data augmentation, adding four experiences to the buffer for each step. These additional experiences consisted of images flipped horizontally and vertically. After 500 steps (i.e., 2000 experiences in the buffer), we started training the action CNN with the buffer data. We used the <rs xml:id="12972133" type="software">ADAM</rs> optimizer <rs xml:id="12972134" type="bibr">39</rs> with a batch size of 64 images processed simultaneously and with a constant learning rate of 5 × 10 -4 . We limited the buffer size to 15,000, with new experiences replacing the old ones (first-in, first out). To allow parallel execution and increase the overall performance of the training, we decoupled the gathering of experience and the learning into separate threads. During training, we decreased ε linearly over 500 steps, from 1.0 to 0.05. After reaching ε = 0.05, we continued training with additional 4360 steps, during which we kept ε = 0.05 constant 34 . We used a constant discount factor of γ = 0.95 25 .</p>
<p>Testing of the RL agent. After training the RL agent, we tested its performance in operating the STM by comparing it with the probe-conditioning performance achieved via random conditioning action selection. During this evaluation, we allowed the action CNN to continue learning from continuous data acquisition with a constant ε = 0.05. Except for this value of ε, the testing process matches that of the RL agent training above. To achieve a meaningful comparison, we accounted for the fact that the state of the sample and the probe changes after each executed conditioning action (Supplementary Figs. 3 and4), by adopting an interleaved evaluation scheme. That is, RL agent action selection and random selection alternate in conditioning the probe, switching after each completed probeconditioning episode.</p>
<p>STM image pre-processing. The scanning plane of the probe is never perfectly parallel to the local surface of the sample. This results in a background gradient in the SPM images that depends on the macroscopic position and, to a lesser extent, on the nanoscopic shape of the probe. This gradient was removed in each image by fitting and subtracting a plane using
<rs xml:id="12972135" type="software" subtype="component" corresp="12972138">RANSAC</rs> <rs xml:id="12972136" type="bibr">42</rs> (<rs xml:id="12972137" type="software" subtype="environment">Python</rs> <rs xml:id="12972138" type="software" subtype="component" corresp="12972137">scikit-learn</rs> implementation; polynomial of degree 1, residual threshold of 5 × 10 -12 , max trials of 1000). The acquired STM data were further normalized and offset to the range [-1; 1], i.e., such that pixels corresponding to the flat Ag(100) had values of -1 and those corresponding to the maximum apparent height of MgPc (~2 Å) had values of 1. In addition, we limited the range of values to [-1.5, 1.5], shifting any values outside this range to the closest one inside the interval.
</p>
<p>Finding an appropriate action location. For a given acquired STM image, <rs xml:id="12972139" type="software">DeepSPM</rs> executes a probe-conditioning action at the center of the largest clean Ag (100) square area (Fig. 3). This center is found by calculating a binary map from the pre-processed image (see above), where pixels close (≤0.1 Å) to the surface fitted plane are considered empty, i.e., belong to a clean Ag(100) patch, and all others as occupied. The center of the largest clean Ag(100) square area within this binary map was chosen as the conditioning location. We defined an area requirement for each conditioning action (Supplementary Table 1). A conditioning action is allowed and can be selected by the agent only if the available square area is within this specified requirement.</p>
<p>Detection and fixing of lost contact/probe crash. <rs xml:id="12972140" type="software">DeepSPM</rs> is able to detect and fix any potential loss of probe-sample contact during scanning. It does so by monitoring the extension (z-range) of the fine piezo scanner; if the fine piezo scanner extends in the z-direction beyond a specified threshold (towards the sample surface), <rs xml:id="12972141" type="software">DeepSPM</rs> prevents the potential loss of probe-sample contact by re-approaching the probe towards the sample with the coarse probe-positioning system (until the probe is within an acceptable distance range from the sample). Data acquisition can then continue at the same position. Similarly, <rs xml:id="12972142" type="software">DeepSPM</rs> can prevent probe-sample crashes, i.e., by increasing the probe-sample distance with the coarse probe-positioning system if the fine piezo scanner retracts in the z-direction beyond a specified threshold (away from the sample surface).</p>
<p>We thank Florian Jug for his feedback on the manuscript. A.S. acknowledges support from the Australian Research Council (ARC) Future Fellowship scheme (FT150100426). C.K. acknowledges support from the ARC Center of Excellence in Future Low-Energy Electronics Technologies. Part of the computations were performed on an HPC Cluster at the Center for Information Services and High Performance Computing (ZIH) at TU Dresden. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 program (grant number 647769).</p>
<p>Relevant data are made available by the authors. Our classification dataset is available online at https://alex-krull.github.io/stm-data.html. A visual representation of the probeshaping episodes of the autonomous operation is available as Supplementary Data 1.</p>
<p>The source <rs xml:id="12972143" type="software" subtype="implicit">code</rs> will be made available at
<rs xml:id="12972144" type="url" corresp="12972143">https://github.com/abred/DeepSPM</rs>.
</p>
<p>A.K., P.H., and C.K. performed all experiments and analyzed all data. A.K., P.H., A.S., C.R., and C.K. designed the experiments, interpreted the data, and wrote the manuscript. All authors discussed the results and contributed to the final manuscript.</p>
<p>The authors declare no competing interests.</p>
</text>
</tei>