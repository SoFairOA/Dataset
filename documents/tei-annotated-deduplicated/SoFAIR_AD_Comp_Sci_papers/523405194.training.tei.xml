<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
<teiHeader>
<fileDesc xml:id="_1"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text xml:lang="en">
<p>This study is the first to provide an integrated view on the body of knowledge of artificial intelligence (AI) published in the marketing, consumer research, and psychology literature. By leveraging a systematic literature review using a data-driven approach and quantitative methodology (including bibliographic coupling), this study provides an overview of the emerging intellectual structure of AI research in the three bodies of literature examined. We identified eight topical clusters: (1) memory and computational logic; (2) decision making and cognitive processes; (3) neural networks; (4) machine learning and linguistic analysis; (5) social media and text mining; (6) social media content analytics; (7) technology acceptance and adoption; and (8) big data and robots. Furthermore, we identified a total of 412 theoretical lenses used in these studies with the most frequently used being: (1) the unified theory of acceptance and use of technology; (2) game theory; (3) theory of mind; (4) theory of planned behavior; (5) computational theories; (6) behavioral reasoning theory; (7) decision theories; and (8) evolutionary theory. Finally, we propose a research agenda to advance the scholarly debate on AI in the three literatures studied with an emphasis on cross-fertilization of theories used across fields, and neglected research topics.</p>
<p>artificial intelligence, AI, big data and robots, decision making and cognitive processes, machine learning and linguistic analysis, memory and computational logic, neural networks, social media content analytics, social media and text mining, systematic literature review, technology acceptance and adoption</p>
<p>The field of artificial intelligence (AI) is experiencing a second renaissance since computers appeared first in the 1950s (Tan &amp; Lim, 2018). This is partly explained by advances in computing and big data capabilities which enabled computer scientists to develop algorithmic models that can identify patterns and learn in real time. Today, AI applications go beyond purely computing fields and are deployed in a rapidly increasing number of contexts and devises. These include smartphones (Makridakis, 2017), recommender systems (Zhang et al., 2021), and customer service (Belanche et al., 2020;Lu et al., 2020; Wirtz et al., 2018). They even take on advanced roles in fields that were previously considered to be reliant on human intellect such as in journalism (Carlson, 2015), creative roles like painting (Quackenbush,</p>
<p>2018) and music production (Marshall, 2018), (Tufekci, 2015) and marketing (Sterne, 2017).</p>
<p>While AI is experiencing exponential growth in adoption by marketing managers and consumers, to the best of our knowledge, there is no study covering comprehensively and holistically the body of knowledge produced on AI in the closely related fields of marketing, consumer research, and psychology. This is surprising as the psychological underpinnings of AI adoption in consumer behavior and use of AI in marketing are often tightly related to research in the broader psychology field. Furthermore, the importance of understanding psychological processes to the field of AI is evident. Scientists that began working on AI had the ultimate goal to develop machines that could perform a task that, if conducted by a human, would require intelligence (McCarthy et al., 2006). Therefore, an understanding of how cognitive processes can be replicated by algorithms has become essential. The link with the field of marketing is also critical as marketing represents one of the most important application areas for AI (Sterne, 2017). Accordingly, this literature review aims to answer the following research question: What is the intellectual structure of the marketing, consumer research, and psychology literature related to AI?</p>
<p>To address our research question, the paper is organized as follows. Section 2 reviews the conceptual underpinnings and sheds light on the recent debate on AI in the three fields of study. Section 3 describes the methodology and research design. Section 4 discusses our findings regarding the descriptive analysis, keyword occurrence, the themes that emerged from the bibliographic coupling analysis, the theoretical lenses used in the three literatures, and emerging theories. Section 5 presents suggestions for further research.</p>
<p>This paper aims to map the intellectual structure of three areas of marketing, consumer research, and psychology knowledge in relation to AI. Therefore, this section defines the conceptual underpinnings of AI in each of these fields to inform this systematic literature review (SLR).</p>
<p>Marketing is defined as the activity, set of institutions, and processes for creating, communicating, delivering, and exchanging offerings that have value for customers, clients, partners, and society at large (American Marketing Association, 2017). Marketing as a discipline has evolved due to rapid technological changes. In its research priorities for 2020-2022, the Marketing Science Institute describes AI as an important technology that has impact on the capabilities and accountability of marketing management and in the optimization of marketing functions and strategies (Marketing Science Institute, 2020).</p>
<p>Consumption, consumer studies, and consumer research are fundamental parts of contemporary society and of interest not only to marketers, but also to policy makers and other research disciplines (MacInnis et al., 2020). There is a variety of interactions that consumers currently have with AI. Marketing researchers recognize that AI offers important potential benefits for consumers and their lives (e.g., Pitardi et al., 2021). However, there are also inherent tensions the increased use of AI can have on consumers, which include privacy concerns, dehumanization, and even addiction (Lobschat et al., 2021;Puntoni et al., 2021).</p>
<p>The field of psychology emerged early on as discipline of great importance to the investigation of behavior in the marketplace and marketing science (Alderson, 1952). Psychology focuses on the study of the mind and how it influences our behaviors, and ranges from communications, memory, and decision making, to perceptions, thought, and emotions (British Psychological Society, 2021). Despite the fact that marketing has drawn on several social science disciplines such as sociology and cultural anthropology, psychological theories remain at the core of consumer behavior and marketing research.</p>
<p>The intersection between marketing, consumer research, and psychology has been underpinned historically by the shift from using mostly economic models to explain consumer choice to a focus on psychological theories. These psychological theories draw on models from social psychology, motivational psychology, environmental psychology, and education psychology (Hansen, 1976). By embracing theories from psychology and other social sciences, consumer research has increasingly focused on gaining a deeper understanding of the thinking, desires, and experiences of individual consumers (Malter et al., 2020). AI has been defined as "the use of computational machinery to emulate capabilities inherent in humans, such as doing physical or mechanical tasks, thinking, and feeling" (Huang &amp; Rust, 2021, p. 31).</p>
<p>Historically, AI emerged almost at the same time as the first computers, but more recently, AI has gained momentum as new applications are possible due to rapid advances in computer power and a wide range of technologies (e.g., computer vision, machine learning, and natural language processing), and an explosion of available data to train algorithms (Bornet et al., 2021).</p>
<p>The increasing relevance of AI in marketing is witnessed by the emergence of several literature reviews on the topic. For example, Mustak et al. (2021) conducted topic modeling using natural language processing. They identified ten research topics in the area of marketing and AI that were later classified in relation to two major pillars:</p>
<p>(1) consumer research, and (2) organization and strategy-related research. Vlacic et al. (2021) reviewed the literature on AI/intelligent systems and marketing using content analysis combined with multiple correspondence analysis procedures and identified four themes: (1) marketing channels, (2) marketing strategy, (3) performance, and (4) segmentation, targeting and positioning.</p>
<p>Our study is distinctively different compared to past literature reviews and makes the following contributions. First, our article is the first to focus on AI in the interrelated fields of marketing, consumer research and psychology, and provides an integrated view of these three streams of literature. Second, in addition to adopting bibliometric techniques, we examine the overarching intellectual structure emerging from the three steams of literature, and therefore, move beyond traditional disciplinary boundaries and look at the multidisciplinary linkages and dialogue between the three fields. Third, and as a corollary of the previous point, we identify and discuss the wide range of theoretical lenses adopted in this multidisciplinary area to facilitate a better understanding of AI research.</p>
<p>To generate an up-to-date overview of existing research on AI in marketing, consumer research, and psychology, and assess quantitatively the related literature, we carried out a SLR. SLRs are considered the appropriate tool to systematically assess and evaluate a given body of literature (Ginsberg &amp; Venkatraman, 1985). Additionally, as a comprehensive, structured, and analytical means of accurately organizing reviews, a SLR is an effective method to identify research gaps (Klassen et al., 1998;Paul &amp; Criado, 2020). Widely adopted in social sciences (Tranfield et al., 2003), management, and marketing research (Christofi et al., 2021;Paul &amp; Feliciano-Cestero, 2021), a SLR offers a number of benefits, including the ability to construct flexible databases of articles that can easily be updated and interrogated (Pickering &amp; Byrne, 2014). Data for our SLR was extracted and gathered from <rs xml:id="12896678" type="software">Scopus</rs>, one of the most comprehensive sources of indexed academic publications. It covers articles published since 1966, indexing 12,850 journals in fields such as physical sciences, health sciences, life sciences, and of course, social sciences (Archambault et al., 2009). <rs xml:id="12896679" type="software">Scopus</rs> was chosen over <rs xml:id="12896680" type="software">Web of Science</rs> for two reasons. First, as scholars face a trade-off between data coverage and cleanliness, <rs xml:id="12896681" type="software">Scopus</rs> has been found to have a larger coverage (60% larger) than <rs xml:id="12896682" type="software">WoS</rs> <rs xml:id="12953742" type="bibr">(Zhao &amp; Strotmann, 2015)</rs>. Second, SLRs and bibliometric studies in social sciences typically deploy only on one database to mitigate data homogenization issues faced when working with multiple databases (e.g., Galati &amp; Bigliardi, 2019).</p>
<p>To search the database, we first identified a set of keywords related to AI in our three fields of study. Specifically, in line with a recent literature review of AI in marketing (Mustak et al., 2021) the keywords identified were: "AI," "artificial intelligence," "machine learning," "robot," "automation," "big data," "neural network*," "natural language processing," "data mining," "text mining," "soft computing," "fuzzy logic," "biometrics," "geotagging," "wearable*," "IoT," "Internet of Things," "chatbot," "smart technologies," "AI service robots," and "autonomous vehicles."</p>
<p>We ran a query using a combination of these keywords (adopting the Boolean operator "OR") in the fields related to "title," "abstract," and "keywords." We took into account works published until June 15, 2021. We then narrowed down the sample by examining its intersection with the keywords "marketing," "consumer*," and "psycholog*." After excluding proceedings, book chapters, books, and materials not published in English, and confining the search to the subject areas "Business, Management and Accounting" and "Psychology," the search yielded 4488 articles.</p>
<p>Finally, we retrieved the metadata for these 4,488 articles which included author names, titles, country of corresponding author, total number of publications, citation counts (i.e., total citations, average article citations, and number of citing articles with and without selfcitations), journal sources, keywords, countries and regions, and author-level metrics (c.f., Martynov et al., 2020).</p>
<p>The analysis section first presents the descriptive analyses, followed by the analyses of key word occurrence and co-occurrence. The final section examines the theoretical lenses used across the three literature fields.</p>
<p>In this section, we provide a descriptive analysis of the sample obtained through our SLR queries. For this analysis, we used number of publications as proxy for research productivity (e.g., by country and journal) and the number of citations for research impact.</p>
<p>We plotted the evolution of publications on the topic of AI in our three fields over time from 1972 to June 2021. Figure 1 presents this evolution which suggests a rapid and exponential growth over the last decade which testifies to the growing scholarly interest in the topic.</p>
<p>We note that the majority of publications of the topic (53.7% of 4497 articles) are accounted from the period of 2017 to June 2021.</p>
<p>Our query collected publications from 72 different countries. A holistic illustration of the countries by number of articles published is shown in Figure 2. The top 10 countries are shown in Table 1, with the United States, the UK, and China in the top three. This seems to largely mirror the technological achievements of these countries, which is potentially driven by their large scale governmental funding and industrial policies that support investments in Industry 4.0 technologies in general and AI in particular. According to recent academic and industry research, the United States hosts the largest AI service providers (UNCTAD, 2021), China and the United States are home to the most AI professionals (Rayome, 2019), and all of the top 20 countries in terms of AI publications are also those in the top 20 countries in terms of technologies readiness index (UNCTAD, 2021).</p>
<p>Journals publishing on AI in our three fields are listed in Table S1. It is interesting to note that it is journals in psychology and human-computer interactions that have played a key role in the advancement of research in AI, which are then followed by journals in computer and information systems, then business and marketing journals.</p>
<p>Previous bibliometric work has conducted keyword analyses to determine the content of articles and the main themes that are examined in an area of knowledge (Comerio &amp; Strozzi, 2019). In this study we performed keyword co-occurrence analysis aimed at identifying keyword co-occurrence networks (Radhakrishnan et al., 2017). Keywords co-occurrence analyses allow to graphically F I G U R E 1 Number of publications per year on AI in marketing and psychology. The number of publications for 2020 only shows the first 6 months of the year and suggests a dramatic overall increase for 2020 over the previous year. AI, artificial intelligence F I G U R E 2 Countries that have published on AI within marketing, consumer research, and psychology. AI, artificial intelligence represent and understand the knowledge structure of a scientific field by examining the links between keywords. Co-occurrence analysis explores implicitly the relationships that authors in research papers make when they select the keywords for their manuscripts (Su &amp; Lee, 2010). Therefore, in our analysis, the keywords found in the same keyword co-occurrence networks are the ones that are conceptually close, while proximity to other keyword co-occurrence networks and keywords can be regarded as how close those two concepts are to each other. The results of our keyword cooccurrence analysis is shown in Figure 3. As is shown in Figure 3, the concepts of AI, big data and machine learning are central and closely interrelated. However, they are also connected to each of the other keyword co-occurrence networks. The keyword co-occurrence networks related to neural networks are more isolated and closely related to elements of learning memory, and decision making, which in turn link to marketing management functions such as market segmentation and customer relationship management.</p>
<p>As part of the keyword co-occurrence analysis, we were able to determine those keywords with the highest levels of occurrences and this is represented by the size of the circles in the visual representation of our co-occurrence analysis. We used the keywords with the highest occurrence in each keyword co-occurrence networks to name the keyword co-occurrence networks in our analysis: Big data, machine learning, AI, data mining, neural networks, marketing, and e-commerce. We discuss each of the keyword cooccurrence networks next, presented in order of occurrence.</p>
<p>Big data is a term used to describe data that due to its volume, rapidity in generation, and its diversity in terms of variety of data types provides marketers with an important area of opportunity to inform decision making (Erevelles et al., 2016). Big data has four characteristics (commonly referred as the 4Vs): volume (from terabytes to petabytes), velocity (cross-sectional data to high frequency stream data), variety (numeric, text, images, video, sound, etc.), and veracity (reliability and validity; Wedel &amp; Kannan, 2016). Erevelles et al. (2016) highlight that due to the high adoption of technological devices, consumers have become constant producers of traditional, structured, and transactional data as well as more contemporary, unstructured, and behavioral data. Applications of big data include establishing customer-centric marketing, developing and provisioning vehicle-data-driven services, and optimizing production processes by creating highly accurate virtual representations of production facilities (e.g., car manufacturing) and using real time data to minimize production costs (Dremel et al., 2020).</p>
<p>Machine learning is defined as a "computational strategy that automatically determines (i.e., learns) methods and parameters to reach an optimal solution to a problem rather than being programmed by a human a priori to deliver a fixed solution" (Dwyer et al., 2018, p. 94).</p>
<p>Machine learning is considered a subfield of AI as the learning process mimics a facet of human intelligence (Domingos, 2017).</p>
<p>There are numerous advantages associated to machine learning that academics in many fields have identified. For instance, in the field of psychology, machine learning methodologies and theory are considered to have the potential to move away from mainly explanatory theories and models to more predictive ones (Yarkoni &amp; Westfall, 2017). Similar expectations are also seen in the field of marketing, where early evidence on application of machine learning techniques in marketing activities (e.g., in direct marketing campaigns) have witnessed improvements in forecasting models, therefore assisting marketers with decision making (Cui et al., 2006).</p>
<p>AI refers to programs, algorithms, systems and machines that demonstrate intelligence (Shankar, 2018, p. vi). Since its early days, AI has had the ultimate goal to mimic intelligent human behavior (Syam</p>
<p>Data mining is the process of searching and analyzing data to detect implicit, but potentially useful, information (Berry &amp; Linoff, 2004).</p>
<p>Outcomes from data mining have improved due to developments in database processing, data warehousing, machine learning, and knowledge management (Shaw et al., 2001). Applications of data mining in marketing can be used for discovery, predictive modeling, and forensic analysis (Rygielski et al., 2002). Discovery involves looking into a database to identify hidden patterns without predetermined idea of what the patterns might be. Predictive modeling involves taking discovered patterns to predict future outcomes.</p>
<p>Finally, forensic analysis uses extracted patterns to identify anomalous or unusual data elements (Rygielski et al., 2002).</p>
<p>F I G U R E 3 Keyword co-occurrence networks in AI research in the fields of marketing, consumer behavior, and psychology. AI, artificial intelligence</p>
<p>A neural network (also known as an artificial neural network) is computer software that simulates human intelligence to deduce or learn from a data set (Law &amp; Au, 1999). In the context of neural computing, neural networks are used for pattern recognition and make use of feed-forward network architectures such as the multilayer perceptron (a computational method that efficiently evaluate the iterative procedures that algorithms perform to reduce errors)</p>
<p>and the radial basis function network (an alternative training method for algorithms to form links between disparate concepts; Bishop, 1995). Cortez et al. (2009) highlight that due to improvements in IT capabilities, it is possible to collect, store and process highly complex datasets. Neural networks have emerged as one of the data mining algorithms used to analyze this data. Through such data mining, managers aim to extract high-level knowledge by identifying trends and patterns which can then be used to improve decision making (Turban et al. 2008). Other techniques to derive meaning from neural networks are linear/multiple regression and support vector machines (Cortez et al., 2009).</p>
<p>As it would be expected in a SLR that focuses on the structure of knowledge related to marketing and AI, marketing as a theme emerged as a prominent topic. Research related to understanding how consumers make AI-supported decisions were highly cited.</p>
<p>Notably, Hauser (2014) provided evidence of consumers using heuristic decision rules to select the products in their consideration set and the role of AI in supporting this decision making. In relation to this, the use of big data is also identified as an opportunity to better understand consumer behavior (Filieri &amp; Mariani, 2021;Hofacker et al., 2016). Furthermore, empirical work found that using online promotional marketing and online reviews can be useful at predicting future product demand (e.g., Chong et al., 2017). Another prominent theme relates to marketing automation to attract customers, and build and maintain relationships with current and prospective customers (Järvinen &amp; Taiminen, 2016). Marketing automation exploits both active and passive means of learning about potential buyers.</p>
<p>Active approaches involve directly asking questions, and passive approaches involve utilizing information on past transactions or clickstream data.</p>
<p>E-commerce has emerged as a prevalent sales and service channel for many businesses (Chiang et al., 2006;Grewal et al., 2018) and has become an important context for research on data mining, business intelligence, and customer relationship management systems (Phan &amp; Vogel, 2010). Many e-commerce websites also use recommender systems that rely on algorithms and machine learning to recommend new products to customers and improve the transactions on these platforms (Guo et al., 2017).</p>
<p>Bibliographic coupling is a technique that measures the similarity between articles by capturing the number of shared references (Kessler, 1963). The references cited in an article help explain the topic and, as such, articles citing the same references are linked (Perianes-Rodriguez et al., 2016). Benefits of bibliographic coupling include the ability to provide visualization maps based on the most cited papers, presenting insights for current research concerns, and guidelines for upcoming research (Jones &amp; Gatrell, 2014).</p>
<p>We conducted a bibliographic coupling analysis of articles, authors, and journals to create structure maps and present a clear picture of the evolution of scientific production on the focal topic of AI in our three scientific fields (c.f., Boyack &amp; Klavans, 2010;Mariani &amp; Borghi, 2019;Mariani et al., 2021;Mariani &amp; Baggio, 2021;Pritchard, 1969;Zupic &amp; Čater 2015). Specifically, we employed VOS using the
<rs xml:id="12896684" type="software">VOSviewer</rs> package of <rs xml:id="12896685" type="publisher" subtype="person" corresp="12896684">Van Eck and Waltman</rs> ( 2009) to generate bibliometric maps, which has been widely adopted in the literature (e.g., Apriliyanti &amp; Alon, 2017;Ferreira, 2018). VOS has been found to be superior to multidimensional scaling to build bibliometric maps (Van Eck et al., 2010), and we therefore did not involve multidimensional scaling.
</p>
<p>We carried out bibliographic coupling by using articles as units of analysis and setting a threshold of at least 100 citations per paper.</p>
<p>This produced eight clusters from 198 documents. Figure 4 illustrates the eight clusters and their main themes. The clusters to the right side (clusters 1-3), just like the right hemisphere of the human brain, focus mainly on memory and reasoning, and general cognitive processes.</p>
<p>Those in the center (clusters 4 and 8) focus on specific aspects of how cognitive processes are translated into machine settings, as it is with the case of robotics and machine learning. Finally, the left side of the figure (clusters 5-7) shows the interaction between technology and humans and consumer psychology. These range from the acceptance, adoption and use of AI technology to analyzing consumer psychology using content analytics and text mining. The following sections explore each of these clusters in more detail.</p>
<p>Cluster 1 focuses on different cognitive processes that humans can perform and some of the tools that are available for computers to replicate them. For instance, Wilson (1988) developed a machineusable dictionary for experimentation in psycholinguistics. The dictionary also supported early applications of AI to create psychological and linguistic descriptions of words that could be understood and processed by machines. In a similar vein, Perry et al. (2007) offer an analysis of different computational models used for reading and word recognition.</p>
<p>Notable to the field of computational logic is the work of Thagard (1989) Other articles in this cluster focus on additional human cognitive processes that could be replicated by machines. For instance, Pylyshyn (1999) described how visual perception can be operationalized in computers and engaged in the debate on whether vision was indeed a cognitive process or a separate process from cognition. Human vision involves human brain processing an immense amount of sensory inputs and the activation of mechanisms to make sense of the visual inputs, including selective attention that helps the brain to prioritize differently the visual inputs (Frintrop et al., 2010). In the context of computer vision, computer systems and robots must also process millions of pixel values and given that visual perception is not separated from cognition, it is important to endow machines and robots with multiple sensors when performing visual tasks (Frintrop et al., 2010).</p>
<p>While the inputs of vision are pixel values in the context of robots, the output of vision would consist of shape representations entailing at least surface layouts, edges and further details sufficiently rich to allow parts to be looked up in a shape-indexed memory to identify known objects, as was suggested by Pylyshyn (1999).</p>
<p>Some of the most prominent articles in cluster 2 focus on purely cognitive processes that are relevant to understand how the human brain performs. For example, Everitt and Robbins (1997) examined the different functions of basal forebrain and pontine cholinergic mechanisms within the brain. They found that (1) the cholinergic system contributes greatly to visual attentional function, but not to mnemonic processes per se;</p>
<p>(2) the septohippocampal projection influences the modulation of short-term spatial (working) memory processes; and (3) the diagonal band-cingulate cortex cholinergic projection influences the ability to utilize response rules. This suggests that cognitive processes are highly complex, and that AI research should explore brain functions in depth.</p>
<p>Furthermore, Frank and Claus (2006) explored how different parts and systems within the brain inform decision making processes.</p>
<p>Recent work in this cluster developed connections between the scholarly understanding of those cognitive processes and the advances in AI that emulate some of them. Despite this progress in technology, there are challenges AI still faces. For example, Lake et al.</p>
<p>(2017) highlighted that even though AI is able to solve problems through pattern recognition, there is still significant progress needed before these systems are able to explain and understand phenomena, and to build knowledge gained via intuitive theories.</p>
<p>Cluster 3 focuses on the formation of neural networks, their role within psychological functions, and the formation of human personality. Neural networks are defined as a number of brain areas that, when used together, can carry out a psychological and/or physiological functions (Posner &amp; Rothbart, 2007). For instance, they can help humans identify faces by connecting different parts of the brain et al., 2002). Neural networks are also important to the formation of human personality and are closely related to temperament, which is conceptualized as the initial stage from which personality develops (Rothbart, 2007). For example, neural networks help scientists understand specific cognitive processes that are important to perform certain tasks. For instance, Posner and Rothbart (2007) examination of neural networks focused on how attention works. They argue that neural networks, genes, and socialization can explain human behavior and emotions.</p>
<p>Cluster 4 connects the field of psychology with advancements in computer science, namely through the use of machine learning.</p>
<p>Machine learning is understood "as a computational strategy that automatically determines (i.e., learns) methods and parameters to reach an optimal solution to a problem rather than being programmed by a human a priori to deliver a fixed solution" (Dwyer et al., 2018, p. 94). Part of the discussion found in this cluster relates less with how machine learning can help understand cognitive processes, but it is more centered on reshaping the field of psychology by incorporating principles from computer science. For instance, Yarkoni and Westfall (2017) criticize the field of psychology for their focus on explaining the causes of behavior, but not developing theories around predicting future behaviors accurately. They argue that the field of machine learning might help overcome this limitation, and refocus the attention from explanation to prediction.</p>
<p>Other articles in this cluster focus more specifically on the field of psychology and linguistics and contribute to the understanding of speech and cognitive styles, and how different application of machine learning can leverage this knowledge to better understand behavior.</p>
<p>Central to this area of knowledge is the work of Pennebaker et al. (2003) which emphasizes the importance of particles (e.g., pronouns, articles, conjunctions, prepositions, and auxiliary verbs) in speech, suggesting that they serve as markers of emotional states, social identity, and cognitive styles. They also examine some of the technologies available to process natural language through computers.</p>
<p>Cluster 5 emphasizes how user-generated content on social media can be used to inform marketing decisions. Social media emerged as an environment where consumers engage in a many-to-many communications and the creation and dissemination of content, which were all further fostered by the emergence of online communities (Kaplan &amp; Haenlein, 2010). Brands saw an opportunity to be where their target audiences where and started to permeate their presence in this environment (Fournier &amp; Avery, 2011;Wirtz et al., 2013).</p>
<p>However, marketers were faced with the challenge of how to systematically analyze and act on the large amount of unstructured data that were creating in blog posts, online reviews, and social networking sites (Wedel &amp; Kannan, 2016). This cluster covers the They also provide a taxonomy to determine the instances in which more reliance on big data versus traditional marketing data sources is more appropriate.</p>
<p>Finally, Fan et al. (2015) provide insights on when using and analyzing social media content is better than marketing's more traditional approaches such as surveys or advertising to derive customer insights. For example, the authors suggest that social media content analysis can help with customer segmentation and customer profiling, Furthermore, the literature on robots explores the role that this technology will have in different settings, such as services (Borghi &amp; Mariani, 2021;Mariani &amp; Borghi, 2021;Wirtz et al., 2018) and service encounters (Paluch &amp; Wirtz, 2020;Pitardi et al., 2021). Robots integrate several cognitive processes replicated by machines and rely on multiple sensors to autonomously perform complex actions. Prominent work in this area discusses at a conceptual level how robots can operate in service settings (Van Doorn et al., 2017;Wirtz et al., 2018;Huang &amp; Rust, 2018).</p>
<p>Additional studies focus on human-robot interaction and drivers of acceptance of social robots based on different occupational roles (e.g., security services and healthcare), gender (male vs. female), and personality (extrovert vs. introvert; Tay et al., 2014), and even the formation of attitudes towards service robots among children (Kahn et al., 2012).</p>
<p>To identify the different theoretical lenses used to inform the studies in our SLR, the abstracts were analyzed searching for the keywords "theory" and "model" to identify the theories and models that the articles contributed to. In total, 538 articles mentioned a theory or model in the abstract. From those papers, 412 different theories and models were identified, and Table 2 provides a summary of the 16 most frequently used theories organized by frequency on mention.</p>
<p>The TAM is one of the most widely applied model of users' acceptance and usage of technology (Venkatesh, 2000). TAM holds that perceived ease of use and perceived usefulness are critical factors in predicting First, PMT posits that coping appraisal (i.e., response efficacy, response cost, and self-efficacy) and threat appraisal (i.e., perceived vulnerability and perceived severity) influence decision making.</p>
<p>Second, PCT argues that when user's perception of benefit exceeds the privacy risk loss consumers would choose to adopt the behavior.</p>
<p>Another example on how
UTAUT has been expanded is the work of Moriuchi (2021) that integrated the four core factors of
UTAUT in conjunction with realism maximization theory and literature on anthropomorphism to determine virtual assistant's usage experience and intention to re-use this technology. Madigan et al. (2017) used
UTAUT to test the factors that influence users' acceptance of automated road transport systems (ARTS), where they found hedonic motivation to be the strongest predictor of behavioral intentions to use ARTS.
</p>
<p>Game theory aims to understand situations in which decision markers interact (Osborne, 2004). Prominent exemplar papers that used game theory are the works of West and Lebiere (2001) positive correlation between investment in BDA and higher profits.</p>
<p>The theory of mind maps physiological and mental phenomena, and has been central to AI research as it posits that mind can be realized in a wide range of set materials, both organic and inorganic (Steele, 2002). The theory of mind has two components: first order recursive thinking which implies the meta-representation or the representation of a mental representation of a low complexity level; and second order meta-representations of a greater complexity (Di Dio et al., 2020). A prominent study in this field is the work by Osbeck (2009) that examined the differences between models of cognition and information processing models. Models of cognition are found in psychology and are underpinned by the tenet that the mind is a complex system of representations of the world. On the other hand, information processing models found in computational sciences suggest that the mind acts more like a computer, processing units of information. Information processing models underpin the development of AI.</p>
<p>The theory of planned behavior is a psychological theory that links beliefs with intentions and ultimately behavior itself. The theory posits that attitudes towards the behavior, subjective norm, and perceived behavioral control determine the intentions to perform a specific behavior, and that intention is a strong predictor of actual behavior (Ajzen, 1991). The theory has been applied extensively in several consumer research settings, and from the studies captured by our literature review notable work is that of Kowatsch and Maass (2010) that integrated this theory together with the TAM (Davis, 1989) to determine the intention to use mobile recommendation agents (MRAs), the intention to prefer stores that used this technology, and the purchase intentions to buy the products after using</p>
<p>MRAs. Another example of application of this theory is the work of Perri et al. (2020) that utilize it to study the intention of consumers to adopt the smart grid technology. Their study included the three antecedents of intentions described by Ajzen (1991) with an additional variable related to resistance to change. In both studies the theory helped explained the behavioral intentions being measured.</p>
<p>Computational theories posit that the mind works like a computer.</p>
<p>The most notable work in this area is the work of Thagard (1989) that developed the computational theory of explanatory coherence to apply to the rejection and acceptance of hypotheses as well as to explain reasoning of everyday life. The theory consists of seven principles that capture properties such as if some set of properties P explain some other property Q, then all properties in P must be coherent with Q; that is, people will be more likely to accept explanations if they are consistent with their prior beliefs (Miller, 2019). Thagard's work has helped with the advancement in explainable AI, an area of research that aims to develop explanations of AI behavior beyond mere intuition of the researcher (Miller, 2019).</p>
<p>Another prominent computation theory is the computational theory of cognition. This theory is a unifying theory that combines psychological theories (e.g., theory of event coding, event segmentation theory, the theory of anticipatory behavioral control, and concept development), AI and machine learning theories (e.g., reinforcement learning and generative artificial neural networks), and theories from theoretical and computational neuroscience (e.g., predictive coding and free energy-based inference) (Butz, 2016). The</p>
<p>Decision theories are rooted in the belief that the human mind and decision making do not need to be mysterious processes and instead they can be mapped (Frantz, 2003). In the field of AI, decision theories have informed programming of algorithms in expert systems in the context of human resource management around heuristics decision making (Lawler &amp; Elliot, 1996). Furthermore, Matsui (2000) established that case-based decision theory (CBDT) can lead to equivalent results than more traditional expected utility theories that analyze human behavior under uncertainty in economics and game theory. In the case of CBDT, decisions under uncertainty are made by analogies to previously encountered problems (Gilboa &amp; Schmeidler, 1995).</p>
<p>Evolutionary theory, usually associated with Darwin, suggests that evolution occurs due to natural selection. Academics inPiattelli this area discuss for and against evolutionary perspectives to cognitive processes such as learning. For instance, the work of Piattelli-Palmarini (1989) examines evolutionary perspectives of learning and argues against the adaptationist view of the process, and instead suggests that learning results from exaptation.</p>
<p>On the other hand, Darwinian evolutionary theory has also been heavily criticized. In particular the work of Swenson (1997) deconstructs the arguments posited by Dennett (1995) that used evolutionary theory to explain psychological and epistemic dimensions of the world. Evolutionary theory has enabled the emergence of evolutionary computation (EC) that draws on neo-Darwinian principles (e.g., natural selection, mutation). A subfield of EC is that of evolutionary robotics, which unlike traditional AI methods (e.g., expert systems) depart from a naïve robot that learns by exploring and interacting with its environment by trial and error by building their own knowledge rather than relying on large datasets to learn particular outcomes.</p>
<p>The theory of flow explains the mechanics of engagement with a task (Csikszentmihalyi, 1991). Flow is defined as the satisfying feeling of heightened functioning in a task with full concentration to finish it (Csikszentmihalyi &amp; Csikzentmihaly, 1990). The theory has been used</p>
<p>to develop robots that adapt the level of difficulty of tasks to increase engagement and improve user experience (Shirzad &amp; Van der Loos, 2016).</p>
<p>Poushneh (2021) extended flow theory by examining the effect that voice assistant personality traits drive the voice interaction flow experience that can influence consumers' attitudes and behavioral intentions. Furthermore, Balakrishnan and Dwivedi (2021) found that human-to-machine interaction influences cognitive absorption (a state of flow) more positively than human-to-human interaction.</p>
<p>Fuzzy theories focus on explaining different cognitive processes. An example is fuzzy trace theory that introduce dual-trace conceptions, composed of exact literal memory (i.e., verbatim traces) and fuzzy representations of past events (i.e., gist traces). Both traces predict and explain cognitive phenomena, particularly in memory and reasoning. Using fuzzy trace theory, Reyna &amp; Casillas, (2009) develop theoretical propositions to reduce low numeracy in the context of medical decision making. Unlike original set theories, where an item is either a member or not of a set, fuzzy set theories recognize that some sets have less clear boundaries (Maiers &amp; Sherif, 1985). Applications of this theory are found in the fields of AI, computer science, medicine, control engineering, decision theory, expert systems, pattern recognition, and robotics (Zimmermann 2010). From our review, notable studies applying fuzzy set theory is the work of Deng (2008) to improve conventional importance-performance analysis which was used by managers in determining critical service attributes to improve service quality and customer satisfaction.</p>
<p>Graph theory is concerned with the study of graphs. The majority of studies on graph theory dates to the 1940s and 1950s when work on social networks allowed to discover emergent groups and trends in network data (Bondy &amp; Murty, 1976). Graph theory precedes more recent work on network analysis (Heeren et al., 2019). Some prominent papers in the field include the work of Lai et al (2019) who used graph theory to analyze user generated content collected via text mining to inform design generation, product improvement, and market analysis.</p>
<p>The institutional theory is traditionally concerned with what and how organizations act upon to secure their positions and legitimacy by conforming to social norms, rules, and beliefs (DiMaggio &amp; Powell, 1983). The theory has been applied in studies that examine environmental management in organizations (Glover et al., 2014;Hoffman, 1999), social values changes (Ball &amp; Craig, 2010), and technology advancements related to sustainable activities (Lounsbury, 1997) ART combines neurobiological plausibility with mathematical rigor to explain a range of psychological and neural findings, including memory, learning, attention, priming, and pattern recognition (Protopapas, 1999).</p>
<p>During the presentation of input vector, ART networks create categories online and are able to classify known and unknown input vectors (Raijmakers &amp; Molenaar, 2004). Raijmakers and Molenaar (2004) demonstrated how neural networks, through the use of change in the equilibrium behavior, acquire new knowledge.</p>
<p>The cognitive dissonance theory posits that dissonance is a psychological state of tension that people are motivated to reduce (Festinger, 1957). The theory has been used to explain psychological phenomena such as the transmission of rumors, rationalization of decisions, selectivity in information search and interpretation, and responses to disconfirmation of beliefs (Shultz &amp; Lepper, 1996). Shultz and Lepper (1996) CCT refers to a family of theoretical perspectives that address the dynamic relationships between consumer actions, the marketplace, and cultural meanings (Arnould &amp; Thompson, 2005). Some of the papers that were captured by our literature search posit that that big data, the use of algorithms and market analytics are limiting the ability of consumer researchers to cultivate their own theories (Belk &amp; Sobh, 2019). In another study, Hollebeek and Belk (2021) compared positivist models such as the TAM and the positive emotions, engagement, relationships, meaning, and accomplishments (PERMA) model that consist with CCT perspectives to examine consumers' technology-facilitated brand engagement and wellbeing.</p>
<p>Based on frequency analysis of the theories that display lower overall frequency in the full sample but recorded the fastest growth over the last year, we identified a number of emerging theories. These theories could help advance knowledge in this area further. These include anthropomorphism, construal level theory (CLT), actor-network theory (ANT), and RBT.</p>
<p>Anthropomorphism consists in the attribution of human mental states or affects to non-human entities such as animals and objects (Airenti, 2018). The sociality, effectance, and elicited agent knowledge (SEEK) model has been the major social psychological theory to organize our understanding of anthropomorphism (Epley et al., 2007).</p>
<p>Sociality relates to the human need to form social connection with other humans, whilst effectance relates to the need to interact effectively with one's environment. Finally, elicitation of agent knowledge relates to the knowledge agents gather about humans and their behavior. A combination of the three factors are considered to explain the anthropomorphism of objects. In relation to this psychological phenomena, neurophysiological research has found that humans react more to a nonanthropomorphic robot when a human interacts in a social way with the robot as opposed than when interacting in a functional way (Hoenen et al., 2016).</p>
<p>Notable research in this area examines how, as we move towards building robots that look and behave like humans, emerging concerns about deception, privacy, job loss, safety, and the loss of human relationships become more prevalent (Broadbent, 2017). Of interest is also the work of Araujo (2018) on disembodied conversational agents (chatbots) and the extent to which human-like cues such as language style and name influence perceptions about social presence as well as mindful and mindless anthropomorphism.</p>
<p>CLT introduces the concept of psychological distances to explain how people perceive objects (or persons) at different construal levels, which in turns affects how those objects are being evaluated (Trope &amp; Liberman, 2010). Construals are conceptualized as the individuals' perception and action in seeking to comprehend, categorize, identify and/or recognize what they encounter (e.g., a task or an experience).</p>
<p>The theory posits that when psychological distances increases, construals become more abstract, and as the level of abstraction increases so too would the psychological distances people envisage.</p>
<p>Changes in distances perceptions also influence prediction, evaluation, and action (Adler &amp; Sarstedt, 2021). The theory has advanced several aspects of consumer research on perception, information processing, preference shifts, and decision making. In terms of AI, the theory has informed research on natural language processing.</p>
<p>For example, the work of Bhatia and Walasek (2016) found that text posted on social media mentioning temporally proximate dates used more concrete words than those mentioning distant dates.</p>
<p>ANT explains human behaviors (e.g., consumption behaviors) and people's interactions with inanimate objects. According to ANT, an actor is conceptualized as the source of an action regardless of its status as a human or non-human. Cresswell et al. (2010) 2010) used an actornetwork approach to identify the social and ethical dimensions of the increased use of robots as companions.</p>
<p>RBT provides a theoretical lens when examining the implications of AI in marketing at a meso-level from an organizational perspective. RBT suggests that a firm's resources, both tangible and intangible, facilitate its performance and competitive advantage when the resource is valuable, rare, imperfectly imitable, and exploitable by the organization (Barney, 1991). A resource is valuable when it generates value to the firm or the customer. Rare resources are those that are not abundant. Imperfectly imitable resources are difficulty for competitors to copy, and finally, an exploitable resource that one that the firm can benefit from in a way others cannot. Here, RBT has been used to examine the potential impact that new resources that enable many of the AI applications in marketing (e.g., big data) can become a source of competitive advantage (Erevelles et al., 2016).</p>
<p>This study makes several key contributions to research in AI. First, we focus on AI in the interrelated fields of marketing, consumer research, and psychology. This represents a way to capture in a more holistic manner research on AI in disciplinary areas whose boundaries are often blurring when dealing with AI. This represents an advancement over recent bibliometric studies and literature reviews that have more narrowly focused on AI in marketing, without taking into account the cognate field of psychology (Mustak et al., 2021;Vlacic et al., 2021).</p>
<p>Our SLR shows that the publications in the interrelated areas of marketing, consumer research, and psychology has recorded exponential growth over the last decade, with the most publications being in journals that focus on psychology and human-computer interactions, followed by computer and information system journals, and business research, marketing, and sector specific journals.</p>
<p>Clearly, cross-fertilization between these fields should advance our understanding of AI as each field explores similar issues from their discipline's particular lens.</p>
<p>Second, in addition to adopting bibliometric techniques, we focused on the overarching intellectual structure emerging from the three steams of literature and therefore move beyond traditional disciplinary boundaries and look at the multidisciplinary linkages and dialogue between these three fields. As such, this SLR study is by definition multidisciplinary and identifies topical areas in a holistic process. This means, for instance, that marketing phenomena are captured also in relation to their psychological drivers which is in line with the philosophy, aim and scope of Psychology &amp; Marketing (Donthu et al., 2021).</p>
<p>In particular, we compellingly connect and synthetize theory found in the literature (Vargo &amp; Koskela-Huotari, 2020) by identifying eight major clusters where research in the focal areas have developed.</p>
<p>Through our analysis of keywords occurrence, we were able to identify the keyword co-occurrence networks in this field (which we named using the term occurring more frequently within the network): big data, machine learning, AI, data mining, neural networks, marketing, and ecommerce. Furthermore, using bibliographic coupling, we identify topical areas and illustrate the relationships that exist between the topical areas in the literature.</p>
<p>Using bibliographic coupling eight clusters of research were identified which range from those that are heavily reliant on computer science (memory and computational logic, neural network, machine learning and linguistic analytics), psychological sciences (decision making and cognitive processes), and themes related to technology acceptance/ adoption and applications to marketing and consumer research (technology acceptance and adoption, big data and robots, social media and text mining and social media content analysis).</p>
<p>Third, and as a corollary of the previous point, we identify and discuss the wide range of theoretical lenses and models adopted to get to a better understanding of AI. This attention to theoretical lenses and models can help not only to connect studies formally belonging to the different literatures, but also to cross-fertilize the use of theories across fields. Specifically, we identified a total of 412 different theories and models, with the most frequently used being: Game theory, theory of mind, theory of planned behavior, computational theories, BRT, decision theories, evolutionary theory, flow theory, fuzzy theories, graph theory, institutional theory, ART, cognitive dissonance theory, CCT, and UTAUT (including its predecessor, the TAM).</p>
<p>Finally, we identified a number of emerging theories in the literature that could help to advance knowledge in AI. They are anthropomorphism, CLT, ANT, and RBT.</p>
<p>As comprehensive, structured, and analytical means of accurately organizing research articles, a SLR is an effective method to identify gaps in the literature (Klassen et al., 1998;Paul &amp; Criado, 2020) and highlight areas that remain understudied but should receive further attention (Snyder, 2019). We first discuss findings that flow directly from our literature analysis, followed by topics the author team sees as important but that have not yet been covered much in the literature.</p>
<p>This SLR identified the following eight clusters: (1) memory and computational logic, (2) neural networks, (3) machine learning and linguistic analytics, (4) decision making and cognitive processes, (5) technology acceptance and adoption, (6) big data and robots, ( 7) social media and text mining, and (8) social media content analysis.</p>
<p>These clusters could be linked to each other and thus reconfigured into three macro-clusters (as clarified in Section 4.3) due to the proximity of the topical areas of the clusters. The first macro-cluster includes articles that are heavily reliant on computer science (memory and computational logic, neural network, machine learning and linguistic analytics). We predict that several research opportunities can arise and contribute to the expansion of this macro-cluster in the future as cross-disciplinary studies involving computer science, brain science and social sciences might become increasingly relevant. In this area, research on explainable AI will help overcome some of the emerging challenges around the use AI in daily settings, particularly in terms of improving transparency and trust, enabling auditing of AI systems for regulatory reasons, and to enable adjusting of AI systems when they behave unexpectedly. The second macro-cluster includes articles that relate mostly to psychological sciences (decision making and cognitive processes). This is an area that has already witnessed some growth but could record further evolution as an increasing number of AI scholars from outside the psychology field team up with psychology experts to understand the psychological underpinnings of human perceptions of and interaction with AI. The third macrocluster entails studies related to technology acceptance/adoption and applications to marketing and consumer research (technology acceptance and adoption, big data and robots, social media and text mining and social media content analysis). While this is a relatively mature area, further research is likely to cover AI technology acceptance and adoption as AI technologies evolve further.</p>
<p>The different clusters can cross-fertilize each other not only in terms of commonalities of topics, but also in terms of theories. For example, decision theories can be adopted in conjunction with game theories to generate added value in studies that will focus on data-driven models. For example, evidence suggest that some marketing activities could be outperformed by automated systems relying on machine learning (Salminen et al., 2019). Here, decision theories and game Furthermore, some technologies that rely more on the disclosure of personal data to allow customization might lead to higher levels of privacy concerns as a barrier of adoption (Lobschat et al., 2021).</p>
<p>CCT might generate opportunities to advance our understanding of how the growing use of AI technologies and social media platforms influence cultural production (e.g., Rokka, 2021) and the way consumers make sense of cultural production.</p>
<p>We were surprised that important topics did not seem to get the research attention we feel they should deserve. First, AI-related ethics, fairness and privacy are probably the most important topics that have not had the prominence they deserve in our three fields of study. In addition to concerns related to privacy, the unprecedented power of AI (Bornet et al., 2021;Brynjolfsson &amp; McAfee, 2017) poises important ethical dilemmas (Belk, 2020;Breidbach &amp; Maglio, 2020;Rahwan et al., 2019). These include how customer data are used in AI systems for automated decision making (e.g., whether and at what interest rate to approve a housing loan) which can result in biased and unfair consumer outcomes (e.g., a loan rejection and overpricing). At a higher level, AI can cause concern related to loss of autonomy, dignity, social isolation, dehumanization, and more (Belk, 2020;Čaić et al., 2018;Vandemeulebroucke et al. 2018).</p>
<p>Recent work on corporate digital responsibility (CDR) integrated these topics, whereby CDR relates to the ethical responsibilities organizations (including marketing departments) need to face when creating and operating AI and other digital technologies and the data they produce (Wirtz et al., 2021). CDR seems especially important when digital platform business models are involved as they largely operate via scalable and autonomous AI and provide complete visibility of all actors and their behaviors on the a platform (Rangaswamy et al., 2020) Second, it is easy to see the downsides of AI and the literature has examined many potential consumer concerns related to AI and why consumers may not want to use it (e.g., Lu et al., 2020). However, there are also advantages consumers value. For instance, consumers have been shown to prefer AI-over people-delivered service in potentially embarrassing situations (Pitardi et al., 2021). As would be predicted by theory of mind and agency, AI's inability to make social judgments may be an advantage in other contexts, such as in situations where consumers can feel unpleasant emotions such as shame, shyness, and guilt. We feel that more work is needed to better understand consumer benefits of AI.</p>
<p>Finally, there is significant AI literature in (service) operations management that has focused on productivity gains, service improvements (e.g., enhanced convenience, availability, better affordability, and frictionless customer journeys), and end-to-end automation of customer service processes (e.g., Wirtz &amp; Zeithaml, 2018). Likewise, the computer science literature has a long tradition of AI research (e.g., Jordan &amp; Mitchell, 2015), and it would be of interest to examine the applicability of the theories used in these field in marketing contexts.</p>
<p>A limitation of our study were the decisions we made for data extraction where we opted for <rs xml:id="12896686" type="software">Scopus</rs> over <rs xml:id="12896687" type="software">WoS</rs> and
<rs xml:id="12896688" type="software">Google Scholar</rs>.
</p>
<p>While this is consistent with recent work (Gusenbauer &amp; Haddaway, 2020;Ling et al., 2021), future research might also collect data from different databases. However, retrieving data from <rs xml:id="12896689" type="software">WoS</rs> would yield only a subsample of the scientific articles obtained as we found when running the same queries in <rs xml:id="12896690" type="software">WoS</rs>, and extracting data from
<rs xml:id="12896691" type="software">Google Scholar</rs> would increase significantly the complexity of retrieving meaningful metadata for large-scale bibliometric studies (Martín-Martín et al., 2018). Overall, using a major database like <rs xml:id="12896692" type="software">Scopus</rs> is consistent with previous research but casting the net wider might yield additional insights.
</p>
<p>15206793, 2022, 4, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/mar.21619 by Area Sistemi Dipart &amp; Document, Wiley Online Library on [23/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License</p>
<p>Open access funding provided by Universita degli Studi di Bologna within the CRUI-CARE Agreement.</p>
<p>The authors declare that there are no conflict of interests.</p>
</text>
</tei>