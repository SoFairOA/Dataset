<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
<teiHeader>
<fileDesc xml:id="_1"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text xml:lang="en">
<p>An optimized dense convolutional neural network (CNN) architecture (DenseNet) for corn leaf disease recognition and classification is proposed in this paper. Corn is one of the most cultivated grain throughout the world. Corn crops are highly susceptible to certain leaf diseases such as corn common rust, corn gray leaf spot, and northern corn leaf blight are very common. Symptoms of these leaf diseases are not differentiable in their nascent stages. Hence, the current research presents a solution through deep learning so that crop health can be monitored and, it will lead to an increase in the quantity as well as the quality of crop production. The proposed optimized DenseNet model has achieved an accuracy of 98.06%. Besides, it uses significantly lesser parameters as compared to the various existing CNN such as <rs xml:id="12966194" type="software">EfficientNet</rs>, <rs xml:id="12966195" type="software">VGG19Net</rs>, <rs xml:id="12966196" type="software">NASNet</rs>, and <rs xml:id="12966197" type="software">Xception Net</rs>. The performance of the optimized DenseNet model has been contrasted with the current CNN architectures by considering two (time and accuracy) quality measures. This study indicates that the performance of the optimized DenseNet model is close to that of the established CNN architectures with far fewer parameters and computation time.</p>
<p>The agriculture sector is adopting artificial intelligence and machine learning in diverse areas including disease detection, soil monitoring, weed controlling, diagnosing pests, computer vision and drones for crop analysis, and weather predictions. Agriculture is the most important sector of the Indian economy, accounting for 18% of its GDP [1]. The main source of income for a large population of India is agriculture. Hence, India is extremely dependent on crop productivity.</p>
<p>Corn is a very common crop in India. Corn farming is essential in India because it has a high export potential and a vast population of farmers is dependent on it [2,3]. Corn is being used in various sectors like cattle feed, poultry industry and food and beverage industries. It has become a primary food in many parts of the world, with its overall production exceeding that of wheat and rice. But in India, the yield of corn is almost half of the overall global average [2]. One of the reasons for low corn yield is that it is subjected to many diseases which significantly reduce the overall crop yield. Certain leaf diseases remain a challenge for crop production, not only through scaling down the crop yield but also through the reduction in its nutritional value. Some of the prevalent leaf diseases include common rust, gray leaf spot, and leaf blight.</p>
<p>These leaf diseases may look very comparable in their nascent phases, hence making it very difficult to detect through the naked eye. Detection of leaf diseases through visual observation requires a team of specialists and constant crop monitoring [4]. Thus, making it very costly, time-consuming and less reliable. We can leverage deep learning techniques to conduct automatic, rapid and more precise leaf disease detection and classification. Several researchers have worked in this region to create a model that can predict the existence of leaf disease in corn plants. We examine some of these researches in the following paragraphs.</p>
<p>Zhang et al. [5] proposed an improved SVM called genetic algorithm support vector machine (GA-SVM). The author collected and classified six types of corn leaf diseases. The following steps were carried out to classify the diseases: For image processing, the JPEG images were transformed into BMP format. Furthermore, the images were converted from RGB template to HSI, to extract various features (average and standard deviations of R, G, B and shape features such as area, circumference, circularity, height, and width, etc). Then segmentation was implemented to get binary images. Finally, the technique of Orthogonal rotation was used to obtain appropriate parameters for the genetic algorithm. Twenty feature parameters were fed to the model. For classification comparisons between SVM and GA-SVM, four kernels were selected: linear, polynomial, RBF and sigmoid. The author concluded after comparison that GA-SVM has a higher classification rate (between 69.63% -90.09% for SVM and between 88.72% -92.59% for GA-SVM).</p>
<p>Alehegn [6] classified three types of corn leaf diseases (common rust, leaf blight, leaf spot) using KNN (K-nearest neighbour) and ANN (artificial neural network) classification algorithms. Images of healthy and corn leaf diseases were taken from Ethiopia farming areas.</p>
<p>For training and testing, a minimum of 800 images were considered. Texture, morphology and color features were obtained from the images. Total 22 features were fed to the classification model of KNN and ANN. Lastly, the author concluded that ANN had a higher performance rate with an accuracy of 94.4% whereas KNN reached an accuracy of 82.5%.</p>
<p>An improved <rs xml:id="12966198" type="software">GoogLeNet</rs> and Cifar 10 model was proposed in [7] for classification of 8 corn leaf diseases (southern leaf blight, brown spot, rust, round spot, dwarf mosiac, curvularia leaf spot, gray leaf spot, northern leaf blight). Total 500 images were collected for 9 classes (8 classes of diseased corn leaves and one for healthy leaves). Data augmentation technique was deployed on the images. The proposed <rs xml:id="12966199" type="software">GoogLeNet</rs> architecture had 22 layers and lesser parameters than VGG and <rs xml:id="12966200" type="software">Alexnet</rs> model. Cifar 10 model was also optimized by adding more layers and using ReLU function. The performance of the models was evaluated on the corn leaf dataset. The precision of <rs xml:id="12966201" type="software">GoogLeNet</rs> and Cifar 10 was 98.9% and 98.8%, respectively. Durga and Anuradha [8] used SVM and ANN algorithm for leaf disease classification in tomato and corn plants. Image dataset included 200 pictures with a collection of healthy leaves and diseased leaves like northern leaf blight, common rust, bacterial spot, tomato mosaic virus, etc. They used the following steps to identify the diseases: the RGB picture was converted to the grayscale picture and the image was then segmented by calculating the intensity gradient at each pixel. For feature extraction, HOG (histogram of oriented gradients) procedure was used. The extracted features were fed to the SVM and ANN classifier models. For corn crops, SVM gave an accuracy of 70-75% and ANN gave an accuracy of 55-65%.</p>
<p>Bhatt and Sarangai [9] developed a system for the identification of corn leaf diseases using CNN architectures (<rs xml:id="12966202" type="software">VGG16</rs>, <rs xml:id="12966203" type="software">inception</rs>-v<rs xml:id="12966204" type="version" corresp="12966203">2</rs>, <rs xml:id="12966205" type="software">ResNet50</rs>, <rs xml:id="12966206" type="software">mobileNet</rs>-v<rs xml:id="12966207" type="version" corresp="12966206">1</rs>) and applied a combination of adaptive boosting with decision tree-based classifier to distinguish between diseases that appeared to be similar. Four categories of image data included healthy leaves, common rust, leaf blight, and leaf spot. Pictures of each class were taken from PlantVillage dataset. The pictures were resized for image preprocessing according to the necessity of the CNN model used. Features derived from the CNN models were fed to the classifiers (softmax, support vector machine and random forest). It was observed that <rs xml:id="12966208" type="software">inception</rs>-v<rs xml:id="12966209" type="version" corresp="12966208">2</rs> gave the highest precision with random forest. From the confusion matrix of each classifier, the author noted that leaf blight and leaf spot classes were difficult to differentiate. Therefore, to increase the classification accuracy between them, the Adaptive boosting technique was applied to the best performing model (based on <rs xml:id="12966210" type="software">Inception</rs>-v<rs xml:id="12966211" type="version" corresp="12966210">2</rs> and RF). Finally, the model reached an accuracy of ~98%.</p>
<p>Lu C and Gao S, et al. [37] used a fuzzy least-square vector machine (FLSVM) to classify corn leaf diseases. To segment the diseased areas, YCbCr color space technology was used.</p>
<p>Then, the spatial grey-level co-occurrence matrix was used to extract the texture features of the region and FLSVM was used to classify the diseases. A total of 12 pictures of four different diseases were taken. Further, 0 degrees, 45 degrees, 90 degrees, and 135 degrees matrix are computed for each disease. Five texture features extracted were used in training for the fuzzy least square algorithm. The results were approximately 98% correct, for identification and classification.</p>
<p>These studies have shown good results but on small image dataset with an increase in parameters or computation time, which has an adverse effect on recognition performance. Also, some methods defined above involve machine learning techniques for feature extraction and classification of corn leaf diseases with the help of SVM, ANN, random forest and so on. For image processing in machine learning, the researcher needs to extract the features manually in an image and feed them to the classification model. These workflows are very complicated, challenging and time-consuming. Therefore, the objective of this research is to improve the conventional methods of identification and to present an optimized model for corn leaf disease identification with lesser parameters and computation time.</p>
<p>Deep learning image classifiers are used for corn leaf disease recognition and classification.</p>
<p>In deep learning, Convolutional neural networks (CNNs) is arguably the most popular architecture. It was specially designed for working with images. Convolutional neural networks are significantly used in image recognition, video recognition, object detection, medical image analysis, traffic control [38] and flow prediction [39], anomaly detection [40][41] and recommendation systems for healthcare [42]. Deep convolution neural networks have accomplished unprecedented performance in the field of computer vision over recent years.</p>
<p>For image recognition, models should have a lot of prior knowledge to make up for all the data that we don't have. Convolutional neural networks (CNNs) are one such class [10,11,12,13], but established CNN architectures give a high-performance rate with many parameters or high convergence time. By altering their depth and breadth, their capacity can be regulated, and mostly they make the right assumptions about the nature of images. CNN's, therefore, have much fewer links and parameters and are simpler to train as compared to normal neural networks [10].</p>
<p>We have been studying that the most efficient way of enhancing the performance of neural networks is by expanding their depth and width, but a recent study shows that once the network reaches a saturation point, scaling up the depth and width might cause an increase in error rate [33]. Moreover, scaling up the depth and width has two other main challenges. The first challenge that occurs with bigger networks is many parameters that makes the network more likely to overfit [14]. Another challenge is that increasing the size of the network increases the use of computational resources. Since the computational budget is usually finite, we need a systematic distribution of computing resources [14].</p>
<p>While considering the above discussion, we have proposed a novel optimized DenseNet architecture for disease recognition and classification in corn leaf. The main contribution to this paper can be stated as follows.</p>
<p>• We propose an optimized DenseNet architecture for corn leaf disease recognition and classification. Further, we have trained four other established CNN models such as <rs xml:id="12966212" type="software">VGGNet</rs>, <rs xml:id="12966213" type="software">XceptionNet</rs>, <rs xml:id="12966214" type="software">EfficientNet</rs>, <rs xml:id="12966215" type="software">NASNet</rs> for corn leaf disease recognition and classification.</p>
<p>• The performance of the proposed model has been analyzed through rigorous simulations.</p>
<p>It is noted that the proposed CNN architecture takes fewer parameters and is computationally cost effective. Simulation results reveal that the proposed network has 77,612 parameters and shows 98.06% accuracy as compared to the existing CNN models such as <rs xml:id="12966216" type="software">EfficientNet</rs>, <rs xml:id="12966217" type="software">VGG19Net</rs>, <rs xml:id="12966218" type="software">NASNet</rs>, and <rs xml:id="12966219" type="software">XceptionNet</rs>. Further, these results indicate that the accuracy of the proposed model is close to existing CNN architectures, but with significantly fewer parameters.</p>
<p>The remaining exposition is as follows. Background discussion is outlined in Section 2.</p>
<p>Proposed model is elaborated in Section 3. Simulation model is discussed in Section 4. The conclusion and future avenues are presented in Section 5.</p>
<p>CNNs are one of the most important parts of deep learning and are extensively used in computer vision. CNN's recognize visual patterns with minimal preprocessing straight from pixel images. The recent rise in popularity of CNN is attributed to its immense effectiveness.</p>
<p><rs xml:id="12966220" type="software">LeNet</rs> <rs xml:id="12966221" type="bibr">[15]</rs> architecture started the history of CNN. The interest in CNN began with <rs xml:id="12966222" type="software">AlexNet</rs> <rs xml:id="12966223" type="bibr">[10]</rs> and
<rs xml:id="12966224" type="software">ZFNet</rs> <rs xml:id="12966225" type="bibr">[16]</rs> and it has grown exponentially ever since. Some popular architectures that have been considered in this study are discussed below. weight layers) and <rs xml:id="12966226" type="software">VGG19</rs> (with 19 weight layers). Large receptive fields in
<rs xml:id="12966227" type="software">VGGNet</rs> have been substituted with consecutive layers of 3x3 convolutions with ReLU in between. The convolutional stride was fixed to 1 pixel. The padding of convolution layer input was maintained as 1 pixel and max-pooling was done with a stride of 2 over a 2 × 2-pixel window [17]. The pile of convolutional layers was joined with 3 fully connected layers and one softmax layer.
<rs xml:id="12966228" type="software">VGGNet</rs> has 144 million parameters, of which approximately 124 million are used in the last 3 Fully Connected layers. Therefore, if the fully connected layers could be eliminated, the architecture efficiency could be enhanced. This step was taken in subsequent architectures replacing the first Fully Connected layer with a node layer using a method called average pooling [18]. The architecture of
<rs xml:id="12966229" type="software">VGGNet</rs> (<rs xml:id="12966230" type="software">VGG16</rs>) is shown in Figure 1[36]. The main hallmark of the inception network was to utilize computing resources inside the network. It eliminates all the fully connected layers and uses average pooling, therefore, the system has only 5 million parameters [18]. Inception module is the building block of inception network, which captures parallel paths with distinct receptive field dimensions and operations in the stack of feature maps [14]. After the tremendous success of the inception network,
<rs xml:id="12966231" type="software">GoogLeNet</rs> (<rs xml:id="12966232" type="software">Inception</rs> V<rs xml:id="12966233" type="version" corresp="12966232">1</rs>) was modified to <rs xml:id="12966234" type="software">Inception</rs>V<rs xml:id="12966235" type="version" corresp="12966234">2</rs>, <rs xml:id="12966236" type="software">Inception</rs> V<rs xml:id="12966237" type="version" corresp="12966236">3</rs>, and <rs xml:id="12966238" type="software">Inception-ResNet</rs>.
</p>
<p>Inspired by inception network, Chollet [19] The need for computing resources grows as the dataset increases. Zoph and V. Le [22] proposed a method to search for an architectural building block on a small dataset and transferred the block to a larger dataset. <rs xml:id="12966239" type="software">NASNET</rs> achieved an 82.7 percent top-1 and 96.2 percent top-5 state-of-the-art accuracy on <rs xml:id="12966240" type="software">ImageNet</rs>. Two types of convolutional layers (or cells) are required to build <rs xml:id="12966241" type="software">NASNet</rs>: (1) convolutional layers that return same size feature maps (Normal Cells), and (2) convolutional layers which return a feature map with its height and width decreased by a factor of two (Reduction Cells). The overall architecture is predefined in [22] as shown in Figure 3. [20] proposed <rs xml:id="12966242" type="software">EfficientNet</rs>, which showed high precision value and, found more flexible as compared to ConvNets [21]. Authors [20] had addressed the challenges (developed at a fixed resource budget, and then scaled up to gain better accuracy) of the ConvNets by suggesting new scaling method which showed the tendency to uniformly scales all dimensions (depth/width/resolution) of the CNN. The effectiveness of the proposed scaling method was demonstrated by implementing it for scaling on MobileNets and ResNet.</p>
<p><rs xml:id="12966243" type="software">EfficientNet-B7</rs> revealed impressive results as it achieved state-of-the-art result of 84.4% top-1/97-1% top-5 accuracy on <rs xml:id="12966244" type="software">ImageNet</rs> with 8.4x smaller and 6.1x quicker compared to finest current ConNets [21]. The feature-maps of all the previous layers are used as inputs for each layer, and their featuremaps are used in all subsequent layers as inputs. DenseNets solves the issue of vanishing gradient [34], strengthen feature propagation, encourages reuse of features, and significantly reduces the number of parameters [24]. Each lth layer has l inputs, composed of the feature-maps of all preceding convolutional blocks. It passes its feature-maps to all Ll subsequent layers. This introduced L(L+1)/2 connections in an L-layer network [24]. This architecture has a dense connectivity pattern, therefore called a Dense Convolutional neural network.</p>
<p>These established CNN architectures have shown high performance rate for leaf disease identification but with an increase in parameters and computation time. In this paper, we present an optimized custom DenseNet for leaf disease identification and classification which has fewer parameters and, hence, less computation time than the above discussed CNN</p>
<p>architectures. An important point to note at this stage is -"recurrent neural network (RNN) or long short-term memory (LSTM) network) have been designed to work differently. The RNN is usually used to work with sequential data, in contrast, CNN is designed to exploit spatial correlation of data and works well on images. CNN was specially designed for working with images. The architecture of the proposed model is discussed in detail in the next section.</p>
<p>This section presents the methodology adapted in the current research. We have presented a step-by-step description of the methodology to make the overall concept understandable. And finally, the performance of the model is assessed. The general approach model for corn leaf disease recognition and classification is shown below in Figure 5.</p>
<p>Problems arise with the CNNs as they get deeper because the route from the input layer to the output layer becomes so large that when it hits the other side of the network, the backpropagating gradient disappears. This vanishing gradient issue was resolved in ResNet [29] architecture by introducing skip connections between layers that add outputs from prior layers to stacked layers' outputs. ResNets shortened the stochastic depth [30] of the network by dropping some random layers during training which allowed better gradient and information flow. Thus, increasing the ability to train deeper networks. Unlike ResNets, DenseNets [24] links all layers to each other directly and ensures an optimal flow of information within the layers with a simple connectivity pattern. Rather than adding the residual, as in ResNet, all the feature maps are concatenated by the DenseNet. Therefore, they can be deeper than normal networks and can be readily optimized with this fresh residual usage. With very less parameters, this new CNN architecture has achieved state-of-the-art results on datasets (CIFAR, ImageNet). DenseNets have two main advantages: 1) Parameter Efficiency 2) Deep Supervision. This network has fewer parameters than standard networks because firstly it generates feature maps with a tiny growth rate (the total output feature maps of a layer is growth rate) and secondly it applies a 1×1 convolution as a bottleneck layer before each 3×3 convolution to reduce the number of input feature maps [24]. Lastly, extreme residual usage produces deep supervision as each layer in DenseNet receives more supervision from the loss function due to the shorter links.</p>
<p>DenseNet is made by connecting multiple dense blocks. A dense block is a set of layers that are attached to all its former layers. One layer in the dense block is composed of 4 layers: 1) Batch Normalization 2) ReLU activation 3) 3x3 convolution 4) Dropout. The layer between two dense blocks i.e. the transition layer performs down-sampling. It is made of 1) Batch</p>
<p>Normalization 2) ReLU activation 3) 1x1 convolution and 4) Average Pooling. Figure 6 shows the architecture of the proposed model.</p>
<p>Adaptive Moment Estimation (Adam) [32] is a technique used for stochastic optimization. It evaluates adaptive learning rates for distinct parameters. This optimizer brings together the benefits of two latest optimizers, i.e. AdaGrad [35] and RMSProp to provide a technique for handling noisy issues with sparse gradients. It is easy to implement, works efficiently, has fewer memory requirements, invariant to the rescaling of gradient and works with sparse gradients. Adam uses the average of the second-order gradients rather than using the learning rates based on the average of the first moments. It specifically calculates the gradient and the squared gradient as an exponential moving average. Most of the features for the real time datasets are sparse due to which the corresponding gradient for most instances could be zero and therefore the parameters update is also zero hence we will not proceed the learning. In order to respond to this problem, the learning rate should be adaptive to relatively sparse data. The Adagrad, RMSProp, and Adam optimization algorithms are based on adaptive learning rates. In Adagrad the learning rate decays aggressively and RMSProp has high number of oscillations which might delay the convergence, so the best choice is Adam which overcomes both problems. Algorithm 1 presents the Adam optimizer used in this study. • α :</p>
<p>Step size(also called learning rate) parameter (0.001)</p>
<p>• d w , d b : weights and bias gradient • β1 :The first moment exponential decay rate (0.9)</p>
<p>• β2 : The second moment exponential decay rate (0.999)</p>
<p>• ε : Fuzz factor; Very small number to avoid division from zero.</p>
<p>• t: Initial time step • Vd w : first moment vector for weights • Vd b : first moment vector for bias • Sd w : second moment vector for weights Most of the computer vision applications use CNN. Two major difficulties with CNN are hardware for excellent performance and high-power consumption of this hardware [12]. Therefore, high-performance hardware like Colaboratory's GPU is required. Using the accelerated runtime of
<rs xml:id="12966245" type="software">Colaboratory</rs> to train CNNs is 2.93 times faster on average than using all
Linux server physical cores <rs xml:id="12966247" type="bibr">[25]</rs>.
</p>
<p>The proposed models' hyperparameters are shown in Table 3 that are used throughout the training of the model. The model's accuracy can be influenced by changing the initial learning rate. The model is optimized using Adam optimizer with an initial learning rate of 0.0005 which is further fine-tuned to 0.00001. Grid search is used to find the optimal hyperparameter values.</p>
<p>The model is trained by grid search for all combinations by using different sets of hyperparameters. Kernel is initialized using glorot uniform and bias with zeros. The batch training method is to split the training and testing set into several batches with each batch comprising 32 images.</p>
<p>Deep learning models perform better when the size of the dataset is large hence to achieve this, we expanded the dataset by creating artificial samples from existing samples. The technique of creating artificial samples from existence samples by varying orientations of original samples is called data augmentation. Data augmentation allows programmers to considerably enhance the diversity and eventually the size of data available to train the models [28]. It is a known fact that CNN can handle variations in image and classify items even when they are positioned in distinct orientations [43] [44]. This is fundamentally the premise of data augmentation. To train CNN, substantial data is required so that it can learn and extract more features. The data collection process is associated with a cost that can be in terms of money, human effort, computational resources, and time consumption. Therefore, one may need to augment the existing data by making some minor alterations to images like scaling, rotating, translating, etc. The advantage of generating a greater number of training examples is that it makes the model more robust and generalized; thereby improving its accuracy. All images in the dataset are subject to several steps of data augmentation. 4. Besides, it can be seen that the classes 0 and 3 are overlapping the most. Therefore, we can say that it is difficult to distinguish between Cercospora_leaf_spot Gray_leaf_spot and Northern_Leaf_Blight classes. A comprehensive classification reported has been prepared and drafted and in the Table 5.</p>
<p>In this paper, we have presented an optimized dense CNN architecture (DenseNet) for corn leaf disease recognition and classification. We showed existing neural network architectures in the background and comprehensively discussed their strengths and weaknesses. We presented a step-by-step discussion of the proposed model so that it can be re-implemented for future purposes by other researchers. Extensive computer simulations have been performed to evaluate the performance of the proposed network. A robust experimental environment has been developed to conduct the simulations. Table 2 and</p>
<p>Table 1 shows the layer-wise description of the proposed model. Categorical cross entropy is used as model's loss function and Adaptive Moment Estimation (Adam) is used as the optimizer of the model. ReLU is used as an activation function because it is computationally efficient. Other functions like sigmoid and tanh are computationally expensive and suffer from vanishing gradient problem. The model was trained for 47 epochs with each epoch taking approximately 3.7 minutes, following which we get a validation accuracy of 98.06%.</p>
</text>
</tei>